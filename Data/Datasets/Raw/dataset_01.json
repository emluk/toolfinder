{
    "operation_0267": {
        "Name": "Protein secondary structure prediction",
        "Count": 5,
        "Tools": {
            "ps2": {
                "Name": "(PS)2-v2: Protein Structure Prediction Server",
                "Description": "(PS)2 Protein Structure Prediction Server performs automated homology modeling by combining PSI-BLAST, IMPALA, and T-Coffee for template selection and target-template alignment. The final three-dimensional (3D) structure is built using RAMP or MODELLER.",
                "GPU": false,
                "CPU": false,
                "ram": true,
                "parallel": false,
                "distributed": false
            },
            "isgp-drlf": {
                "Name": "isGP-DRLF",
                "Description": "Identification of Sub-Golgi protein localization by use of deep representation learning features.\n\nif computing on a GPU, it would be fasster.",
                "GPU": true,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": false
            },
            "prottrans": {
                "Name": "ProtTrans",
                "Description": "ProtTrans is providing state of the art pre-trained models for proteins. ProtTrans was trained on thousands of GPUs from Summit and hundreds of Google TPUs using various Transformers Models.",
                "GPU": true,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": false
            },
            "Wang-xiaoheng": {
                "Name": "Wang-xiaoheng",
                "Description": "Prediction of protein structural classes by different feature expressions based on 2-D wavelet denoising and fusion.\n\n2D-wavelet-for-protein-structural-classes-prediction We constructed a prediction model based on wavelet denoising using different feature expression methods. A new fusion idea, first fuse and then denoise, is proposed in this article. Two types of pseudo amino acid compositions are utilized to distill feature vectors. Then, a two-dimensional (2-D) wavelet denoising algorithm is used to remove the redundant information from two extracted feature vectors. The two feature vectors based on parallel 2-D wavelet denoising are fused, which is known as PWD-FU-PseAAC. The project includes three original datasets, source code for two-dimensional wavelet denoising and source code for feature vector prediction",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "what_if": {
                "Name": "WHAT IF",
                "Description": "PDB Related Datbases present a series of databases that run parallel to the PDB. DSSP holds the secondary structure of the proteins. PDBREPORT holds reports on the structure quality and lists errors. HSSP holds a multiple sequence alignment for all proteins. The PDBFINDER holds easy to parse summaries of the PDB file content. PDB_REDO holds re-refined, and often improved, copies of all structures solved by X-ray.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            }
        }
    },
    "operation_0268": {
        "Name": "Protein super-secondary structure prediction",
        "Count": 2,
        "Tools": {
            "ps2": {
                "Name": "(PS)2-v2: Protein Structure Prediction Server",
                "Description": "(PS)2 Protein Structure Prediction Server performs automated homology modeling by combining PSI-BLAST, IMPALA, and T-Coffee for template selection and target-template alignment. The final three-dimensional (3D) structure is built using RAMP or MODELLER.",
                "GPU": false,
                "CPU": false,
                "ram": true,
                "parallel": false,
                "distributed": false
            },
            "mri-image-snr-computer": {
                "Name": "MRI parallel image SNR Computer",
                "Description": "Compute SNR for MRI parallel images using different reconstruction methods. There are three methods we used here to compute the SNR of MR images: ACR, SoS, and OPT.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            }
        }
    },
    "operation_0474": {
        "Name": "Protein structure prediction",
        "Count": 7,
        "Tools": {
            "ps2": {
                "Name": "(PS)2-v2: Protein Structure Prediction Server",
                "Description": "(PS)2 Protein Structure Prediction Server performs automated homology modeling by combining PSI-BLAST, IMPALA, and T-Coffee for template selection and target-template alignment. The final three-dimensional (3D) structure is built using RAMP or MODELLER.",
                "GPU": false,
                "CPU": false,
                "ram": true,
                "parallel": false,
                "distributed": false
            },
            "gpgpufragfold": {
                "Name": "GPGPUFRAGFOLD",
                "Description": "GPUFRAGFOLD is a CUDA ACELERATED Protein Structure Prediction Tool.",
                "GPU": true,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": false
            },
            "gpu-i-tasser": {
                "Name": "GPU-I-TASSER",
                "Description": "A GPU accelerated I-TASSER protein structure prediction tool.",
                "GPU": true,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": false
            },
            "gramm-x": {
                "Name": "GRAMM-X",
                "Description": "GRAMM-X is a protein docking server.",
                "GPU": false,
                "CPU": false,
                "ram": true,
                "parallel": false,
                "distributed": false
            },
            "modorama": {
                "Name": "MODORAMA",
                "Description": "At MODORAMA two applications can be run: MODexplorer, an integrated tool for exploring protein sequence, structure and function relationships, and MODalign, a rich alignment editor to improve target-template alignments",
                "GPU": false,
                "CPU": false,
                "ram": true,
                "parallel": false,
                "distributed": false
            },
            "rfcoil": {
                "Name": "RFCoil",
                "Description": "A predictor that could distinguish parallel dimeric and trimeric coiled coils. It uses the most efficient and non-redundant amino acid indices combined with the state-of-the-art machine learning method Random Forest to make the prediction.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "Wang-xiaoheng": {
                "Name": "Wang-xiaoheng",
                "Description": "Prediction of protein structural classes by different feature expressions based on 2-D wavelet denoising and fusion.\n\n2D-wavelet-for-protein-structural-classes-prediction We constructed a prediction model based on wavelet denoising using different feature expression methods. A new fusion idea, first fuse and then denoise, is proposed in this article. Two types of pseudo amino acid compositions are utilized to distill feature vectors. Then, a two-dimensional (2-D) wavelet denoising algorithm is used to remove the redundant information from two extracted feature vectors. The two feature vectors based on parallel 2-D wavelet denoising are fused, which is known as PWD-FU-PseAAC. The project includes three original datasets, source code for two-dimensional wavelet denoising and source code for feature vector prediction",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            }
        }
    },
    "operation_0477": {
        "Name": "Protein modelling",
        "Count": 3,
        "Tools": {
            "ps2": {
                "Name": "(PS)2-v2: Protein Structure Prediction Server",
                "Description": "(PS)2 Protein Structure Prediction Server performs automated homology modeling by combining PSI-BLAST, IMPALA, and T-Coffee for template selection and target-template alignment. The final three-dimensional (3D) structure is built using RAMP or MODELLER.",
                "GPU": false,
                "CPU": false,
                "ram": true,
                "parallel": false,
                "distributed": false
            },
            "gramm-x": {
                "Name": "GRAMM-X",
                "Description": "GRAMM-X is a protein docking server.",
                "GPU": false,
                "CPU": false,
                "ram": true,
                "parallel": false,
                "distributed": false
            },
            "modorama": {
                "Name": "MODORAMA",
                "Description": "At MODORAMA two applications can be run: MODexplorer, an integrated tool for exploring protein sequence, structure and function relationships, and MODalign, a rich alignment editor to improve target-template alignments",
                "GPU": false,
                "CPU": false,
                "ram": true,
                "parallel": false,
                "distributed": false
            }
        }
    },
    "operation_3501": {
        "Name": "Enrichment analysis",
        "Count": 5,
        "Tools": {
            "3d-SPADE": {
                "Name": "3d-SPADE",
                "Description": "3d-SPADE is a method to find reoccurring spike patterns in parallel spike train data, and to determine their statistical significance. It is a part of Elephant.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "HCCPred": {
                "Name": "HCCPred",
                "Description": "Identification of Platform-Independent Diagnostic Biomarker Panel for Hepatocellular Carcinoma using Large-scale Transcriptomics Data | A webserver to predict Hepatocellular carcinoma (HCC) | Pipeline Differential Expression Analysis | HCCpred is a web-bench for the prediction of tumorous and non-tumorous Hepatocellular Carcinoma (HCC) patients. Our major prediction modules based on the robust biomarkers such as 3-Gene HCC Biomarker, 4-Gene HCC Biomarker, 5-Gene HCC Biomarker. These HCC biomarkers identified using gene expression profiles of a total of 3,961 samples include 2,306 HCC and 1,655 non-tumorous samples. The datasets derived from various profiling platforms such as Affymatrix, Illumina, High-througput and Agilent. The user can also analyse the expression pattern of any of 26 'core genes of HCC' in cancerous vs normal conditions",
                "GPU": true,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": false
            },
            "igemrna": {
                "Name": "IgemRNA",
                "Description": "IgemRNA is an open access toolbox for transcriptome data statistical and biochemical network topology-based analysis. IgemRNA was developed in the MATLAB environment in order to take advantage of the up-to-date and most commonly distributed GSM modelling tool Cobra Toolbox 3.0 and spreadsheet file capabilities.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            },
            "MPRAnalyze": {
                "Name": "MPRAnalyze",
                "Description": "Statistical framework for massively parallel reporter assays | Statistical Analysis of MPRA data | MPRAnalyze provides statistical framework for the analysis of data generated by Massively Parallel Reporter Assays (MPRAs), used to directly measure enhancer activity. MPRAnalyze can be used for quantification of enhancer activity, classification of active enhancers and comparative analyses of enhancer activity between conditions. MPRAnalyze construct a nested pair of generalized linear models (GLMs) to relate the DNA and RNA observations, easily adjustable to various experimental designs and conditions, and provides a set of rigorous statistical testig schemes",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "rseqrep": {
                "Name": "RSEQREP",
                "Description": "Cloud-enabled framework that allows users to execute start-to-end gene-level RNA-Seq analysis. It works with unstranded, stranded, and paired-end sequence FASTQ files. It automatically executes a series of customizable steps including reference alignment, CRAM compression, reference alignment QC, data normalization, multivariate data visualization, identification of differentially expressed genes, heatmaps, co-expressed gene clusters, enriched pathways, and a series of custom visualizations.",
                "GPU": false,
                "CPU": false,
                "ram": true,
                "parallel": false,
                "distributed": false
            }
        }
    },
    "operation_3233": {
        "Name": "Copy number estimation",
        "Count": 5,
        "Tools": {
            "adacgh2": {
                "Name": "ADaCGH2",
                "Description": "Analysis and plotting of array CGH data. Allows usage of Circular Binary Segementation, wavelet-based smoothing (both as in Liu et al., and HaarSeg as in Ben-Yaacov and Eldar), HMM, BioHMM, GLAD, CGHseg. Most computations are parallelized (either via forking or with clusters, including MPI and sockets clusters) and use ff for storing data.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "copywriter": {
                "Name": "CopywriteR",
                "Description": "This tool extracts DNA copy number information from targeted sequencing by utilizing off-target reads. It allows extracting uniformly distributed copy number information, and it can be applied to sequencing data obtained from various techniques including chromatin immunoprecipitation and target enrichment on small gene panels. Thereby, this tool constitutes a widely applicable alternative to available copy number detection tools.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            },
            "ngscopy": {
                "Name": "NGScopy",
                "Description": "Provides a quantitative caller for detecting copy number variations in next generation sequencing (NGS), including whole genome sequencing (WGS), whole exome sequencing (WES) and targeted panel sequencing (TPS). The caller can be parallelized by chromosomes to use multiple processors/cores on one computer.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "segseq": {
                "Name": "SegSeq",
                "Description": "An algorithm to identify chromosomal breakpoints using massively parallel sequence data.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "seqseg": {
                "Name": "SeqSeg",
                "Description": "An algorithm to detect and localize copy-number alterations from massively parallel sequence data.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            }
        }
    },
    "operation_0282": {
        "Name": "Genetic mapping",
        "Count": 2,
        "Tools": {
            "ADDO": {
                "Name": "ADDO",
                "Description": "a comprehensive toolkit to detect, classify and visualise additive and non-additive Quantitative Trait Loci.\n\nWe developed ADDO, a highly-efficient tool designed to detect, classify and visualize quantitative trait loci (QTLs) with additive and non-additive effects. ADDO implements a mixed-model transformation to control for population structure and unequal relatedness that accounts for both additive and dominant genetic covariance among individuals, and decomposes single nucleotide polymorphism (SNP) effects into additive, partial dominance, dominance and overdominance categories. A matrix multiplication approach is used to accelerate the computation: a genome scan on 20 million markers from 836 individuals takes about 8.5 hours with 10 CPUs.\n\nAdditivity and dominance are the major genetic components underlying variations in complex traits",
                "GPU": false,
                "CPU": true,
                "ram": false,
                "parallel": false,
                "distributed": false
            },
            "liteqtl": {
                "Name": "LiteQTL",
                "Description": "LiteQTL is a package that runs whole genome QTL scans near real-time, utilizing the computation power of GPU.",
                "GPU": true,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": false
            }
        }
    },
    "operation_3196": {
        "Name": "Genotyping",
        "Count": 40,
        "Tools": {
            "ADDO": {
                "Name": "ADDO",
                "Description": "a comprehensive toolkit to detect, classify and visualise additive and non-additive Quantitative Trait Loci.\n\nWe developed ADDO, a highly-efficient tool designed to detect, classify and visualize quantitative trait loci (QTLs) with additive and non-additive effects. ADDO implements a mixed-model transformation to control for population structure and unequal relatedness that accounts for both additive and dominant genetic covariance among individuals, and decomposes single nucleotide polymorphism (SNP) effects into additive, partial dominance, dominance and overdominance categories. A matrix multiplication approach is used to accelerate the computation: a genome scan on 20 million markers from 836 individuals takes about 8.5 hours with 10 CPUs.\n\nAdditivity and dominance are the major genetic components underlying variations in complex traits",
                "GPU": false,
                "CPU": true,
                "ram": false,
                "parallel": false,
                "distributed": false
            },
            "BIRD": {
                "Name": "BIRD",
                "Description": "Bayesian Estimation of Genetic Regulatory Effects in High-throughput Reporter Assays | Bayesian Inference of Regulatory Differences | Photo by Bill Majoros. Used with permission | [6/16/2018] First version of BIRD released - The first version of BIRD has been released on GitHub at https://github.com/bmajoros/BIRD | [8/23/2018] Experiment design web tool released - A web tool is now available for power and sample size estimation: http://67.159.92.22:8080/ | BIRD (Bayesian Inference of Regulatory Differences) is a software suite for identifying regulatory variants in data from STARR-seq and other massively parallel reporter assays (MPRAs)",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "dbgenvoc": {
                "Name": "dbGENVOC",
                "Description": "dbGENVOC, a comprehensive, flexible database framework, developed with an aim to allow potential users to access, query, browse and download clinically relevant somatic and germline variation data from Indian oral cancer patients. This database will store variant calls from various studies that uses massively parallel sequencing to generate genome-scale data.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "deepvariant": {
                "Name": "DeepVariant",
                "Description": "DeepVariant is a deep learning-based variant caller that takes aligned reads (in BAM or CRAM format), produces pileup image tensors from them, classifies each tensor using a convolutional neural network, and finally reports the results in a standard VCF or gVCF file.",
                "GPU": false,
                "CPU": false,
                "ram": true,
                "parallel": false,
                "distributed": false
            },
            "delly2": {
                "Name": "Delly2",
                "Description": "Integrated structural variant prediction method that can discover, genotype and visualize deletions, tandem duplications, inversions and translocations at single-nucleotide resolution in short-read massively parallel sequencing data. It uses paired-ends and split-reads to sensitively and accurately delineate genomic rearrangements throughout the genome. Structural variants can be visualized using Delly-maze and Delly-suave.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "denovocnn": {
                "Name": "DeNovoCNN",
                "Description": "DeNovoCNN is a deep learning approach to call de novo mutations (DNMs) on whole-exome (WES) and whole-genome sequencing (WGS) data. DeNovoCNN uses trio recalibrated BAM/CRAM + VCF (or tab-separated list of variants) files to generate image-like genomic sequence representations and detect DNMs with high accuracy.",
                "GPU": false,
                "CPU": false,
                "ram": true,
                "parallel": false,
                "distributed": false
            },
            "easyparallel": {
                "Name": "EasyParallel",
                "Description": "EasyParallel is a free GUI cross-platform tool that utilizes a multi-thread parallel algorithm for processing multiple iterations of STRUCTURE and NEWHYBRIDS analyses.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "elssi": {
                "Name": "ELSSI",
                "Description": "Ensemble learning-based approach (ELSSI): parallel SNP-SNP interactions detection by ensemble multi-type detectors.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "ExpansionHunter_Denovo": {
                "Name": "ExpansionHunter Denovo",
                "Description": "A computational method for locating known and novel repeat expansions in short-read sequencing data.\n\nA suite of tools for detecting expansions of short tandem repeats.\n\nExpansionHunter Denovo (EHdn) is a suite of tools for detecting novel expansions of short tandem repeats (STRs). EHdn is intended for analysis of a collection of BAM/CRAM files containing alignments of short (100-200bp) reads.",
                "GPU": false,
                "CPU": false,
                "ram": true,
                "parallel": false,
                "distributed": false
            },
            "f5c": {
                "Name": "f5c",
                "Description": "GPU Accelerated Adaptive Banded Event Alignment for Rapid Comparative Nanopore Signal Analysis | Re-engineered and optimised Nanopolish call-methylation module (supports CUDA acceleration) | An optimised re-implementation of the call-methylation module in Nanopolish. Given a set of basecalled Nanopore reads and the raw signals, f5c detects the methylated cytosine bases. f5c can optionally utilise NVIDIA graphics cards for acceleration",
                "GPU": true,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": false
            },
            "FixVAF": {
                "Name": "FixVAF",
                "Description": "Correcting reference bias from the Illumina Isaac aligner enables analysis of cancer genomes.\n\nCode to remove bias from Isaac aligned data by clipping all reads for variant positions by 5 bases and producing a modified vcf file.\n\nSupport code for NGS copy number algorithms. Takes a file of locations and a [cr:b]am file and generates a count of coverage of each allele [ACGT] at that location (given any filter settings). Altered so that it clips all reads by n bases to reduce reference bias.\n\npython FixVaf.py [vcf file] [bam file] [fasta file].\n\nThe alleleCount package primarily exists to prevent code duplication between some other projects, specifically AscatNGS and Battenberg.\n\nRequires python 3 with psam installed.\n\nThe project previously contained 2 equivalent implementations of allele counting code in perl and C for BAM CRAM processing",
                "GPU": false,
                "CPU": false,
                "ram": true,
                "parallel": false,
                "distributed": false
            },
            "gbc": {
                "Name": "GBC",
                "Description": "Parallel toolkit based on highly addressable byte-encoding blocks for extremely large-scale genotypes of species.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "GenomeScope_2.0": {
                "Name": "GenomeScope 2.0",
                "Description": "Reference-free profiling of polyploid genomes | We have developed GenomeScope 2.0, which applies classical insights from combinatorial theory to establish a detailed mathematical model of how k-mer frequencies will be distributed in heterozygous and polyploid genomes | Average k-mer coverage for polyploid genome | Upload results from running Jellyfish or KMC",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            },
            "GWAS-Flow": {
                "Name": "GWAS-Flow",
                "Description": "A GPU accelerated framework for efficient permutation based genome-wide association studies | GPU accelerated GWAS framework based on TensorFlow | GWAS-Flow was written and published in the hope that you might find it useful. If you do and use it for your research please cite the paper published alongside the software, which is currently publicly accessible on the BiorXiv preprint server. https://www.biorxiv.org/content/10.1101/783100v1 doi: 10.1101/783100",
                "GPU": true,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": false
            },
            "HIrisPlex-S": {
                "Name": "HIrisPlex-S",
                "Description": "Massively parallel sequencing solutions for two common forensically used platforms | HIrisPlex-S Eye, Hair and Skin Colour DNA Phenotyping Webtool | 8px 9px 10px 11px 12px 13px 14px 15px 16px 17px 18px | With the advancement of DNA phenotyping as a tool in Forensic and Anthropological usage, we now provide an easy to use interactive website to predict eye, hair and skin colour from DNA using the IrisPlex, HIrisPlex and HIrisPlex-S systems",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "hpc-reditools": {
                "Name": "HPC-REDItools",
                "Description": "A Novel HPC-aware Tool for Improved Large Scale RNA-editing Analysis.\n\nREDItools2 is the optimized, parallel multi-node version of REDItools.\n\nREDItools takes in input a RNA-Seq (or DNA-Seq BAM) file and outputs a table of RNA-Seq editing events. Here is an example of REDItools's output:.\n\nThe following image explains the high-level architecture.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "ICGRM": {
                "Name": "ICGRM",
                "Description": "Integrative construction of genomic relationship matrix combining multiple genomic regions for big dataset.\n\nBACKGROUND:Genomic prediction is an advanced method for estimating genetic values, which has been widely accepted for genetic evaluation in animal and disease-risk prediction in human. It estimates genetic values with genome-wide distributed SNPs instead of pedigree. The key step of it is to construct genomic relationship matrix (GRM) via genome-wide SNPs; however, usually the calculation of GRM needs huge computer memory especially when the SNP number and sample size are big, so that sometimes it will become computationally prohibitive even for super computer clusters. We herein developed an integrative algorithm to compute GRM.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            },
            "igemrna": {
                "Name": "IgemRNA",
                "Description": "IgemRNA is an open access toolbox for transcriptome data statistical and biochemical network topology-based analysis. IgemRNA was developed in the MATLAB environment in order to take advantage of the up-to-date and most commonly distributed GSM modelling tool Cobra Toolbox 3.0 and spreadsheet file capabilities.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            },
            "ldkit": {
                "Name": "LDkit",
                "Description": "A parallel computing toolkit for linkage disequilibrium analysis.\n\nGUI package is under the GUI folder, please double-click the LDkit_GUI.jar to start.\n\nRun using Graphic User Interface (GUI).",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "liteqtl": {
                "Name": "LiteQTL",
                "Description": "LiteQTL is a package that runs whole genome QTL scans near real-time, utilizing the computation power of GPU.",
                "GPU": true,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": false
            },
            "MCSeEd": {
                "Name": "MCSeEd",
                "Description": "A reference-free, whole genome profiling system to address cytosine/adenine methylation changes.\n\nMethods for investigating DNA methylation nowadays either require a reference genome and high coverage, or investigate only CG methylation. Moreover, no large-scale analysis can be performed for N6-methyladenosine (6 mA) at an affordable price. Here we describe the methylation content sensitive enzyme double-digest restriction-site-associated DNA (ddRAD) technique (MCSeEd), a reduced-representation, reference-free, cost-effective approach for characterizing whole genome methylation patterns across different methylation contexts (e.g., CG, CHG, CHH, 6 mA). MCSeEd can also detect genetic variations among hundreds of samples. MCSeEd is based on parallel restrictions carried out by combinations of methylation insensitive and sensitive endonucleases, followed by next-generation sequencing.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "mucnv": {
                "Name": "muCNV",
                "Description": "muCNV is genotyping structural variants for population-level sequencingMulti-sample SV genotyper for large-scale WGS data. muCNV uses multiple steps for multi-sample SV genotyping, to handle large number of samples and to enable efficient parallelization:.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "MySeq": {
                "Name": "MySeq",
                "Description": "Privacy-protecting browser-based personal Genome analysis for genomics education and exploration.\n\nMySeq is a web-application for privacy-protecting interactive analysis of personal genomes (distributed as compressed-and-indexed VCF files) inspired by GENOtation (previously the Interpretome) and DNA.LAND Compass. MySeq is intended for use as a genomics educational platform.\n\nAnalyzing the PTC Tasting Phenotype with MySeq.\n\nThis page is an example analysis of the 'bitter tasting' trait using the MySeq application in an embedded context. Here MySeq is used to both query a whole genome VCF for NA12878 (from Genome in a Bottle) by genomic coordinates and predict the bitter tasting phenotype directly. All of the queries demonstrated here are performed 'live' in the browser, that is these are not pre-generated results. Try MySeq as a 'standalone' application.\n\nMySeq is a single-page web application for privacy-protecting personal genome analysis",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            },
            "ngs-primerplex": {
                "Name": "NGS-PrimerPlex",
                "Description": "High-throughput primer design for multiplex polymerase chain reactions.\n\nNGS-PrimerPlex is a high-throughput tool for mupltiplex primer design.\n\nIt includes four Python-scripts:.\n\nNGS-PrimerPlex can be run as a Docker image. In this way you only need to install Docker (for windows 7 users this install steps should be performed). If you have 'VD-x, VD-t error', you need to turn on virtualization in BIOS CPU section.",
                "GPU": false,
                "CPU": true,
                "ram": false,
                "parallel": false,
                "distributed": false
            },
            "nthits": {
                "Name": "ntHits",
                "Description": "De novo repeat identification of genomics data using a streaming approach.\n\nntHits is a method for identifying repeats in high-throughput DNA sequencing data.\n\nntHits uses OpenMP for parallelization, which requires a modern compiler such as GCC 4.2 or greater. If you have an older compiler, it is best to upgrade your compiler if possible. If you have multiple versions of GCC installed, you can specify a different compiler:.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "PaSGAL": {
                "Name": "PaSGAL",
                "Description": "PaSGAL (Parallel Sequence to Graph Aligner) is designed to accelerate local sequence alignment of sequences to directed acyclic sequence graphs (DAGs), e.g., variation graphs, splicing graphs.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "permgwas": {
                "Name": "permGWAS",
                "Description": "permGWAS is an open source software tool written in python to efficiently perform genome-wide association studies (GWAS) with permutation-based thresholds. permGWAS provides support for multiple CPUs as well as for GPUs.",
                "GPU": true,
                "CPU": true,
                "ram": false,
                "parallel": false,
                "distributed": false
            },
            "plexdb": {
                "Name": "PLEXdb",
                "Description": "Unified gene expression resource for plants and plant pathogens. It is a genotype to phenotype, hypothesis building information warehouse, leveraging highly parallel expression data with seamless portals to related genetic, physical, and pathway data.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "PRINCESS": {
                "Name": "PRINCESS",
                "Description": "Privacy-preserving international collaboration framework for analyzing rare disease genetic data that are distributed across different continents.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            },
            "quickbam": {
                "Name": "quickBAM",
                "Description": "Parallelized BAM file access API for high-throughput sequence analysis informatics.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "quickld": {
                "Name": "quickLD",
                "Description": "quickLD (qLD) is a tool to calculate Linkage disequilibrium (the non-random association between alleles at different loci), with highly efficient CPU and GPU kernels that utilize dense linear algebra (DLA) operations.",
                "GPU": true,
                "CPU": true,
                "ram": false,
                "parallel": false,
                "distributed": false
            },
            "RelocaTE2": {
                "Name": "RelocaTE2",
                "Description": "a high resolution transposable element insertion site mapping tool for population resequencing.\n\nThis tool is for mapping TEs from resequencing data: Stajich lab.\n\nRelocaTE2: a high resolution transposable element insertion sites mapping tool for population resequencing.\n\nRelocaTE2 is an improved version of RelocaTE (Robb et al., 2013). RelocaTE2 is highly sensitive and accurate in mapping transposable elements (TE) polymorphisms at single base pair resolution. RelocaTE2 uses the reads associated with TEs as seeds to cluster the read pairs on chromosomes. It automatically detects the target site duplication (TSD) of a TE insertion from alignments in each cluster, which enable high resolution mapping of TE polymorphisms. Unlike parallel searching of multi-TE elements in RelocaTE, RelocaTE2 searches all TEs in one cycle, which enables us find polymorphisms of thousands of TEs in an individual genome or large population in a reasonable timeframe without losing sensitivity and specificity",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "rmvp": {
                "Name": "rMVP",
                "Description": "A Memory-efficient, Visualization-enhanced, and Parallel-accelerated tool for Genome-Wide Association Study.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "rvpedigree": {
                "Name": "RVPedigree",
                "Description": "Family-based rare variant association tests for normally and non-normally distributed quantitative traits. Calculation of kinship matrices, various options for coping with non-normality, three different ways of estimating statistical significance incorporating triaging to enable efficient use of the most computationally-intensive calculations, and a parallelization option for genome-wide analysis.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": true
            },
            "scawmv": {
                "Name": "scAWMV",
                "Description": "An adaptively weighted multi-view learning framework for the integrative analysis of parallel scRNA-seq and scATAC-seq data.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "sceqtl": {
                "Name": "SCeQTL",
                "Description": "an R package for identifying eQTL from single-cell parallel sequencing data.\n\nSCeQTL is an R package that uses zero-inflated negative binomial regression to do eQTL analysis on single-cell data. It can distinguish two type of gene-expression differences among different genotype groups. It\u2019s more suitable to use SCeQTL to identify eQTLs from single-cell data. It can also be used for finding gene expression variations associated with other grouping factors like cell lineages. Following is the detail information and usage of this program. You can also found them in READ.ME. R Packages is a book based around this workflow.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "sideretro": {
                "Name": "sideRETRO",
                "Description": "a pipeline for identifying somatic and dimorphic insertions of processed pseudogenes or retrocopies.\n\nA pipeline for detecting Somatic Insertion of DE novo RETROcopies.\n\nsideRETRO is a bioinformatic tool devoted for the detection of somatic retrocopy insertion, also known as retroCNV, in whole genome and whole exome sequencing data (WGS, WES). The program has been written from scratch in C, and uses HTSlib and SQLite3 libraries, in order to manage SAM/BAM/CRAM reading and data analysis.",
                "GPU": false,
                "CPU": false,
                "ram": true,
                "parallel": false,
                "distributed": false
            },
            "somalier": {
                "Name": "somalier",
                "Description": "rapid relatedness estimation for cancer and germline studies using efficient genome sketches.\n\nfast sample-swap and relatedness checks on BAMs/CRAMs/VCFs/GVCFs.\n\nsomalier: extract informative sites, evaluate relatedness, and perform quality-control on BAM/CRAM/BCF/VCF/GVCF.\n\nNote that the somalier relate command runs extremely quickly (< 2 seconds for 600 samples and ~1 minute for 4,500 samples) so it's possible to add/remove samples or adjust a pedigree file and re-run iteratively",
                "GPU": false,
                "CPU": false,
                "ram": true,
                "parallel": false,
                "distributed": false
            },
            "tis": {
                "Name": "TIS",
                "Description": "Assessment of methods for Transposon Insertion Sequencing(TIS) analyses.\n\nThe TA are distributed relatively evenly along genome. The Mariner-based transposons can be inserted to impact statistically every gene, with in average more than 30 insertions site per kb. With the low insertion bias, it is easy to build saturated libraries. But local variations means less loci and less statistical power.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            },
            "wish-r": {
                "Name": "WISH-R",
                "Description": "WISH-R package (WISH-R) can calculate epistatic interactions using a linear or generalized linear model on a genome-wide level using genomic data and phenotype/disease data in a fully parallelized environment, and visualize genome-wide epistasis in many ways.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            }
        }
    },
    "operation_2478": {
        "Name": "Nucleic acid sequence analysis",
        "Count": 5,
        "Tools": {
            "affypara": {
                "Name": "affyPara",
                "Description": "The package contains parallelized functions for exploratory oligonucleotide array analysis. The package is designed for large numbers of microarray data.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "genogam": {
                "Name": "GenoGAM",
                "Description": "This package allows statistical analysis of genome-wide data with smooth functions using generalized additive models based on the implementation from the R-package 'mgcv'. It provides methods for the statistical analysis of ChIP-Seq data including inference of protein occupancy, and pointwise and region-wise differential analysis. Scaling of generalized additive model fitting to whole chromosomes is achieved by parallelization over overlapping genomic intervals.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "mosdepth": {
                "Name": "mosdepth",
                "Description": "Fast BAM/CRAM depth calculation for WGS, exome, or targeted sequencing.",
                "GPU": false,
                "CPU": false,
                "ram": true,
                "parallel": false,
                "distributed": false
            },
            "pboost": {
                "Name": "PBOOST",
                "Description": "GPU based tool for parallel permutation tests in genome-wide association studies.",
                "GPU": true,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "sprint": {
                "Name": "SPRINT",
                "Description": "A parallel framework for R. It provides an easy access to high performance computing for the analysis of high throughput post genomic data using the statistical programming language R.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            }
        }
    },
    "operation_2495": {
        "Name": "Expression analysis",
        "Count": 21,
        "Tools": {
            "affyparaebi": {
                "Name": "affyParaEBI",
                "Description": "Aan R based pipeline for parallel pre-processing of Affymetrix TM chips. The pipeline starts from a directory containing raw CEL files files and produces Bioconductor R objects containing gene expression measurements suitable for further analysis.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "AGS_ACN": {
                "Name": "AGS ACN",
                "Description": "> CORRECT NAME OF TOOL COULD ALSO BE 'ags.sh acn.sh tools', 'AGS', 'ACN' | Fast and accurate average genome size and 16S rRNA gene average copy number computation in metagenomic data | Here, we present the ags.sh and acn.sh tools dedicated to the computation of the Average Genome Size (AGS) and 16S rRNA gene Average Copy Number (ACN), respectively. The ags.sh and acn.sh tools compute these metagenomic traits based on the (ultra-fast) annotation of 35 universally distributed single-copy genes in unassembled metagenomic data | Pereira-Flores, E., Gl\u00f6ckner F. O., and Fernandez-Guerra A. Fast and accurate average genome size and 16S rRNA gene average copy number computation in metagenomic data. BMC Bioinformatics. 2019;20(1):453. doi:10.1186/s12859-019-3031-y",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            },
            "asterias": {
                "Name": "Asterias",
                "Description": "Set of tools for the analyses of high throughput genomic data that includes applications for microarray data normalization, filtering, detection of differential gene expression, class and survival prediction model building, and analysis of array CGH data. Most applications use parallel computing resulting in significant increases in speed.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "bigPint": {
                "Name": "bigPint",
                "Description": "Visualization methods for differential expression analysis | Methods for visualizing large multivariate datasets using static and interactive scatterplot matrices, parallel coordinate plots, volcano plots, and litre plots. Includes examples for visualizing RNA-sequencing datasets and differentially expressed genes | Big multivariate data plotted interactively | bigPint: Make BIG data pint-sized | Welcome to the bigPint package website! If you are a new user, please begin by reading from the Get Started tab at the top of this website. There are ten short vignette articles in that tab, and we recommend reading them in order. These short vignette articles consist of reproducible code that provide: | Alternatives to data metrics object | Clustering, DataImport, DifferentialExpression, GeneExpression, MultipleComparison, Normalization, Preprocessing, QualityControl, RNASeq, Sequencing, Software, Transcription, Visualization",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "EPA-ng": {
                "Name": "EPA-ng",
                "Description": "Complete reimplementation of the evolutionary placement algorithm (EPA) that is substantially faster, offers a distributed memory parallelization, and integrates concepts from both, RAxML-EPA and PPLACER.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": true
            },
            "FunGeCo": {
                "Name": "FunGeCo",
                "Description": "A web based tool for estimation of Functional potential of bacterial genomes and microbiomes using Gene Context information.\n\nFunctional potential of bacterial genomes and microbiomes from gene context information.\n\nThis feature allows the user to input a newly sequenced genome and annotate it using gene context based modules generated using extensive literature mining and manual curation. Users can also carry out comparative analysis (synteny view using parallel coordinates) of the uploaded genome with genomes already sequenced in NCBI using interactive visualizations.\n\nThis feature allows comparison of functional modules in sequenced genomes obtained from NCBI. Users can interactively select upto five genomes which are compared using a synteny based visualization (parallel coordinates) and circular genomic representations. Information about individual modules in all these genomes can also be viewed as tabular outputs",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "igemrna": {
                "Name": "IgemRNA",
                "Description": "IgemRNA is an open access toolbox for transcriptome data statistical and biochemical network topology-based analysis. IgemRNA was developed in the MATLAB environment in order to take advantage of the up-to-date and most commonly distributed GSM modelling tool Cobra Toolbox 3.0 and spreadsheet file capabilities.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            },
            "jind": {
                "Name": "JIND",
                "Description": "Joint Integration and Discrimination for Automated Single-Cell Annotation.\n\nJIND is a framework for automated cell-type identification based on neural networks. It directly learns a low-dimensional representation (latent code) inwhich cell-types can be reliably determined. To account for batch effects, JIND performs a novel asymmetric alignment in which the transcriptomic profileof unseen cells is mapped onto the previously learned latent space, hence avoiding the need of retraining the model whenever a new dataset becomes available. JIND also learns cell-type-specific confidence thresholds to identify and reject cells that cannot be reliably classified. We show on datasets with and without batch effects that JIND classifies cells more accurately than previously proposed methods while rejecting only a small proportion of cells. Moreover, JIND batch alignment is parallelizable, being more than five or six times faster than Seurat integration.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "MAP": {
                "Name": "MAP",
                "Description": "Model-based analysis of proteomic data to detect proteins with significant abundance changes.\n\nMAP (Model-based Analysis of Proteomic data), is designed to statistically compare the proteomic profiles generated from different biological samples using the isotope labeling based mass spectrometry (MS) technique and directly identify proteins with significant abundance changes. Unlike many existing tools for this purpose, it does not require parallel/additional technical replicates to fathom technical variations; instead, MAP uses a novel step-by-step regression analysis to directly model technical variations from the profiles under comparison. Therefore, experimental designs and their expenses can be simplified and reduced for more practices",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "mappertrac": {
                "Name": "MaPPeRTrac",
                "Description": "A Massively Parallel, Portable, and Reproducible Tractography Pipeline.\n\nMassively Parallel, Portable, and Reproducible Tractography (MaPPeRTrac) is a brain tractography workflow for high performance computing. It incorporates novel technologies to simplify and accelerate neuroimaging research.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "metalaffa": {
                "Name": "MetaLAFFA",
                "Description": "A flexible, end-to-end, distributed computing-compatible metagenomic functional annotation pipeline.\n\nMetaLAFFA is a flexible, end-to-end, and compute cluster-compatible metagenomic functional annotation pipeline.\nMetaLAFFA is a pipeline for annotating shotgun metagenomic data with abundances of functional orthology groups. This process consists of several steps to go from raw FASTQs (with sequencing adapters removed) to functional profiles:.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            },
            "MetaSpark": {
                "Name": "MetaSpark:",
                "Description": "Spark-based distributed processing tool to recruit metagenomic reads to reference genomes.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            },
            "mmcp-counter": {
                "Name": "mMCP-counter",
                "Description": "The murine Microenvironment Cell Population counter method to estimate abundance of tissue-infiltrating immune and stromal cell populations in murine samples using gene expression.\n\nMurine version of MCP-counter, a tool to estimate the immune and stromal composition of heterogeneous tissue, from transcriptomic data. It is distributed as a R package.\n\n.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            },
            "pageman": {
                "Name": "PageMan",
                "Description": "PageMan is a tool to get a quick overview of multiparallel experiments. PageMan also helps comparing experiments from different organisms.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "parasam": {
                "Name": "ParaSAM",
                "Description": "ParaSAM is a high performance parallel processing implementation of the SAM (Significance Analysis of Microarrays) algorithm. The permutations are divided across the multiple nodes. The computational workload is divided among multiple CPUs and the main memory of all participating computers is utilized to avoid caching operations to the disk, which significantly decrease algorithm execution time.",
                "GPU": false,
                "CPU": true,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "parbibit": {
                "Name": "ParBiBit",
                "Description": "Parallel tool to accelerate the search of biclusters on binary datasets, especially useful for gene expression data. This tool receives as input the expression values of n genes and m samples in a file with ARFF extension and returns a file with the biclustering information.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "plexdb": {
                "Name": "PLEXdb",
                "Description": "Unified gene expression resource for plants and plant pathogens. It is a genotype to phenotype, hypothesis building information warehouse, leveraging highly parallel expression data with seamless portals to related genetic, physical, and pathway data.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "sceqtl": {
                "Name": "SCeQTL",
                "Description": "an R package for identifying eQTL from single-cell parallel sequencing data.\n\nSCeQTL is an R package that uses zero-inflated negative binomial regression to do eQTL analysis on single-cell data. It can distinguish two type of gene-expression differences among different genotype groups. It\u2019s more suitable to use SCeQTL to identify eQTLs from single-cell data. It can also be used for finding gene expression variations associated with other grouping factors like cell lineages. Following is the detail information and usage of this program. You can also found them in READ.ME. R Packages is a book based around this workflow.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "soapmetas": {
                "Name": "SOAPMetaS",
                "Description": "Profiling large metagenome datasets efficiently on distributed clusters.\n\nAn Apache SparkTM based tool for profiling large metagenome datasets accurately on distributed cluster.\n\n'meph' mode reference (recommended for new microbe communities where MetaPhlAn2 is preferable).\n\n'comg' mode reference (recommended for new samples of known microbe communities which has known gene set).\n\nSOAPMetaS has been tested in the environments of local, Spark standalone cluster as well as YARN cluster. Users should download Spark and use spark-submit file to launch SOAPMetaS.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            },
            "sprint": {
                "Name": "SPRINT",
                "Description": "A parallel framework for R. It provides an easy access to high performance computing for the analysis of high throughput post genomic data using the statistical programming language R.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "xps": {
                "Name": "xps",
                "Description": "The package handles pre-processing, normalization, filtering and analysis of Affymetrix GeneChip expression arrays, including exon arrays, gene arrays and plate arrays on computers with 1 GB RAM only.",
                "GPU": false,
                "CPU": false,
                "ram": true,
                "parallel": false,
                "distributed": false
            }
        }
    },
    "operation_0310": {
        "Name": "Sequence assembly",
        "Count": 19,
        "Tools": {
            "AGS_ACN": {
                "Name": "AGS ACN",
                "Description": "> CORRECT NAME OF TOOL COULD ALSO BE 'ags.sh acn.sh tools', 'AGS', 'ACN' | Fast and accurate average genome size and 16S rRNA gene average copy number computation in metagenomic data | Here, we present the ags.sh and acn.sh tools dedicated to the computation of the Average Genome Size (AGS) and 16S rRNA gene Average Copy Number (ACN), respectively. The ags.sh and acn.sh tools compute these metagenomic traits based on the (ultra-fast) annotation of 35 universally distributed single-copy genes in unassembled metagenomic data | Pereira-Flores, E., Gl\u00f6ckner F. O., and Fernandez-Guerra A. Fast and accurate average genome size and 16S rRNA gene average copy number computation in metagenomic data. BMC Bioinformatics. 2019;20(1):453. doi:10.1186/s12859-019-3031-y",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            },
            "datma": {
                "Name": "DATMA",
                "Description": "DATMA (Distributed AuTomatic Metagenomic Assembly and annotation framework) is a distributed automatic pipeline for fast metagenomic analysis that includes: sequencing quality control, 16S-identification, reads binning, de novo assembly, ORF detection and taxonomic annotation.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            },
            "EPA-ng": {
                "Name": "EPA-ng",
                "Description": "Complete reimplementation of the evolutionary placement algorithm (EPA) that is substantially faster, offers a distributed memory parallelization, and integrates concepts from both, RAxML-EPA and PPLACER.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": true
            },
            "Flint": {
                "Name": "Flint",
                "Description": "Large scale microbiome profiling in the cloud | Main repository of the Flint project for Spark and Amazon EMR | This is the main repository of the Flint project for Amazon Web Services. Flint is a metagenomics profiling pipeline that is built on top of the Apache Spark framework, and is designed for fast real-time profiling of metagenomic samples against a large collection of reference genomes. Flint takes advantage of Spark's built-in parallelism and streaming engine architecture to quickly map reads against a large reference collection of bacterial genomes",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "gpgpufragfold": {
                "Name": "GPGPUFRAGFOLD",
                "Description": "GPUFRAGFOLD is a CUDA ACELERATED Protein Structure Prediction Tool.",
                "GPU": true,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": false
            },
            "grit": {
                "Name": "GRIT",
                "Description": "Tool for transcript discovery and quantification via the integrated analysis of CAGE, RAMPAGE, RNAseq, and poly(A)-seq data",
                "GPU": false,
                "CPU": false,
                "ram": true,
                "parallel": false,
                "distributed": false
            },
            "metacram": {
                "Name": "MetaCRAM",
                "Description": "Pipeline for taxonomy identification and lossless compression of FASTA-format metagenomic reads. \u00a0It integrates algorithms for taxonomy identification, read alignment, assembly, and finally, a reference-based compression method in a parallel manner.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "Metage2Metabo": {
                "Name": "Metage2Metabo",
                "Description": "metabolic complementarity applied to genomes of large-scale microbiotas for the identification of keystone species.\n\nFrom annotated genomes to metabolic screening in large scale microbiotas.\n\nMetage2metabo is a Python3 (Python >= 3.6) tool to perform graph-based metabolic analysis starting from annotated genomes (reference genomes or metagenome-assembled genomes). It uses Pathway Tools in a automatic and parallel way to reconstruct metabolic networks for a large number of genomes. The obtained metabolic networks are then analyzed individually and collectively in order to get the added value of metabolic cooperation in microbiota over individual metabolism and to identify and screen interesting organisms among all.\n\nm2m \u2014 metage2metabo documentation.\n\nFree document hosting provided by Read the Docs",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "metalaffa": {
                "Name": "MetaLAFFA",
                "Description": "A flexible, end-to-end, distributed computing-compatible metagenomic functional annotation pipeline.\n\nMetaLAFFA is a flexible, end-to-end, and compute cluster-compatible metagenomic functional annotation pipeline.\nMetaLAFFA is a pipeline for annotating shotgun metagenomic data with abundances of functional orthology groups. This process consists of several steps to go from raw FASTQs (with sequencing adapters removed) to functional profiles:.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            },
            "MetaSpark": {
                "Name": "MetaSpark:",
                "Description": "Spark-based distributed processing tool to recruit metagenomic reads to reference genomes.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            },
            "mp-nerf": {
                "Name": "MP-NeRF",
                "Description": "A Massively Parallel Method for Accelerating Protein Structure Reconstruction from Internal Coordinates.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "multinanopolish": {
                "Name": "MultiNanopolish",
                "Description": "Refined grouping method for reducing redundant calculations in nanopolish.\n\nNanopolish is a software package for signal-level analysis of Oxford Nanopore sequencing data. Nanopolish can calculate an improved consensus sequence for a draft genome assembly, detect base modifications, call SNPs and indels with respect to a reference genome and more (see Nanopolish for more details).\n\nWe present an efficient implementation of Nanopolish, called MultiNanopolish. MultiNanopolish use a different iterative calculation strategy to reduce redundant calculations. We propose an abstract concept, namely independent computing unit(GroupTask) which can be distributed to the thread pool for multi-thread concurrent computing.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            },
            "musket": {
                "Name": "Musket",
                "Description": "It is an efficient multistage k-mer based corrector for Illumina short read data. This corrector employs the k-mer spectrum approach and introduces three correction techniques in a multistage workflow. It is multi-threaded using a master-slave model and demonstrates superior parallel scalability compared to all other evaluated correctors as well as a highly competitive overall execution time.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "nubeam-dedup": {
                "Name": "Nubeam-dedup",
                "Description": "A fast and RAM-efficient tool to de-duplicate sequencing reads without mapping.\n\nnubeam-dedup is a fast and easy-to-use bioinformatics tool removing exact PCR duplicates for sequencing reads, single-end or paired-end. We appreciate your interest in nubeam-dedup. If you use nubeam-dedup, please kindly cite:.",
                "GPU": false,
                "CPU": false,
                "ram": true,
                "parallel": false,
                "distributed": false
            },
            "pasha": {
                "Name": "PASHA",
                "Description": "It is a parallel short read assembler for large genomes using de Bruijn graphs. Taking advantage of both shared-memory multi-core CPUs and distributed-memory compute clusters, it has demonstrated its potential to perform high-quality de-novo assembly of large genomes in reasonable time with modest computing resources.",
                "GPU": false,
                "CPU": true,
                "ram": false,
                "parallel": true,
                "distributed": true
            },
            "pts": {
                "Name": "PTS",
                "Description": "Small collection of programs concerned with parallel sequencing of multiple samples on the 454 platform. untag supports Parallel Tagged Sequencing by sorting sequences according to their tags and by removing those tags when producing output files (in FASTA or SFF format) for downstream processing with standard 454 or other assembly software.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "rampart": {
                "Name": "rampart",
                "Description": "A configurable workflow management system for de novo genome assembly, which helps the user identify combinations of third-party tools and settings that provide good results for their particular genome and sequenced reads. RAMPART is designed to exploit High performance computing environments, such as clusters and shared memory systems, where available.",
                "GPU": false,
                "CPU": false,
                "ram": true,
                "parallel": false,
                "distributed": false
            },
            "reframe": {
                "Name": "ReFRAME",
                "Description": "The ReFRAME library as a comprehensive drug repurposing library and its application to the treatment of cryptosporidiosis.\n\nReframeDB is an open and extendable drug repurposing database and screening set of 12,000 compounds.",
                "GPU": false,
                "CPU": false,
                "ram": true,
                "parallel": false,
                "distributed": false
            },
            "seqsphere": {
                "Name": "SeqSphere+",
                "Description": "This software is designed for distributed work-groups (client/server model) and allows automatic processing, assembling and analyzing NGS (e.g., Illumina, Ion Torrent or PacBio) and Sanger capillary-electrophoresis sequence data. It provides with an easy and automated microbial analysis; enabling your lab to employ whole genome microbial typing (cgMLST or MLST+), traditional MLST or eMLST/rMLST sequencing projects.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            }
        }
    },
    "operation_0362": {
        "Name": "Genome annotation",
        "Count": 9,
        "Tools": {
            "AGS_ACN": {
                "Name": "AGS ACN",
                "Description": "> CORRECT NAME OF TOOL COULD ALSO BE 'ags.sh acn.sh tools', 'AGS', 'ACN' | Fast and accurate average genome size and 16S rRNA gene average copy number computation in metagenomic data | Here, we present the ags.sh and acn.sh tools dedicated to the computation of the Average Genome Size (AGS) and 16S rRNA gene Average Copy Number (ACN), respectively. The ags.sh and acn.sh tools compute these metagenomic traits based on the (ultra-fast) annotation of 35 universally distributed single-copy genes in unassembled metagenomic data | Pereira-Flores, E., Gl\u00f6ckner F. O., and Fernandez-Guerra A. Fast and accurate average genome size and 16S rRNA gene average copy number computation in metagenomic data. BMC Bioinformatics. 2019;20(1):453. doi:10.1186/s12859-019-3031-y",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            },
            "cramdb": {
                "Name": "CRAMdb",
                "Description": "CRAMdb (a database for composition and roles of animal microbiome) is a comprehensive resource of curated and consistently annotated metagenomes for non-human animals",
                "GPU": false,
                "CPU": false,
                "ram": true,
                "parallel": false,
                "distributed": false
            },
            "datma": {
                "Name": "DATMA",
                "Description": "DATMA (Distributed AuTomatic Metagenomic Assembly and annotation framework) is a distributed automatic pipeline for fast metagenomic analysis that includes: sequencing quality control, 16S-identification, reads binning, de novo assembly, ORF detection and taxonomic annotation.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            },
            "EPA-ng": {
                "Name": "EPA-ng",
                "Description": "Complete reimplementation of the evolutionary placement algorithm (EPA) that is substantially faster, offers a distributed memory parallelization, and integrates concepts from both, RAxML-EPA and PPLACER.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": true
            },
            "FunGeCo": {
                "Name": "FunGeCo",
                "Description": "A web based tool for estimation of Functional potential of bacterial genomes and microbiomes using Gene Context information.\n\nFunctional potential of bacterial genomes and microbiomes from gene context information.\n\nThis feature allows the user to input a newly sequenced genome and annotate it using gene context based modules generated using extensive literature mining and manual curation. Users can also carry out comparative analysis (synteny view using parallel coordinates) of the uploaded genome with genomes already sequenced in NCBI using interactive visualizations.\n\nThis feature allows comparison of functional modules in sequenced genomes obtained from NCBI. Users can interactively select upto five genomes which are compared using a synteny based visualization (parallel coordinates) and circular genomic representations. Information about individual modules in all these genomes can also be viewed as tabular outputs",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "malacoda": {
                "Name": "malacoda",
                "Description": "Bayesian modelling of high-throughput sequencing assays with malacoda.\n\nThe goal of malacoda is to enable Bayesian analysis of high-throughput genomic assays like massively parallel reporter assays (MPRA) and CRISPR screens.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "Metage2Metabo": {
                "Name": "Metage2Metabo",
                "Description": "metabolic complementarity applied to genomes of large-scale microbiotas for the identification of keystone species.\n\nFrom annotated genomes to metabolic screening in large scale microbiotas.\n\nMetage2metabo is a Python3 (Python >= 3.6) tool to perform graph-based metabolic analysis starting from annotated genomes (reference genomes or metagenome-assembled genomes). It uses Pathway Tools in a automatic and parallel way to reconstruct metabolic networks for a large number of genomes. The obtained metabolic networks are then analyzed individually and collectively in order to get the added value of metabolic cooperation in microbiota over individual metabolism and to identify and screen interesting organisms among all.\n\nm2m \u2014 metage2metabo documentation.\n\nFree document hosting provided by Read the Docs",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "metalaffa": {
                "Name": "MetaLAFFA",
                "Description": "A flexible, end-to-end, distributed computing-compatible metagenomic functional annotation pipeline.\n\nMetaLAFFA is a flexible, end-to-end, and compute cluster-compatible metagenomic functional annotation pipeline.\nMetaLAFFA is a pipeline for annotating shotgun metagenomic data with abundances of functional orthology groups. This process consists of several steps to go from raw FASTQs (with sequencing adapters removed) to functional profiles:.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            },
            "MetaSanity": {
                "Name": "MetaSanity",
                "Description": "An integrated, customizable microbial genome evaluation and annotation pipeline.\n\nPipeline for major biological analyses.\n\nMetaSanity v1.1.1 - 2020 version.\n\nMetaSanity v1.1.1 provides a unified workflow for genome assessment and functional annotation that combines all outputs into a single queryable database \u2013 all within an easily distributed Docker image",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            }
        }
    },
    "operation_2422": {
        "Name": "Data retrieval",
        "Count": 25,
        "Tools": {
            "ahoj": {
                "Name": "AHoJ: Apo Holo Protein Search",
                "Description": "Webserver & command-line tool for search and alignment of APO (unbound) protein structures from HOLO (bound) forms and vice versa. Features: customizable search of Apo-Holo pairs in the PDB, alignment to the query structure, batch mode for fast parallel dataset processing, visualization via Molstar and PyMol, public documented REST-API.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "cogstack": {
                "Name": "CogStack",
                "Description": "Experiences of deploying integrated information retrieval and extraction services in a large National Health Service Foundation Trust hospital.\n\nCogStack is a lightweight distributed, fault tolerant database processing architecture and ecosystem, intended to make NLP processing and preprocessing easier in resource constrained environments.\n\nCogStack is a lightweight distributed, fault tolerant database processing architecture, intended to make NLP processing and preprocessing easier in resource constained environments.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            },
            "dasmiweb": {
                "Name": "DASMIweb",
                "Description": "Server that allows integration, analysis and quantitative assessment of distributed sources of protein and domain interactions. Users can query numerous sources simultaneously, which can then be configured and can support incorporation of user data.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            },
            "DDVFA": {
                "Name": "DDVFA",
                "Description": "Distributed dual vigilance fuzzy adaptive resonance theory learns online, retrieves arbitrarily-shaped clusters, and mitigates order dependence. Dual Vigilance Fuzzy ART - Companion MATLAB Code. Distributed Dual Vigilance Fuzzy ART - Companion MATLAB Code.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            },
            "deep-framework": {
                "Name": "Deep-Framework",
                "Description": "A Distributed, Scalable, and Edge-Oriented Framework for Real-Time Analysis of Video Streams.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            },
            "diamin": {
                "Name": "DIAMIN",
                "Description": "DIAMIN is a high-level software library to facilitate the development of distributed applications for the efficient analysis of large-scale molecular interaction networks.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            },
            "eccparacorp": {
                "Name": "ECCParaCorp",
                "Description": "English-Chinese Cancer Parallel Corpus (ECParaCorp) is a database involving information of 6 cancers in three different themes: cancer prevention, cancer screening and cancer treatment.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "GET-IT": {
                "Name": "GET-IT",
                "Description": "Exploiting observations and measurement data standard for distributed LTER-Italy freshwater sites. Water quality issues.\n\nGeoinformation Enabling ToolkIT starterkit.\n\nGeoinformation Enabling ToolkIT starterkit &REG;.\n\nGET-IT allows you to easily share geospatial data on the web with simple actions.\n\nShare your maps, measurements, and sensors.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            },
            "kmerkeys": {
                "Name": "KmerKeys",
                "Description": "KmerKeys is a web resource for searching indexed genome assemblies and variants. It provides performant, rapid query speeds for cloud computation on genome assemblies. It enable fuzzy as well as exact k-mer-based searches of assemblies. To enable robust and speedy performance, the website implements cache-friendly hash tables, memory mapping and massive parallel processing. Our method employs a scalable and efficient data structure that can be used to jointly index and search a large collection of human genome assembly information. One can include variant databases and their associated metadata such as the gnomAD population variant catalog. This feature enables the incorporation of future genomic information into sequencing analysis.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "MaveDB": {
                "Name": "MaveDB",
                "Description": "An open-source platform to distribute and interpret data from multiplexed assays of variant effect.\n\nTable of Multiplexed Assay of Variant Effect (MAVE) studies.\n\nMaveDB - A repository for MAVE assay datasets.\n\nTo cite this document, please use the citation details for MaveDB.\n\nMaveDB is a public repository for datasets from Multiplexed Assays of Variant Effect (MAVEs), such as those generated by deep mutational scanning (DMS) or massively parallel reporter assay (MPRA) experiments.\n\nWelcome to our table of Multiplexed Assay of Variant Effect (MAVE) studies. To contribute a study or amend/expand an existing entry, please use the GitHub issue tracker or create a pull request",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "MetaSanity": {
                "Name": "MetaSanity",
                "Description": "An integrated, customizable microbial genome evaluation and annotation pipeline.\n\nPipeline for major biological analyses.\n\nMetaSanity v1.1.1 - 2020 version.\n\nMetaSanity v1.1.1 provides a unified workflow for genome assessment and functional annotation that combines all outputs into a single queryable database \u2013 all within an easily distributed Docker image",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            },
            "microbench": {
                "Name": "Microbench",
                "Description": "Microbench is a small Python package for benchmarking Python functions, and optionally capturing extra runtime/environment information. It is most useful in clustered/distributed environments, where the same function runs under different environments, and is designed to be extensible with new functionality. In addition to benchmarking, this can help reproducibility by e.g. logging the versions of key Python packages, or even all packages loaded into the global environment. Other captured metadata can include CPU and RAM usage, environment variables, and hardware specifications.",
                "GPU": false,
                "CPU": true,
                "ram": true,
                "parallel": false,
                "distributed": true
            },
            "ogda": {
                "Name": "OGDA",
                "Description": "A comprehensive organelle genomes database for algae cpDNA and mtDNA.\n\nAlgae is the earliest evolutionary biological group on the earth, are thought to have appeared at least 2.6 billion years ago. As the most complex biological group, algae have shown the high diversity during the long evolutionary history. Algae are widely distributed in 4 kingdoms of the Eukaryota, including the Plantae, Protozoa, Acritarcha, Chromista and Fungi. Up to now, there are 46,177 species of eukaryotic algae have been recognized and classified (AlgaeBase, 2020), but in fact, more species need the further confirmation.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            },
            "omicsdi": {
                "Name": "omicsDI",
                "Description": "Provides dataset discovery across a heterogeneous, distributed group of Transcriptomics, Genomics, Proteomics and Metabolomics data resources.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            },
            "permgwas": {
                "Name": "permGWAS",
                "Description": "permGWAS is an open source software tool written in python to efficiently perform genome-wide association studies (GWAS) with permutation-based thresholds. permGWAS provides support for multiple CPUs as well as for GPUs.",
                "GPU": true,
                "CPU": true,
                "ram": false,
                "parallel": false,
                "distributed": false
            },
            "Phen2Gene": {
                "Name": "Phen2Gene",
                "Description": "Phen2Gene is a phenotype-driven gene prioritization tool, that takes HPO (Human Phenotype Ontology) IDs as inputs, searches and prioritizes candidate causal disease genes. It is distributed under the MIT License by Wang Genomics Lab. Additionally, we have provided a web server and an associated RESTful API service for running Phen2Gene. Finally, a mobile app for Phen2Gene and several other genetic diagnostic tools from our lab is being tested and will be available soon.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            },
            "rdad": {
                "Name": "RDAD",
                "Description": "A Machine Learning System to Support Phenotype-Based Rare Disease Diagnosis.\n\nDNA sequencing has allowed for the discovery of the genetic cause for a considerable number of diseases, paving the way for new disease diagnostics. However, due to the lack of clinical samples and records, the molecular cause for rare diseases is always hard to identify, significantly limiting the number of rare Mendelian diseases diagnosed through sequencing technologies. Clinical phenotype information therefore becomes a major resource to diagnose rare diseases. In this article, we adopted both a phenotypic similarity method and a machine learning method to build four diagnostic models to support rare disease diagnosis. All the diagnostic models were validated using the real medical records from RAMEDIS",
                "GPU": false,
                "CPU": false,
                "ram": true,
                "parallel": false,
                "distributed": false
            },
            "reindeer": {
                "Name": "REINDEER",
                "Description": "efficient indexing of k-mer presence and abundance in sequencing datasets.\n\nREINDEER builds a data-structure that indexes k-mers and their abundances in a collection of datasets (raw RNA-seq or metagenomic reads for instance). Then, a sequence (FASTA) can be queried for its presence and abundance in each indexed dataset. While other tools (e.g. SBT, BIGSI) were also designed for large-scale k-mer presence/absence queries, retrieving abundances was so far unsupported (except for single datasets, e.g. using some k-mer counters like KMC, Jellyfish). REINDEER combines fast queries, small index size, and low memory footprint during indexing and queries. We showed it allows to index 2585 RNA-seq datasets (~4 billions k-mers) using less than 60GB of RAM and a final index size lower than 60GB on the disk. Then, a REINDEER index can either be queried on disk (experimental feature, low RAM usage) or be loaded in RAM for faster queries.",
                "GPU": false,
                "CPU": false,
                "ram": true,
                "parallel": false,
                "distributed": false
            },
            "schema-health": {
                "Name": "schema",
                "Description": "an open-source, distributed mobile platform for deploying mHealth research tools and interventions.\n\nschema is a cross-platform mobile application for deploying mHealth monitoring and intervention studies.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            },
            "SciApps": {
                "Name": "SciApps",
                "Description": "A Cloud-Based Platform for Analyses and Distribution of the MaizeCODE data.\n\nMaizeCODE is a project aimed at identifying and analyzing functional elements in the maize genome. In its initial phase, MaizeCODE assayed up to five tissues from four maize strains (B73, NC350, W22, TIL11) by RNA-Seq, Chip-Seq, RAMPAGE, and small RNA sequencing. To facilitate reproducible science and provide both human and machine access to the MaizeCODE data, we developed SciApps, a cloud-based portal, for analysis and distribution of both raw data and analysis results. Based on the SciApps workflow platform, we generated new components to support the complete cycle of the MaizeCODE data management",
                "GPU": false,
                "CPU": false,
                "ram": true,
                "parallel": false,
                "distributed": false
            },
            "sv-plaudit": {
                "Name": "SV-plaudit",
                "Description": "A cloud-based framework for manually curating thousands of structural variants.\n\nSV-plaudit: A cloud-assisted framework manually curating thousands of structural variants.\n\nSV-plaudit provides a pipeline for creating image views of genomic intervals, automatically storing them in the cloud, deploying a website to view/score them, and retrieving scores for analysis. SV-plaudit supports image generation sequencing data from BAM or CRAM files from Illumina paired-end sequencing, PacBio or Oxford Nanopore Technologies long-read sequencing, or 10X Genomics linked-read sequencing.\n\nSource code and documentation:https://github.com/jbelyeu/SV-plaudit.",
                "GPU": false,
                "CPU": false,
                "ram": true,
                "parallel": false,
                "distributed": false
            },
            "tensorpac": {
                "Name": "Tensorpac",
                "Description": "Tensorpac is an Python open-source toolbox for computing Phase-Amplitude Coupling (PAC) using tensors and parallel computing for an efficient, and highly flexible modular implementation of PAC metrics both known and novel. Check out our documentation for details.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "vkcdb": {
                "Name": "VKCDB",
                "Description": "The Voltage-gated K(+) Channel DataBase contains full-length or nearly full-length unique channel sequences from Bacteria, Archaea and Eukaryotes. Corresponding nucleotide sequences of the open reading frames corresponding to the amino acid sequences are now available and can be extracted in parallel with sets of protein sequences. Channels are categorized into subfamilies by phylogenetic analysis and by using hidden Markov model analyses.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "watchdog": {
                "Name": "Watchdog",
                "Description": "Workflow management system for the automated and distributed analysis of large-scale experimental data",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            },
            "yabi": {
                "Name": "Yabi",
                "Description": "It is an open source software system which provides an analysis workflow environment that can create and reuse workflows as well as manage large amounts of both raw and processed data in a secure and flexible way across geographically distributed compute resources. It can be used via a web-based environment to drag-and-drop tools to create sophisticated workflows.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            }
        }
    },
    "operation_0417": {
        "Name": "PTM site prediction",
        "Count": 1,
        "Tools": {
            "AIKYATAN": {
                "Name": "AIKYATAN",
                "Description": "mapping distal regulatory elements using convolutional learning on GPU.\n\nBACKGROUND:The data deluge can leverage sophisticated ML techniques for functionally annotating the regulatory non-coding genome. The challenge lies in selecting the appropriate classifier for the specific functional annotation problem, within the bounds of the hardware constraints and the model's complexity. In our system AIKYATAN, we annotate distal epigenomic regulatory sites, e.g., enhancers. Specifically, we develop a binary classifier that classifies genome sequences as distal regulatory regions or not, given their histone modifications' combinatorial signatures. This problem is challenging because the regulatory regions are distal to the genes, with diverse signatures across classes (e.g., enhancers and insulators) and even within each class (e.g., different enhancer sub-classes)",
                "GPU": true,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": false
            }
        }
    },
    "operation_0438": {
        "Name": "Transcriptional regulatory element prediction",
        "Count": 5,
        "Tools": {
            "AIKYATAN": {
                "Name": "AIKYATAN",
                "Description": "mapping distal regulatory elements using convolutional learning on GPU.\n\nBACKGROUND:The data deluge can leverage sophisticated ML techniques for functionally annotating the regulatory non-coding genome. The challenge lies in selecting the appropriate classifier for the specific functional annotation problem, within the bounds of the hardware constraints and the model's complexity. In our system AIKYATAN, we annotate distal epigenomic regulatory sites, e.g., enhancers. Specifically, we develop a binary classifier that classifies genome sequences as distal regulatory regions or not, given their histone modifications' combinatorial signatures. This problem is challenging because the regulatory regions are distal to the genes, with diverse signatures across classes (e.g., enhancers and insulators) and even within each class (e.g., different enhancer sub-classes)",
                "GPU": true,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": false
            },
            "gcup": {
                "Name": "gCUP",
                "Description": "Rapid GPU-based HIV-1 coreceptor usage prediction for next-generation sequencing.",
                "GPU": true,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": false
            },
            "MPRAnator": {
                "Name": "MPRAnator",
                "Description": "Web-based tool for the design of massively parallel reporter assay experiments.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "silencerdb": {
                "Name": "SilencerDB",
                "Description": "a comprehensive database of silencers.\n\nA deep convolutional neural network for the accurate prediction of silencers.\n\nSilencers, which were first identified around 30 years ago as sequence-specific elements that induce negative effect on the transcription of particular genes, have started to receive growing attention. To facilitate the studies of silencers and their potential roles in transcriptional control during normal development and disease, we developed this comprehensive database of silencers, SilencerDB.\n\nFor accurate classification of silencers, we propose a CNN-based model named DeepSilencer.\n\n$ pip install tensorflow-gpu==1.15.2 #pip install tensorflow==1.15.2.",
                "GPU": true,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": false
            },
            "tipr": {
                "Name": "TIPR",
                "Description": "A sequence-based machine learning model that identifies TSSs with high accuracy and resolution for multiple spatial distribution patterns along the genome, including broadly distributed TSS patterns that have previously been difficult to characterize.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            }
        }
    },
    "operation_3443": {
        "Name": "Image analysis",
        "Count": 22,
        "Tools": {
            "AIKYATAN": {
                "Name": "AIKYATAN",
                "Description": "mapping distal regulatory elements using convolutional learning on GPU.\n\nBACKGROUND:The data deluge can leverage sophisticated ML techniques for functionally annotating the regulatory non-coding genome. The challenge lies in selecting the appropriate classifier for the specific functional annotation problem, within the bounds of the hardware constraints and the model's complexity. In our system AIKYATAN, we annotate distal epigenomic regulatory sites, e.g., enhancers. Specifically, we develop a binary classifier that classifies genome sequences as distal regulatory regions or not, given their histone modifications' combinatorial signatures. This problem is challenging because the regulatory regions are distal to the genes, with diverse signatures across classes (e.g., enhancers and insulators) and even within each class (e.g., different enhancer sub-classes)",
                "GPU": true,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": false
            },
            "aradeepopsis": {
                "Name": "ARADEEPOPSIS",
                "Description": "ARADEEPOPSIS is a software tool that enables plant researchers to non-invasively score plant growth, biomass accumulation and senescence from image data in a highly parallelized, high throughput, yet easy to use manner.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "autodeconj": {
                "Name": "AutoDeconJ",
                "Description": "A GPU-accelerated ImageJ plugin for 3D light-field deconvolution with optimal iteration numbers predicting.",
                "GPU": true,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": false
            },
            "CLIJ": {
                "Name": "CLIJ",
                "Description": "GPU-accelerated image processing for everyone.\n\nCLIJ is an OpenCL - ImageJ bridge and a Fiji plugin allowing users with entry-level skills in programming to build GPU-accelerated workflows to speed up their image processing. Increased efforts were put on documentation, code examples, interoperability, and extensibility. CLIJ is based on ClearCL, JOCL, Imglib2, ImageJ and SciJava",
                "GPU": true,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": false
            },
            "clij-assistant": {
                "Name": "CLIJ-assistant",
                "Description": "CLIJx-Assistant is an intuitive user interface for building custom GPU-accelerated image processing workflows using CLIJ2 in Fiji. It visualizes workflows as image date flow graphs while building them. It suggests what to do next and generates scripts and human readable protocols to facilitate reproducible bio-image analysis.",
                "GPU": true,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": false
            },
            "covidmulti-net": {
                "Name": "CovidMulti-Net",
                "Description": "CovidMulti-Net is a parallel-dilated multi-scale feature fusion architecture for the identification of COVID-19 cases from chest X-ray Images.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "ct-projection-simulator": {
                "Name": "CT Projection Simulator",
                "Description": "CT Projection Simulator computes the parallel beam 2D projections of an object specified as a set of geometric shapes.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "dax": {
                "Name": "DAX",
                "Description": "Distributed automation for XNAT toolkit (DAX) provides large-scale image storage and analysis pipelines with an optimized job management tool for neuroimaging data",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            },
            "ddecon": {
                "Name": "DDecon",
                "Description": "DDecon is an ImageJ plug-in that provides a GUI for super-resolution measurement of thin filament lengths by applying distributed deconvolution analysis to periodic line scans collected from fluorescence images.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            },
            "denoisem": {
                "Name": "DenoisEM",
                "Description": "An interactive ImageJ plugin for semi-automated image denoising in electron microscopy.\n\nDenoisEM offers several state-of-the-art denoising and deconvolution algorithms such as non-local means, BLS-GSM, Tikhonov deconvolution, etc.\n\nFast and advanced image denoising of large-scale 3D electron microscopy data.\n\nDenoisEM is developed by the TELIN department at Ghent University and the Bio Informatics Core at VIB . The GPU backbone is driven by Quasar , an in-house programming language of the TELIN department.\n\nApache/2.4.7 (Ubuntu) Server at bioimagingcore.be Port 443.",
                "GPU": true,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": false
            },
            "fret-ibra": {
                "Name": "FRET-IBRA",
                "Description": "FRET - IBRA is a fully parallelized toolkit to process fluorescence resonance energy transfer (FRET) intensity data to produce ratiometric images with low measurement bias.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "grasviq": {
                "Name": "grasviq",
                "Description": "Grass Vein Image Quantification (GrasVIQ) is an image analysis framework for automatic quantification of veins in grass leaves. Designed specifically for parallel venation, GrasVIQ automatically segments veins from images of cleared grass leaves using thresholding and edge detection techniques. Veins are quantified and classified into orders, and spatial parameters, such as vein width and interveinal distance, are calculated automatically. For more details, please see.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "igneous": {
                "Name": "Igneous",
                "Description": "Distributed dense 3D segmentation meshing, neuron skeletonization, and hierarchical downsampling.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            },
            "mri-image-snr-computer": {
                "Name": "MRI parallel image SNR Computer",
                "Description": "Compute SNR for MRI parallel images using different reconstruction methods. There are three methods we used here to compute the SNR of MR images: ACR, SoS, and OPT.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "prismatic": {
                "Name": "Prismatic",
                "Description": "CPU/GPU software for fast simulation of Scanning Transmission Electron Microscopy (STEM) experiments.",
                "GPU": true,
                "CPU": true,
                "ram": false,
                "parallel": false,
                "distributed": false
            },
            "raagr2-net": {
                "Name": "RAAGR2-Net",
                "Description": "A brain tumor segmentation network using parallel processing of multiple spatial frames.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "recoittv": {
                "Name": "RecoItTV",
                "Description": "It's an accelerated implementation of an iterative method for CBCT following the Split Bregman formulation, which reduces computational time through GPU-accelerated kernels. The implementation enables the reconstruction of large volumes (>10243 pixels) using partitioning strategies in forward- and back-projection operations.",
                "GPU": true,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": false
            },
            "sepca": {
                "Name": "sePCA",
                "Description": "Rotationally Invariant Exponential Family PCA.\n\nIn photon-limited imaging, the pixel intensities are affected by photon count noise. Many applications require an accurate estimation of the covariance of the underlying 2-D clean images. For example, in X-ray free electron laser (XFEL) single molecule imaging, the covariance matrix of 2-D diffraction images is used to reconstruct the 3-D molecular structure. Accurate estimation of the covariance from low-photon-count images must take into account that pixel intensities are Poisson distributed, hence the classical sample covariance estimator is highly biased. Moreover, in single molecule imaging, including in-plane rotated copies of all images could further improve the accuracy of covariance estimation. In this paper we introduce an efficient and accurate algorithm for covariance matrix estimation of count noise 2-D images, including their uniform planar rotations and possibly reflections",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            },
            "SIIM": {
                "Name": "SIIM",
                "Description": "SIIM is a professional organization at the nexus of medical imaging informatics and healthcare technologies. \nSIIM provides an unparalleled opportunity to not only hear from the best, brightest and most forward thinkers in imaging space but talk to them face to face in a collegial setting.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "simpli": {
                "Name": "SIMPLI",
                "Description": "A SIMPLI (Single-cell Identification from MultiPLexed Images) approach for spatially resolved tissue phenotyping at single-cell resolution. SIMPLI is a platform agnostic pipeline for the analysis of highly multiplexed histological imaging data.\n\nThis will run SIMPLI on minimal example dataset distributed in this repository. For more details on the example dataset and the associated analysis workflow see the example-workflow page.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            },
            "skeleton3d": {
                "Name": "Skeleton3D",
                "Description": "Calculates the 3D skeleton of an arbitrary binary volume using parallel medial axis thinning.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "virtual_imaging_platform": {
                "Name": "Virtual Imaging Platform",
                "Description": "VIP is a web portal for medical imaging applications. It allows users to access scientific applications as a service (directly through the web browser with no installation required), as well as distributed computing resources in a transparent manner. It exploits the resources available in the biomed virtual organization of the EGI e-infrastructure to offer an open service to researchers worldwide.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            }
        }
    },
    "operation_2476": {
        "Name": "Molecular dynamics",
        "Count": 18,
        "Tools": {
            "ambergpumdsimulation": {
                "Name": "AmberGPUMDSimulation",
                "Description": "An automated workflow tool for Kepler to perform AMBER GPU molecular dynamics simulations.",
                "GPU": true,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": false
            },
            "ddcmd": {
                "Name": "ddcMD",
                "Description": "ddcMD is a fully GPU-accelerated molecular dynamics program for the Martini force field.\nddcMDconverter should be used to convert GROMACS inputs to ddcMD inputs",
                "GPU": true,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": false
            },
            "desmond": {
                "Name": "Desmond",
                "Description": "Desmond is a software package developed at D. E. Shaw Research to perform high-speed molecular dynamics simulations of biological systems on conventional commodity clusters. The code uses novel parallel algorithms and numerical techniques to achieve high performance and accuracy on platforms containing a large number of processors, but may also be executed on a single computer.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "easyamber": {
                "Name": "easyAmber",
                "Description": "EasyAmber is a comprehensive toolbox to automate the molecular dynamics simulation of proteins. EasyAmber is a set of wrapper scripts to automate the molecular dynamics routines implemented in the Amber package. The toolbox can address a wide set of tasks in computational biology struggling to account for protein flexibility, and supports the full-atom model building, optimization/equilibration of the molecular system, classical/conventional and accelerated molecular dynamics simulations. The easyAmber software takes the molecular dynamics to the next level in terms of usability for complex processing of large volumes of data. It implements advanced MD protocols, but is highly automated and easy-to-operate to attract a broad audience. The toolbox can be used on a personal desktop station equipped with a gaming GPU-accelerator, as well as help to manage huge workloads on a powerful supercomputer.",
                "GPU": true,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": false
            },
            "ego_viii": {
                "Name": "EGO VIII",
                "Description": "EGO is a program to perform molecular dynamics simulations on parallel as well as on sequential computers. Supported parallel machines include the Hitachi SR8000, CRAY-T3E, IBM-SP2, Fujitsu VPP700, Parsytec-CC under PARIX and inhomogeneous clusters of UNIX workstations under PVM or MPI.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "HPCCS": {
                "Name": "HPCCS",
                "Description": "Collision Cross Section Calculations Using HPCCS.\n\nThe High Performance Collision Cross Section (HPCCS) is a new software for fast and accurate calculation of CCS for molecular ions. Based on the Trajectory Method (TM), HPCCS was parallelized and optimized to be an user-friendly program.\n\nHigh Performance Collision Cross Section Calculation \u2013 HPCCS",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "mdscan_CLI": {
                "Name": "MDSCAN",
                "Description": "MDSCAN is a Python command-line interface (CLI) conceived to speed up and significantly lower the RAM memory needs of the HDBSCAN clustering of long Molecular Dynamics.",
                "GPU": false,
                "CPU": false,
                "ram": true,
                "parallel": false,
                "distributed": false
            },
            "mp-nerf": {
                "Name": "MP-NeRF",
                "Description": "A Massively Parallel Method for Accelerating Protein Structure Reconstruction from Internal Coordinates.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "NUFEB": {
                "Name": "NUFEB",
                "Description": "Massively Parallel Simulator for Individual-based Modelling of Microbial Communities.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "openmdlr": {
                "Name": "OpenMDlr",
                "Description": "Parallel, open-source tools for general protein structure modeling and refinement from pairwise distances.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "primordia": {
                "Name": "PRIMoRDiA",
                "Description": "A Software to Explore Reactivity and Electronic Structure in Large Biomolecules.\n\nPRIMoRDiA ( PRIMoRDiA Macromolecular Reactivity Descriptors Access ) is a shared memory parallel software written in C++ for post electronic structure calculations, that efficiently reads output files from most used quantum mechanics packages, storing molecular information and processing it to generate several descriptors to evaluate the global and local reactivity of molecular systems. PRIMoRDiA supports the main reactivity descriptors of the Conceptual Density Functional Theory, the most famous and used reactivity theory, which works from response variables of the electronic structure of the molecules, as also other electrostatics properties.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "prosettac": {
                "Name": "PRosettaC",
                "Description": "Rosetta Based Modeling of PROTAC Mediated Ternary Complexes.\n\nInstallation requirements for PRosettaC:.\n\nPRosettaC is a computational protocol for the prediction of PROTAC-induced ternary complexes. It was benchmarked against ten available ternary complex crystal structures, and was able to predict six of them to atomic accuracy in one of the top three clusters.\n\nThe protocol receives as input, two protein structures (protein target and E3 ligase), including their appropriate ligands (binders), as well as the PROTAC chemical structure in a SMILES representation, and outputs predicted models for the ternary complex.\n\nto /etc/pbs.conf (on all cluster nodes). Another option is to write this line to a file, e.g. env.txt, and then set the enrionment parameter SCHEDULER_PARAMS=/Path_to_env.txt before starting PRosettaC (see below 'Additional parameters').",
                "GPU": false,
                "CPU": false,
                "ram": true,
                "parallel": false,
                "distributed": false
            },
            "pteros": {
                "Name": "Pteros",
                "Description": "Fast parallel molecular analysis library.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "pyspawn": {
                "Name": "PySpawn",
                "Description": "Software for Nonadiabatic Quantum Molecular Dynamics.\n\nThe ab initio multiple spawning (AIMS) method enables nonadiabatic quantum molecular dynamics simulations in an arbitrary number of dimensions, with potential energy surfaces provided by electronic structure calculations performed on-the-fly. However, the intricacy of the AIMS algorithm complicates software development, deployment on modern shared computer resources, and postsimulation data analysis. PySpawn is a nonadiabatic molecular dynamics software package that addresses these issues. The program is designed to be easily interfaced with electronic structure software, and an interface to the TeraChem software package is described here. PySpawn introduces a task-based reorganization of the AIMS algorithm, allowing fine-grained restart capability and setting the stage for efficient parallelization in a future release",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "ramd": {
                "Name": "RAMD",
                "Description": "Efficient random acceleration molecular dynamics simulation and interaction fingerprint analysis of ligand trajectories.\n\nRandom Acceleration Molecular Dynamics (RAMD).\n\nRandom Acceleration Molecular Dynamics (RAMD) is a method to carry out molecular dynamics simulations with an additional randomly oriented force applied to a molecule in the system.",
                "GPU": false,
                "CPU": false,
                "ram": true,
                "parallel": false,
                "distributed": false
            },
            "tinker-hp": {
                "Name": "Tinker-HP",
                "Description": "Tinker-HP is a tool for high-performance massively parallel evolution of tinker on CPUs & GPUs. It is used to accelerating molecular dynamics simulations of large complex systems with advanced point dipole polarizable force fields using GPUs and multi-GPU systems.",
                "GPU": true,
                "CPU": true,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "x-entropy": {
                "Name": "X-Entropy",
                "Description": "X-Entropy is a parallelized kernel density estimator with automated bandwidth selection to calculate entropy. This library is primarily meant to calculate dihedral entropies from MD simulation data. For this, we use a KDE with automatic bandwidth selection as suggested by Z. Botev et al. We tried to keep the package as generalized as possible, therefore, the package can be used to calculate the entropy of any data, or also to simply calculate the KDE.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "xansons": {
                "Name": "XaNSoNS",
                "Description": "XaNSoNS is an open source software with GPU support, which simulates X-ray and neutron 1D (or 2D) diffraction patterns and pair-distribution functions (PDF) for amorphous or crystalline nanoparticles (up to \u223c atoms) of heterogeneous structural content.",
                "GPU": true,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": false
            }
        }
    },
    "operation_0314": {
        "Name": "Gene expression profiling",
        "Count": 6,
        "Tools": {
            "anexvis": {
                "Name": "anexVis",
                "Description": "anexVis is a transcriptome tool to visualize organ/tissue-specific glycosaminoglycan biosynthetic and catabolic pathways in human health and diseases. anexVis  allows one to analyze a large number of genes that are related to biosynthetic and catabolic pathways of all glycosaminoglycans, such as heparan sulfate, chondroitin sulfate, keratan sulfate, and hyaluronic acid, in parallel across various human tissues organs. Such visual analyses have not been accessible to the broad research community despite the accumulation of a large amount of RNA-seq data.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "mcpnet": {
                "Name": "MCPNet",
                "Description": "Parallel maximum capacity-based genome-scale gene network construction framework.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "plexdb": {
                "Name": "PLEXdb",
                "Description": "Unified gene expression resource for plants and plant pathogens. It is a genotype to phenotype, hypothesis building information warehouse, leveraging highly parallel expression data with seamless portals to related genetic, physical, and pathway data.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "scamace": {
                "Name": "scAMACE",
                "Description": "scAMACE (integrative Analysis of single-cell Methylation, chromatin ACcessibility, and gene Expression). Python implementation (both CPU and GPU version) to a model-based approach to the joint analysis of single-cell data on chromatin accessibility, gene expression and methylation.",
                "GPU": true,
                "CPU": true,
                "ram": false,
                "parallel": false,
                "distributed": false
            },
            "scawmv": {
                "Name": "scAWMV",
                "Description": "An adaptively weighted multi-view learning framework for the integrative analysis of parallel scRNA-seq and scATAC-seq data.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "simpli": {
                "Name": "SIMPLI",
                "Description": "A SIMPLI (Single-cell Identification from MultiPLexed Images) approach for spatially resolved tissue phenotyping at single-cell resolution. SIMPLI is a platform agnostic pipeline for the analysis of highly multiplexed histological imaging data.\n\nThis will run SIMPLI on minimal example dataset distributed in this repository. For more details on the example dataset and the associated analysis workflow see the example-workflow page.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            }
        }
    },
    "operation_3463": {
        "Name": "Expression correlation analysis",
        "Count": 1,
        "Tools": {
            "anexvis": {
                "Name": "anexVis",
                "Description": "anexVis is a transcriptome tool to visualize organ/tissue-specific glycosaminoglycan biosynthetic and catabolic pathways in human health and diseases. anexVis  allows one to analyze a large number of genes that are related to biosynthetic and catabolic pathways of all glycosaminoglycans, such as heparan sulfate, chondroitin sulfate, keratan sulfate, and hyaluronic acid, in parallel across various human tissues organs. Such visual analyses have not been accessible to the broad research community despite the accumulation of a large amount of RNA-seq data.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            }
        }
    },
    "operation_3926": {
        "Name": "Pathway visualisation",
        "Count": 1,
        "Tools": {
            "anexvis": {
                "Name": "anexVis",
                "Description": "anexVis is a transcriptome tool to visualize organ/tissue-specific glycosaminoglycan biosynthetic and catabolic pathways in human health and diseases. anexVis  allows one to analyze a large number of genes that are related to biosynthetic and catabolic pathways of all glycosaminoglycans, such as heparan sulfate, chondroitin sulfate, keratan sulfate, and hyaluronic acid, in parallel across various human tissues organs. Such visual analyses have not been accessible to the broad research community despite the accumulation of a large amount of RNA-seq data.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            }
        }
    },
    "operation_0495": {
        "Name": "Local alignment",
        "Count": 9,
        "Tools": {
            "APPAGATO": {
                "Name": "APPAGATO",
                "Description": "APproximate PArallel and stochastic GrAph querying TOol for biological networks.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "blvector": {
                "Name": "BLVector",
                "Description": "BLVector is a fast BLAST-Like Aagorithm for multicore CPU with vectorization.  BLVector produces a list in a similar way than BLAST. BLVector provides a score based on the result of a Smith-Waterman algorithm with affine gaps which is the result of applying a score matrix like BLOSUM62 or PAM30.",
                "GPU": false,
                "CPU": true,
                "ram": false,
                "parallel": false,
                "distributed": false
            },
            "cudasw": {
                "Name": "CUDASW++",
                "Description": "CUDASW++ (compute unified device architecture) is a bioinformatics software for Smith-Waterman protein database searches that takes advantage of the massively parallel CUDA architecture of NVIDIA Tesla GPUs to perform fast sequence searches.",
                "GPU": true,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "f5c": {
                "Name": "f5c",
                "Description": "GPU Accelerated Adaptive Banded Event Alignment for Rapid Comparative Nanopore Signal Analysis | Re-engineered and optimised Nanopolish call-methylation module (supports CUDA acceleration) | An optimised re-implementation of the call-methylation module in Nanopolish. Given a set of basecalled Nanopore reads and the raw signals, f5c detects the methylated cytosine bases. f5c can optionally utilise NVIDIA graphics cards for acceleration",
                "GPU": true,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": false
            },
            "GASAL2": {
                "Name": "GASAL2",
                "Description": "a GPU accelerated sequence alignment library for high-throughput NGS data.\n\nGASAL2 - GPU-accelerated DNA alignment library.\n\nGASAL2 is an easy-to-use CUDA library for DNA/RNA sequence alignment algorithms. Currently it supports different kind of alignments:.\n\nA Linux platform with CUDA toolkit 8 or higher is required, along with usual build environment for C and C++ code. GASAL2 has been tested over NVIDIA GPUs with compute capabilities of 2.0, 3.5 and 5.0. Although lower versions of the CUDA framework might work, they have not been tested",
                "GPU": true,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": false
            },
            "gpu-darwin": {
                "Name": "GPU-Darwin",
                "Description": "GPU acceleration of Darwin read overlapper for de novo assembly of long DNA reads.\n\nThis repository contains a GPU implementation of Darwin [1][2], a hardware-friendly DNA aligner.\n\nIt consists of two parts: D-SOFT and GACT, which represent typical seed-and-extend methods. D-SOFT (Diagonal-band based Seed Overlapping based Filtration Technique) filters the search space by counting non-overlapping bases in matching Kmers in a band of diagonals. GACT (Genomic Alignment using Constant Tracebackmemory) can align reads of arbitrary length using constant memory for the compute-intensive step.\n\nThis implementation can be used to run on CPU only, or use the GPU-accelerated version. For more choices between individual optimizations, go back to commit e472745e.",
                "GPU": true,
                "CPU": true,
                "ram": false,
                "parallel": false,
                "distributed": false
            },
            "PaSGAL": {
                "Name": "PaSGAL",
                "Description": "PaSGAL (Parallel Sequence to Graph Aligner) is designed to accelerate local sequence alignment of sequences to directed acyclic sequence graphs (DAGs), e.g., variation graphs, splicing graphs.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "plast": {
                "Name": "Plast",
                "Description": "Parallel Local Alignment Search Tool for Database Comparison.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "retrieve_and_relate": {
                "Name": "Retrieve and Relate",
                "Description": "Retrieve similar sequences beginning from DNA, RNA or Proteins as well as free text - meaning there is no need to set any preliminary search parameters or filters which restrict the search space. Out of the box your search in parallel 11 of the most popular databases. Average alignment takes less then 3 seconds. Adding your own database is as simple as a click of the button.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            }
        }
    },
    "operation_0452": {
        "Name": "Indel detection",
        "Count": 4,
        "Tools": {
            "aramis": {
                "Name": "ARAMIS",
                "Description": "Accurate long-Reads Assembly correction Method for Indel errorS (ARAMIS) is a NGS long-reads indels correction pipeline that combines several correction software in just one step using accurate short reads. As a proof OF concept, six organisms were selected based on their different GC content, size and genome complexity, and their PacBio-assembled genomes were corrected thoroughly by this pipeline.",
                "GPU": false,
                "CPU": false,
                "ram": true,
                "parallel": false,
                "distributed": false
            },
            "chinook": {
                "Name": "Chinook",
                "Description": "Chinook is a peer-to-peer (P2P) service for the discovery, use and assessment of bioinformatics programs. Chinook Online allows researchers to connect and run distributed bioinformatics programs using a web application.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            },
            "delly2": {
                "Name": "Delly2",
                "Description": "Integrated structural variant prediction method that can discover, genotype and visualize deletions, tandem duplications, inversions and translocations at single-nucleotide resolution in short-read massively parallel sequencing data. It uses paired-ends and split-reads to sensitively and accurately delineate genomic rearrangements throughout the genome. Structural variants can be visualized using Delly-maze and Delly-suave.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "RelocaTE2": {
                "Name": "RelocaTE2",
                "Description": "a high resolution transposable element insertion site mapping tool for population resequencing.\n\nThis tool is for mapping TEs from resequencing data: Stajich lab.\n\nRelocaTE2: a high resolution transposable element insertion sites mapping tool for population resequencing.\n\nRelocaTE2 is an improved version of RelocaTE (Robb et al., 2013). RelocaTE2 is highly sensitive and accurate in mapping transposable elements (TE) polymorphisms at single base pair resolution. RelocaTE2 uses the reads associated with TEs as seeds to cluster the read pairs on chromosomes. It automatically detects the target site duplication (TSD) of a TE insertion from alignments in each cluster, which enable high resolution mapping of TE polymorphisms. Unlike parallel searching of multi-TE elements in RelocaTE, RelocaTE2 searches all TEs in one cycle, which enables us find polymorphisms of thousands of TEs in an individual genome or large population in a reasonable timeframe without losing sensitivity and specificity",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            }
        }
    },
    "operation_0524": {
        "Name": "De-novo assembly",
        "Count": 12,
        "Tools": {
            "aramis": {
                "Name": "ARAMIS",
                "Description": "Accurate long-Reads Assembly correction Method for Indel errorS (ARAMIS) is a NGS long-reads indels correction pipeline that combines several correction software in just one step using accurate short reads. As a proof OF concept, six organisms were selected based on their different GC content, size and genome complexity, and their PacBio-assembled genomes were corrected thoroughly by this pipeline.",
                "GPU": false,
                "CPU": false,
                "ram": true,
                "parallel": false,
                "distributed": false
            },
            "cuttlefish": {
                "Name": "Cuttlefish",
                "Description": "Cuttlefish is a fast, parallel, and very lightweight memory tool to construct the compacted de Bruijn graph from genome reference(s). Cuttlefish is a tool for constructing the (colored) compacted de Bruijn graph from a collection of one or more genome references. Cuttlefish introduces a novel modeling scheme of the de Bruijn graph vertices as finite-state automata, and constrains the state-space for the automata to enable tracking of their transitioning states with very low memory usage. Cuttlefish is also fast and highly parallelizable. Experimental results demonstrate that the algorithm scales much better than existing approaches, especially as the number and scale of the input references grow.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "galaxytrakr": {
                "Name": "GalaxyTrakr",
                "Description": "A distributed analysis tool for public health whole genome sequence data accessible to non-bioinformaticians.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            },
            "gpu-darwin": {
                "Name": "GPU-Darwin",
                "Description": "GPU acceleration of Darwin read overlapper for de novo assembly of long DNA reads.\n\nThis repository contains a GPU implementation of Darwin [1][2], a hardware-friendly DNA aligner.\n\nIt consists of two parts: D-SOFT and GACT, which represent typical seed-and-extend methods. D-SOFT (Diagonal-band based Seed Overlapping based Filtration Technique) filters the search space by counting non-overlapping bases in matching Kmers in a band of diagonals. GACT (Genomic Alignment using Constant Tracebackmemory) can align reads of arbitrary length using constant memory for the compute-intensive step.\n\nThis implementation can be used to run on CPU only, or use the GPU-accelerated version. For more choices between individual optimizations, go back to commit e472745e.",
                "GPU": true,
                "CPU": true,
                "ram": false,
                "parallel": false,
                "distributed": false
            },
            "haslr": {
                "Name": "HASLR",
                "Description": "Fast Hybrid Assembly of Long Reads.\n\nHASLR is a tool for rapid genome assembly of long sequencing reads. HASLR is a hybrid tool which means it requires long reads generated by Third Generation Sequencing technologies (such as PacBio or Oxford Nanopore) together with Next Generation Sequencing reads (such as Illumina) from the same sample. HASLR is capable of assembling large genomes on a single computing node. Our experiments show that it can assemble a CHM1 human dataset in less than 10 hours using 64 CPU threads.",
                "GPU": false,
                "CPU": true,
                "ram": false,
                "parallel": false,
                "distributed": false
            },
            "orfipy": {
                "Name": "orfipy",
                "Description": "A fast and flexible tool for extracting ORFs.\n\norfipy is a tool written in python/cython to extract ORFs in extremely an fast and flexible manner. Other popular ORF searching tools are OrfM and getorf. Compared to OrfM and getorf, orfipy provides the most options to fine tune ORF searches. orfipy uses multiple CPU cores and is particularly faster for data containing multiple smaller fasta sequences such as de-novo transcriptome assemblies. Please read the preprint here.",
                "GPU": false,
                "CPU": true,
                "ram": false,
                "parallel": false,
                "distributed": false
            },
            "ParLECH": {
                "Name": "ParLECH",
                "Description": "A hybrid and scalable error correction algorithm for indel and substitution errors of long reads.\n\nBACKGROUND:Long-read sequencing has shown the promises to overcome the short length limitations of second-generation sequencing by providing more complete assembly. However, the computation of the long sequencing reads is challenged by their higher error rates (e.g., 13% vs. 1%) and higher cost ($0.3 vs. $0.03 per Mbp) compared to the short reads. METHODS:In this paper, we present a new hybrid error correction tool, called ParLECH (Parallel Long-read Error Correction using Hybrid methodology). The error correction algorithm of ParLECH is distributed in nature and efficiently utilizes the k-mer coverage information of high throughput Illumina short-read sequences to rectify the PacBio long-read sequences.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": true
            },
            "pasha": {
                "Name": "PASHA",
                "Description": "It is a parallel short read assembler for large genomes using de Bruijn graphs. Taking advantage of both shared-memory multi-core CPUs and distributed-memory compute clusters, it has demonstrated its potential to perform high-quality de-novo assembly of large genomes in reasonable time with modest computing resources.",
                "GPU": false,
                "CPU": true,
                "ram": false,
                "parallel": true,
                "distributed": true
            },
            "pgcloser": {
                "Name": "PGcloser",
                "Description": "Fast Parallel Gap-Closing Tool Using Long-Reads or Contigs to Fill Gaps in Genomes.\n\nThis tool is for gap-closing in the genome using long-reads or contigs. PGcloser contains 7 modules: SplitFa, ExtrGap, BwtBuilt, CompGap, ClsGap, MergFa and GetCls.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "reindeer": {
                "Name": "REINDEER",
                "Description": "efficient indexing of k-mer presence and abundance in sequencing datasets.\n\nREINDEER builds a data-structure that indexes k-mers and their abundances in a collection of datasets (raw RNA-seq or metagenomic reads for instance). Then, a sequence (FASTA) can be queried for its presence and abundance in each indexed dataset. While other tools (e.g. SBT, BIGSI) were also designed for large-scale k-mer presence/absence queries, retrieving abundances was so far unsupported (except for single datasets, e.g. using some k-mer counters like KMC, Jellyfish). REINDEER combines fast queries, small index size, and low memory footprint during indexing and queries. We showed it allows to index 2585 RNA-seq datasets (~4 billions k-mers) using less than 60GB of RAM and a final index size lower than 60GB on the disk. Then, a REINDEER index can either be queried on disk (experimental feature, low RAM usage) or be loaded in RAM for faster queries.",
                "GPU": false,
                "CPU": false,
                "ram": true,
                "parallel": false,
                "distributed": false
            },
            "rhinella": {
                "Name": "Rhinella arenarum transcriptome",
                "Description": "The common toad Rhinella arenarum is widely distributed in Argentina, where it is utilised as an autochthonous model in ecotoxicological research and environmental toxicology. However, the lack of a reference genome makes molecular assays and gene expression studies difficult to carry out on this non-model species. To address this issue, we performed a genome-wide transcriptome analysis on R. arenarum larvae through massive RNA sequencing, followed by de novo assembly, annotation, and gene prediction. We obtained 57,407 well-annotated transcripts representing 99.4% of transcriptome completeness (available at http: rhinella.uncoma.edu.ar). We also defined a set of 52,800 high-confidence lncRNA transcripts and demonstrated the reliability of the transcriptome data to perform phylogenetic analysis",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            },
            "SWAPCounter": {
                "Name": "SWAPCounter",
                "Description": "Counting Kmers for Biological Sequences at Large Scale.\n\nThis is a distributed kmer counting tools for TB-PB sequencing dataset",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            }
        }
    },
    "operation_0525": {
        "Name": "Genome assembly",
        "Count": 11,
        "Tools": {
            "aramis": {
                "Name": "ARAMIS",
                "Description": "Accurate long-Reads Assembly correction Method for Indel errorS (ARAMIS) is a NGS long-reads indels correction pipeline that combines several correction software in just one step using accurate short reads. As a proof OF concept, six organisms were selected based on their different GC content, size and genome complexity, and their PacBio-assembled genomes were corrected thoroughly by this pipeline.",
                "GPU": false,
                "CPU": false,
                "ram": true,
                "parallel": false,
                "distributed": false
            },
            "enly": {
                "Name": "Enly",
                "Description": "Simple tool based on the iterative mapping of sequence reads at contig edges, capable to extend the genomic contigs deriving from high-throughput sequencing, especially those deriving by Newbler-like assemblies. Testing it on a set of de novo draft genomes led to the closure of up to 20% of the gaps originally present. It is cross-platform and most of the steps of its pipeline are parallelizable, making easy and fast to improve a draft genome resulting from a de novo assembly.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "genomix": {
                "Name": "Genomix",
                "Description": "Parallel genome assembly system built from the ground up with scalability in mind. It can assemble large and high-coverage genomes from fastq files in a short time and produces assemblies similar to Velvet or Ray in quality.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "haslr": {
                "Name": "HASLR",
                "Description": "Fast Hybrid Assembly of Long Reads.\n\nHASLR is a tool for rapid genome assembly of long sequencing reads. HASLR is a hybrid tool which means it requires long reads generated by Third Generation Sequencing technologies (such as PacBio or Oxford Nanopore) together with Next Generation Sequencing reads (such as Illumina) from the same sample. HASLR is capable of assembling large genomes on a single computing node. Our experiments show that it can assemble a CHM1 human dataset in less than 10 hours using 64 CPU threads.",
                "GPU": false,
                "CPU": true,
                "ram": false,
                "parallel": false,
                "distributed": false
            },
            "kmerkeys": {
                "Name": "KmerKeys",
                "Description": "KmerKeys is a web resource for searching indexed genome assemblies and variants. It provides performant, rapid query speeds for cloud computation on genome assemblies. It enable fuzzy as well as exact k-mer-based searches of assemblies. To enable robust and speedy performance, the website implements cache-friendly hash tables, memory mapping and massive parallel processing. Our method employs a scalable and efficient data structure that can be used to jointly index and search a large collection of human genome assembly information. One can include variant databases and their associated metadata such as the gnomAD population variant catalog. This feature enables the incorporation of future genomic information into sequencing analysis.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "musket": {
                "Name": "Musket",
                "Description": "It is an efficient multistage k-mer based corrector for Illumina short read data. This corrector employs the k-mer spectrum approach and introduces three correction techniques in a multistage workflow. It is multi-threaded using a master-slave model and demonstrates superior parallel scalability compared to all other evaluated correctors as well as a highly competitive overall execution time.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "nthits": {
                "Name": "ntHits",
                "Description": "De novo repeat identification of genomics data using a streaming approach.\n\nntHits is a method for identifying repeats in high-throughput DNA sequencing data.\n\nntHits uses OpenMP for parallelization, which requires a modern compiler such as GCC 4.2 or greater. If you have an older compiler, it is best to upgrade your compiler if possible. If you have multiple versions of GCC installed, you can specify a different compiler:.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "ogda": {
                "Name": "OGDA",
                "Description": "A comprehensive organelle genomes database for algae cpDNA and mtDNA.\n\nAlgae is the earliest evolutionary biological group on the earth, are thought to have appeared at least 2.6 billion years ago. As the most complex biological group, algae have shown the high diversity during the long evolutionary history. Algae are widely distributed in 4 kingdoms of the Eukaryota, including the Plantae, Protozoa, Acritarcha, Chromista and Fungi. Up to now, there are 46,177 species of eukaryotic algae have been recognized and classified (AlgaeBase, 2020), but in fact, more species need the further confirmation.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            },
            "pgcloser": {
                "Name": "PGcloser",
                "Description": "Fast Parallel Gap-Closing Tool Using Long-Reads or Contigs to Fill Gaps in Genomes.\n\nThis tool is for gap-closing in the genome using long-reads or contigs. PGcloser contains 7 modules: SplitFa, ExtrGap, BwtBuilt, CompGap, ClsGap, MergFa and GetCls.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "refka": {
                "Name": "RefKA",
                "Description": "A fast and efficient long-read genome assembly approach for large and complex genomes.\n\nRecent advances in long-read sequencing have the potential to produce more complete genome assemblies using sequence reads which can span repetitive regions. However, overlap based assembly methods routinely used for this data require significant computing time and resources. We have developed RefKA, a reference-based approach for long read genome assembly. This approach relies on breaking up a closely related reference genome into bins, aligning k-mers unique to each bin with PacBio reads, and then assembling each bin in parallel followed by a final bin-stitching step.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "swap-assembler": {
                "Name": "SWAP-Assembler",
                "Description": "A scalable and fully parallelized genome assembler designed for massive sequencing data. Intend of using traditional de Bruijn Graph, it adopts multi-step bi-directed graph (MSG). With MSG, the standard genome assembly (SGA) is equivalent to the edge merging operations in a semi-group.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            }
        }
    },
    "operation_3195": {
        "Name": "Sequencing error detection",
        "Count": 3,
        "Tools": {
            "aramis": {
                "Name": "ARAMIS",
                "Description": "Accurate long-Reads Assembly correction Method for Indel errorS (ARAMIS) is a NGS long-reads indels correction pipeline that combines several correction software in just one step using accurate short reads. As a proof OF concept, six organisms were selected based on their different GC content, size and genome complexity, and their PacBio-assembled genomes were corrected thoroughly by this pipeline.",
                "GPU": false,
                "CPU": false,
                "ram": true,
                "parallel": false,
                "distributed": false
            },
            "decgpu": {
                "Name": "DecGPU",
                "Description": "Parallel and distributed error correction algorithm for high-throughput short reads.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": true
            },
            "ParLECH": {
                "Name": "ParLECH",
                "Description": "A hybrid and scalable error correction algorithm for indel and substitution errors of long reads.\n\nBACKGROUND:Long-read sequencing has shown the promises to overcome the short length limitations of second-generation sequencing by providing more complete assembly. However, the computation of the long sequencing reads is challenged by their higher error rates (e.g., 13% vs. 1%) and higher cost ($0.3 vs. $0.03 per Mbp) compared to the short reads. METHODS:In this paper, we present a new hybrid error correction tool, called ParLECH (Parallel Long-read Error Correction using Hybrid methodology). The error correction algorithm of ParLECH is distributed in nature and efficiently utilizes the k-mer coverage information of high throughput Illumina short-read sequences to rectify the PacBio long-read sequences.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": true
            }
        }
    },
    "operation_3092": {
        "Name": "Protein feature detection",
        "Count": 4,
        "Tools": {
            "arion_4_omics": {
                "Name": "Arion 4 Omics",
                "Description": "High performance, \u2018end-to-end\u2019 analysis pipeline for the classification of omics profiles. Incorporating highly parallel architecture and sophisticated database technologies to overcome inherent technology based bottlenecks, currently faced in the Life Science research path. Arion is a scalable platform providing rapid exploratory analysis via machine learning, visualization and statistical modules with topology planned for a future release.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "biochemddi": {
                "Name": "BioChemDDI",
                "Description": "BioChemDDI web server is constructed to predict drug-drug interactions, which is compatible with most major browsers, and the parallel speed-up is implemented.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "deepnog": {
                "Name": "DeepNOG",
                "Description": "DeepNOG is a tool for protein orthologous groups assignment. Assign proteins to orthologous groups (eggNOG 5) on CPUs or GPUs with deep networks. DeepNOG is much faster than alignment-based methods, providing accuracy similar to HMMER.",
                "GPU": true,
                "CPU": true,
                "ram": false,
                "parallel": false,
                "distributed": false
            },
            "probis": {
                "Name": "ProBiS",
                "Description": "Web server which detects protein binding sites based on local structural alignments. Algorithms have been parallelized to allow for faster computing against the PDB. Pre-calculated protein similarity profiles for over 29,000 non-redundant proteins are also available.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            }
        }
    },
    "operation_3741": {
        "Name": "Differential protein expression profiling",
        "Count": 1,
        "Tools": {
            "arion_4_omics": {
                "Name": "Arion 4 Omics",
                "Description": "High performance, \u2018end-to-end\u2019 analysis pipeline for the classification of omics profiles. Incorporating highly parallel architecture and sophisticated database technologies to overcome inherent technology based bottlenecks, currently faced in the Life Science research path. Arion is a scalable platform providing rapid exploratory analysis via machine learning, visualization and statistical modules with topology planned for a future release.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            }
        }
    },
    "operation_3223": {
        "Name": "Differential gene expression profiling",
        "Count": 9,
        "Tools": {
            "asterias": {
                "Name": "Asterias",
                "Description": "Set of tools for the analyses of high throughput genomic data that includes applications for microarray data normalization, filtering, detection of differential gene expression, class and survival prediction model building, and analysis of array CGH data. Most applications use parallel computing resulting in significant increases in speed.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "bigPint": {
                "Name": "bigPint",
                "Description": "Visualization methods for differential expression analysis | Methods for visualizing large multivariate datasets using static and interactive scatterplot matrices, parallel coordinate plots, volcano plots, and litre plots. Includes examples for visualizing RNA-sequencing datasets and differentially expressed genes | Big multivariate data plotted interactively | bigPint: Make BIG data pint-sized | Welcome to the bigPint package website! If you are a new user, please begin by reading from the Get Started tab at the top of this website. There are ten short vignette articles in that tab, and we recommend reading them in order. These short vignette articles consist of reproducible code that provide: | Alternatives to data metrics object | Clustering, DataImport, DifferentialExpression, GeneExpression, MultipleComparison, Normalization, Preprocessing, QualityControl, RNASeq, Sequencing, Software, Transcription, Visualization",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "Eoulsan": {
                "Name": "Eoulsan",
                "Description": "A versatile framework based on the Hadoop implementation of the MapReduce algorithm, dedicated to high throughput sequencing data analysis on distributed computers. With Eoulsan, users can easily set up a cloud computing cluster and automate the analysis of several samples at once using various software solutions available. Working either on standalone workstations or cloud computing clusters, Eoulsan provides an integrated and flexible solution for RNA-Seq data analysis of differential expression.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            },
            "gseabenchmarker": {
                "Name": "GSEABenchmarkeR",
                "Description": "It implements an extendable framework for reproducible evaluation of set- and network-based methods for enrichment analysis of gene expression data. This includes support for the efficient execution of these methods on comprehensive real data compendia using parallel computation on standard workstations and institutional computer grids.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "HCCPred": {
                "Name": "HCCPred",
                "Description": "Identification of Platform-Independent Diagnostic Biomarker Panel for Hepatocellular Carcinoma using Large-scale Transcriptomics Data | A webserver to predict Hepatocellular carcinoma (HCC) | Pipeline Differential Expression Analysis | HCCpred is a web-bench for the prediction of tumorous and non-tumorous Hepatocellular Carcinoma (HCC) patients. Our major prediction modules based on the robust biomarkers such as 3-Gene HCC Biomarker, 4-Gene HCC Biomarker, 5-Gene HCC Biomarker. These HCC biomarkers identified using gene expression profiles of a total of 3,961 samples include 2,306 HCC and 1,655 non-tumorous samples. The datasets derived from various profiling platforms such as Affymatrix, Illumina, High-througput and Agilent. The user can also analyse the expression pattern of any of 26 'core genes of HCC' in cancerous vs normal conditions",
                "GPU": true,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": false
            },
            "netmix": {
                "Name": "NetMix",
                "Description": "A network-structured mixture model for reduced-bias estimation of altered subnetworks.\n\nNetMix is an algorithm for identifying altered subnetworks with node scores that are distributed differently from other nodes in the network. NetMix improves upon current methods by using a Gaussian Mixture Model to find a less biased estimate of the size of an altered subnetwork. This README is under construction.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            },
            "phantasus": {
                "Name": "phantasus",
                "Description": "It is a web-application for visual and interactive gene expression analysis. Phantasus is based on Morpheus \u2013 a web-based software for heatmap visualisation and analysis, which was integrated with an R environment via OpenCPU API. Aside from basic visualization and filtering methods, R-based methods such as k-means clustering, principal component analysis or differential expression analysis with limma package are supported.",
                "GPU": false,
                "CPU": true,
                "ram": false,
                "parallel": false,
                "distributed": false
            },
            "scdrake": {
                "Name": "scdrake",
                "Description": "Scdrake is a highly scalable, reproducible and configurable pipeline for scRNA-seq data prepared by a popular 10x Genomics droplet-based technology. Scdrake is implemented as a package for the R language and is built on top of the drake package, a Make-like pipeline toolkit. Scdrake currently provides common steps of scRNA-seq data analysis: quality control and filtering of cells and genes, normalization, dimensionality reduction, clustering, finding of cluster markers and differentially expressed genes between clusters, and integration of multiple datasets. All pipeline steps are accompanied by rich graphical outputs and reports in HTML format.\n\nThanks to the drake package, all intermediate results can be reused, and the pipeline can be easily extended by users to incorporate custom analyses. Also, drake analyzes which parts of the pipeline are already done or haven't changed since the last run, and which can be run in parallel, resulting in great execution speed.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "sdams": {
                "Name": "SDAMS",
                "Description": "This Package utilizes a Semi-parametric Differential Abundance analysis (SDA) method for metabolomics and proteomics data from mass spectrometry. SDA is able to robustly handle non-normally distributed data and provides a clear quantification of the effect size.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            }
        }
    },
    "operation_3629": {
        "Name": "Deisotoping",
        "Count": 10,
        "Tools": {
            "autodeconj": {
                "Name": "AutoDeconJ",
                "Description": "A GPU-accelerated ImageJ plugin for 3D light-field deconvolution with optimal iteration numbers predicting.",
                "GPU": true,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": false
            },
            "Cytokit": {
                "Name": "Cytokit",
                "Description": "A single-cell analysis toolkit for high dimensional fluorescent microscopy imaging | Microscopy Image Cytometry Toolkit | Cytokit is a collection of tools for quantifying and analyzing properties of individual cells in large fluorescent microscopy datasets with a focus on those generated from multiplexed staining protocols. This includes a GPU-accelerated image processing pipeline (via TensorFlow), CLI tools for batch processing of experimental replicates (often requiring conditional configuration, as things tend go wrong when capturing hundreds of thousands of microscope images over a period of hours or days), and visualization UIs (either Cytokit Explorer or CellProfiler Analyst) | Med Google Cloud Platform kan du oprette, implementere og skalere apps, websites og tjenester p\u00e5 den samme infrastruktur som Google | Forts\u00e6t til Google Cloud Platform | Skriv den tekst, du h\u00f8rer eller ser",
                "GPU": true,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": false
            },
            "DeepImageJ": {
                "Name": "DeepImageJ",
                "Description": "A user-friendly plugin to run deep learning models in ImageJ. Websites for you and your projects, hosted directly from your GitHub repository. Just edit, push, and your changes are live.\n\nDeepImageJ is a user-friendly plugin that enables the use of a variety of pre-trained deep learning models in ImageJ and Fiji. The plugin bridges the gap between deep learning and standard life-science applications. DeepImageJ runs image-to-image operations on a standard CPU-based computer and does not require any deep learning expertise.",
                "GPU": false,
                "CPU": true,
                "ram": false,
                "parallel": false,
                "distributed": false
            },
            "denoisem": {
                "Name": "DenoisEM",
                "Description": "An interactive ImageJ plugin for semi-automated image denoising in electron microscopy.\n\nDenoisEM offers several state-of-the-art denoising and deconvolution algorithms such as non-local means, BLS-GSM, Tikhonov deconvolution, etc.\n\nFast and advanced image denoising of large-scale 3D electron microscopy data.\n\nDenoisEM is developed by the TELIN department at Ghent University and the Bio Informatics Core at VIB . The GPU backbone is driven by Quasar , an in-house programming language of the TELIN department.\n\nApache/2.4.7 (Ubuntu) Server at bioimagingcore.be Port 443.",
                "GPU": true,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": false
            },
            "diapasef": {
                "Name": "diaPASEF",
                "Description": "diaPASEF is an appproch for parallel accumulation-serial fragmentation combined with data-independent acquisition.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "DstarM": {
                "Name": "DstarM",
                "Description": "> MEDIUM CONFIDENCE! | > HOMEPAGE MISSING! | > CORRECT NAME OF TOOL COULD ALSO BE 'nondecision', 'DM', 'two-choice' | an R package for analyzing two-choice reaction time data with the D\u2217M method | The decision process in choice reaction time data is traditionally described in detail with diffusion models. However, the total reaction time is assumed to consist of the sum of a decision time (as modeled by the diffusion process) and the time devoted to nondecision processes (e.g., perceptual and motor processes). It has become standard practice to assume that the nondecision time is uniformly distributed. However, a misspecification of the nondecision time distribution introduces bias in the parameter estimates for the decision model. Recently, a new method has been proposed (called the D\u2217M method) that allows the estimation of the decision model parameters, while leaving the nondecision time distribution unspecified",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            },
            "HiPFSTA": {
                "Name": "HiPFSTA",
                "Description": "Gradient-based, GPU-accelerated, high-precision contour-segmentation algorithm with application to cell membrane fluctuation spectroscopy.",
                "GPU": true,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": false
            },
            "masserstein": {
                "Name": "Masserstein",
                "Description": "Robust linear deconvolution by optimal transport.\n\nThis repository contains software tools which allow to compare spectra using the Wasserstein distance and estimate relative abundances of molecules from the spectrum by minimizing the Wasserstein distance.\n\nThe tools are distributed as a Python3 package called masserstein. Basic functionality is also available as a set of commandline applications: WSDistance to compute the Wasserstein distance and WSDeconv to estimate proportions.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            },
            "pymethylprocess": {
                "Name": "pymethylprocess",
                "Description": "convenient high-throughput preprocessing workflow for DNA methylation data | Preprocessing methylation pipeline, written in python. Easy to use and highly parallelized | https://github.com/Christensen-Lab-Dartmouth/PyMethylProcess | pip install pymethylprocess && pymethyl-install_r_dependencies (Note: May need to prefix pip install with MACOSX_DEPLOYMENT_TARGET=10.9 CC=clang CXX=clang++ for Mac OS install)",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "rck": {
                "Name": "RCK",
                "Description": "Reconstruction of clone- and haplotype-specific cancer genome karyotypes from bulk tumor samples.\n\nReconstruction of clone- and haplotype-specific Cancer Karyotypes.\n\nNOTE: this repository contains only the initial version of RCK at the time of its publication.\n\nRCK - is a method for Reconstruction of clone- and haplotype-specific Cancer Karyotypes from tumor mixtures, distributed both as a standalone software package and as a Python library under the MIT licence.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            }
        }
    },
    "operation_3927": {
        "Name": "Network analysis",
        "Count": 12,
        "Tools": {
            "autodeconj": {
                "Name": "AutoDeconJ",
                "Description": "A GPU-accelerated ImageJ plugin for 3D light-field deconvolution with optimal iteration numbers predicting.",
                "GPU": true,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": false
            },
            "bets": {
                "Name": "BETS",
                "Description": "Bootstrap Elastic net regression from Time Series (BETS) is a statistical framework based on Granger causality for the recovery of a directed gene network from transcriptional time-series data. BETS uses elastic net regression and stability selection from bootstrapped samples to infer causal relationships among genes. BETS is highly parallelized, enabling efficient analysis of large transcriptional data sets.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "biochemddi": {
                "Name": "BioChemDDI",
                "Description": "BioChemDDI web server is constructed to predict drug-drug interactions, which is compatible with most major browsers, and the parallel speed-up is implemented.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "brian2genn": {
                "Name": "Brian2GeNN",
                "Description": "Brian2GeNN is a software package that enables the users to make use of GeNN GPU acceleration when developing their models in Brian, without requiring any technical knowledge about GPUs, C++ or GeNN. The new Brian2GeNN software uses a pipeline of code generation to translate Brian scripts into C++ code that can be used as input to GeNN, and subsequently can be run on suitable NVIDIA GPU accelerators.",
                "GPU": true,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": false
            },
            "deepac4c": {
                "Name": "DeepAc4C",
                "Description": "A convolutional neural network model with hybrid features composed of physicochemical patterns and distributed representation information for identification of N4-acetylcytidine in mRNA.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            },
            "diamin": {
                "Name": "DIAMIN",
                "Description": "DIAMIN is a high-level software library to facilitate the development of distributed applications for the efficient analysis of large-scale molecular interaction networks.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            },
            "forecast_mpra": {
                "Name": "FORECAST",
                "Description": "Effective design and inference for cell sorting and sequencing based massively parallel reporter assays.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "grgmf": {
                "Name": "GRGMF",
                "Description": "A graph regularized generalized matrix factorization model for predicting links in biomedical bipartite networks.\n\nThis code is the implementation of GRGMF, which is both CPU and CUDA compatible(CUDA is preferred).",
                "GPU": false,
                "CPU": true,
                "ram": false,
                "parallel": false,
                "distributed": false
            },
            "netmix": {
                "Name": "NetMix",
                "Description": "A network-structured mixture model for reduced-bias estimation of altered subnetworks.\n\nNetMix is an algorithm for identifying altered subnetworks with node scores that are distributed differently from other nodes in the network. NetMix improves upon current methods by using a Gaussian Mixture Model to find a less biased estimate of the size of an altered subnetwork. This README is under construction.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            },
            "pecanpy": {
                "Name": "PecanPy",
                "Description": "PecanPy: A parallelized, efficient, and accelerated node2vec in Python.\n\nLearning low-dimensional representations (embeddings) of nodes in large graphs is key to applying machine learning on massive biological networks. Node2vec is the most widely used method for node embedding. PecanPy is a fast, parallelized, memory efficient, and cache optimized Python implementation of node2vec. It uses cache-optimized compact graph data structures and precomputing/parallelization to result in fast, high-quality node embeddings for biological networks of all sizes and densities.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "pygenn": {
                "Name": "PyGeNN",
                "Description": "PyGeNN is a Python library for GPU-enhanced neural networks. PyGeNN is a Python package which exposes all of GeNN's functionality to Python with minimal overhead. This provides an alternative, arguably more user-friendly, way of using GeNN and allows modelers to use GeNN within the growing Python-based machine learning and computational neuroscience ecosystems.",
                "GPU": true,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": false
            },
            "silencerdb": {
                "Name": "SilencerDB",
                "Description": "a comprehensive database of silencers.\n\nA deep convolutional neural network for the accurate prediction of silencers.\n\nSilencers, which were first identified around 30 years ago as sequence-specific elements that induce negative effect on the transcription of particular genes, have started to receive growing attention. To facilitate the studies of silencers and their potential roles in transcriptional control during normal development and disease, we developed this comprehensive database of silencers, SilencerDB.\n\nFor accurate classification of silencers, we propose a CNN-based model named DeepSilencer.\n\n$ pip install tensorflow-gpu==1.15.2 #pip install tensorflow==1.15.2.",
                "GPU": true,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": false
            }
        }
    },
    "operation_3200": {
        "Name": "DNA barcoding",
        "Count": 6,
        "Tools": {
            "autorelacs": {
                "Name": "AutoRELACS",
                "Description": "AutoRELACS is a Python script for automated generation and analysis of ultra-parallel ChIP-seq.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "BART-Seq": {
                "Name": "BART-Seq",
                "Description": "cost-effective massively parallelized targeted sequencing for genomics, transcriptomics, and single-cell analysis | Software required for Bart-Seq technology \u2013 a cheap technology to analyze (single) cells using forward and reverse barcoding for target genes | Demultiplexing pipeline for BARTSeq | Software required for Bart-Seq \u2013 a cost-effective target enrichment technology using forward and reverse barcoding to analyze selected set of genes in single cells and/or bulk RNA/DNA samples | The pipeline can be run via snakemake [-j 4] [-s \u2026/bartseq/Snakefile] [-d \u2026/mydata], where -j specifies the number of threads, and the other parameters default to ./Snakefile and ., respectively",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "chromscape": {
                "Name": "ChromSCape",
                "Description": "ChromSCape is a user-friendly interactive Shiny/R application distributed as a Bioconductor package, that processes single-cell epigenomic data to assist the biological interpretation of chromatin landscapes within cell populations. ChromSCape analyses the distribution of repressive and active histone modifications as well as chromatin accessibility landscapes from single-cell datasets.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            },
            "FB5P-seq": {
                "Name": "FB5P-seq",
                "Description": "FACS-based 5-prime end single-cell RNAseq for integrative analysis of transcriptome and antigen receptor repertoire in B and T cells.\n\nFB5P-seq: FACS-based 5'-end single-cell RNA-seq.\n\nCopyright 2019: PMlab, Centre d'Immunologie de Marseille-Luminy This work is distributed under the terms of the GNU General Public License. It is free to use for all purposes.\n\nFB5P-seq is a computational pipeline to process single-cell RNA sequencing (scRNAseq) data produced with the FB5P-seq protocol designed by the Milpied lab at Centre d'Immunologie de Marseille-Luminy. The pipeline relies on 5 main softwares:",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            },
            "malacoda": {
                "Name": "malacoda",
                "Description": "Bayesian modelling of high-throughput sequencing assays with malacoda.\n\nThe goal of malacoda is to enable Bayesian analysis of high-throughput genomic assays like massively parallel reporter assays (MPRA) and CRISPR screens.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "MPRAnalyze": {
                "Name": "MPRAnalyze",
                "Description": "Statistical framework for massively parallel reporter assays | Statistical Analysis of MPRA data | MPRAnalyze provides statistical framework for the analysis of data generated by Massively Parallel Reporter Assays (MPRAs), used to directly measure enhancer activity. MPRAnalyze can be used for quantification of enhancer activity, classification of active enhancers and comparative analyses of enhancer activity between conditions. MPRAnalyze construct a nested pair of generalized linear models (GLMs) to relate the DNA and RNA observations, easily adjustable to various experimental designs and conditions, and provides a set of rigorous statistical testig schemes",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            }
        }
    },
    "operation_3222": {
        "Name": "Peak calling",
        "Count": 3,
        "Tools": {
            "autorelacs": {
                "Name": "AutoRELACS",
                "Description": "AutoRELACS is a Python script for automated generation and analysis of ultra-parallel ChIP-seq.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "chromscape": {
                "Name": "ChromSCape",
                "Description": "ChromSCape is a user-friendly interactive Shiny/R application distributed as a Bioconductor package, that processes single-cell epigenomic data to assist the biological interpretation of chromatin landscapes within cell populations. ChromSCape analyses the distribution of repressive and active histone modifications as well as chromatin accessibility landscapes from single-cell datasets.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            },
            "probis": {
                "Name": "ProBiS",
                "Description": "Web server which detects protein binding sites based on local structural alignments. Algorithms have been parallelized to allow for faster computing against the PDB. Pre-calculated protein similarity profiles for over 29,000 non-redundant proteins are also available.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            }
        }
    },
    "operation_0308": {
        "Name": "PCR primer design",
        "Count": 7,
        "Tools": {
            "BART-Seq": {
                "Name": "BART-Seq",
                "Description": "cost-effective massively parallelized targeted sequencing for genomics, transcriptomics, and single-cell analysis | Software required for Bart-Seq technology \u2013 a cheap technology to analyze (single) cells using forward and reverse barcoding for target genes | Demultiplexing pipeline for BARTSeq | Software required for Bart-Seq \u2013 a cost-effective target enrichment technology using forward and reverse barcoding to analyze selected set of genes in single cells and/or bulk RNA/DNA samples | The pipeline can be run via snakemake [-j 4] [-s \u2026/bartseq/Snakefile] [-d \u2026/mydata], where -j specifies the number of threads, and the other parameters default to ./Snakefile and ., respectively",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "GoldenMutagenesis": {
                "Name": "GoldenMutagenesis",
                "Description": "The Golden Gate cloning technique has been proven to be a highly efficient toolbox for a variety of cloning setups. Based on its modular concept it is particularly suitable for the use in multiple-site mutagenesis approaches. In this technical note we developed a protocol termed Golden Mutagenesis for the rapid, easy, reliable and cheap formation of mutagenesis libraries. One to five positions could be altered in parallel or simultaneously within two days. To facilitate the implementation of this technique, this R-library has been developed for the automated primer design and the graphical evaluation of sequencing results to determine the quality of the library.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "gprimer": {
                "Name": "GPrimer",
                "Description": "GPrimer is a fast GPU-based pipeline for primerdesign for qPCR experiments.",
                "GPU": true,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": false
            },
            "kmerkeys": {
                "Name": "KmerKeys",
                "Description": "KmerKeys is a web resource for searching indexed genome assemblies and variants. It provides performant, rapid query speeds for cloud computation on genome assemblies. It enable fuzzy as well as exact k-mer-based searches of assemblies. To enable robust and speedy performance, the website implements cache-friendly hash tables, memory mapping and massive parallel processing. Our method employs a scalable and efficient data structure that can be used to jointly index and search a large collection of human genome assembly information. One can include variant databases and their associated metadata such as the gnomAD population variant catalog. This feature enables the incorporation of future genomic information into sequencing analysis.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "MCSeEd": {
                "Name": "MCSeEd",
                "Description": "A reference-free, whole genome profiling system to address cytosine/adenine methylation changes.\n\nMethods for investigating DNA methylation nowadays either require a reference genome and high coverage, or investigate only CG methylation. Moreover, no large-scale analysis can be performed for N6-methyladenosine (6 mA) at an affordable price. Here we describe the methylation content sensitive enzyme double-digest restriction-site-associated DNA (ddRAD) technique (MCSeEd), a reduced-representation, reference-free, cost-effective approach for characterizing whole genome methylation patterns across different methylation contexts (e.g., CG, CHG, CHH, 6 mA). MCSeEd can also detect genetic variations among hundreds of samples. MCSeEd is based on parallel restrictions carried out by combinations of methylation insensitive and sensitive endonucleases, followed by next-generation sequencing.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "ngs-primerplex": {
                "Name": "NGS-PrimerPlex",
                "Description": "High-throughput primer design for multiplex polymerase chain reactions.\n\nNGS-PrimerPlex is a high-throughput tool for mupltiplex primer design.\n\nIt includes four Python-scripts:.\n\nNGS-PrimerPlex can be run as a Docker image. In this way you only need to install Docker (for windows 7 users this install steps should be performed). If you have 'VD-x, VD-t error', you need to turn on virtualization in BIOS CPU section.",
                "GPU": false,
                "CPU": true,
                "ram": false,
                "parallel": false,
                "distributed": false
            },
            "rhinella": {
                "Name": "Rhinella arenarum transcriptome",
                "Description": "The common toad Rhinella arenarum is widely distributed in Argentina, where it is utilised as an autochthonous model in ecotoxicological research and environmental toxicology. However, the lack of a reference genome makes molecular assays and gene expression studies difficult to carry out on this non-model species. To address this issue, we performed a genome-wide transcriptome analysis on R. arenarum larvae through massive RNA sequencing, followed by de novo assembly, annotation, and gene prediction. We obtained 57,407 well-annotated transcripts representing 99.4% of transcriptome completeness (available at http: rhinella.uncoma.edu.ar). We also defined a set of 52,800 high-confidence lncRNA transcripts and demonstrated the reliability of the transcriptome data to perform phylogenetic analysis",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            }
        }
    },
    "operation_3192": {
        "Name": "Sequence trimming",
        "Count": 11,
        "Tools": {
            "BART-Seq": {
                "Name": "BART-Seq",
                "Description": "cost-effective massively parallelized targeted sequencing for genomics, transcriptomics, and single-cell analysis | Software required for Bart-Seq technology \u2013 a cheap technology to analyze (single) cells using forward and reverse barcoding for target genes | Demultiplexing pipeline for BARTSeq | Software required for Bart-Seq \u2013 a cost-effective target enrichment technology using forward and reverse barcoding to analyze selected set of genes in single cells and/or bulk RNA/DNA samples | The pipeline can be run via snakemake [-j 4] [-s \u2026/bartseq/Snakefile] [-d \u2026/mydata], where -j specifies the number of threads, and the other parameters default to ./Snakefile and ., respectively",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "bigseqkit": {
                "Name": "BigSeqKit",
                "Description": "The Next Generation Sequencing (NGS) raw data are stored in FASTA and FASTQ text-based file formats. Common operations on FASTA/Q files include searching, filtering, sampling, deduplication and sorting, among others. We can find several tools in the literature for FASTA/Q file manipulation but none of them are well fitted for large files of tens of GB (likely TBs in the near future) since mostly they are based on sequential processing. The exception is seqkit that allows some routines to use a few threads but, in any case, the scalability is very limited. To deal with this issue, we introduce BigSeqKit, a parallel toolkit to manipulate FASTA/Q files at scale with speed and scalability at its core. BigSeqKit takes advantage of an HPC-Big Data framework (IgnisHPC) to parallelize and optimize the commands included in seqkit. In this way, in most cases it is from tens to hundreds of times faster than other state-of-the-art tools such as seqkit, samtools and pyfastx.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "datma": {
                "Name": "DATMA",
                "Description": "DATMA (Distributed AuTomatic Metagenomic Assembly and annotation framework) is a distributed automatic pipeline for fast metagenomic analysis that includes: sequencing quality control, 16S-identification, reads binning, de novo assembly, ORF detection and taxonomic annotation.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            },
            "flexbar": {
                "Name": "Flexbar",
                "Description": "Flexible barcode and adapter removal. It demultiplexes barcoded runs and removes adapter sequences. Several adapter removal presets for Illumina libraries are included. Computes exact overlap alignments using SIMD and multicore parallelism. Moreover, trimming and filtering features are provided. It increases read mapping rates and improves genome as well as transcriptome assemblies.  The software supports data in fasta and fastq format from multiple sequencing platforms.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "metalaffa": {
                "Name": "MetaLAFFA",
                "Description": "A flexible, end-to-end, distributed computing-compatible metagenomic functional annotation pipeline.\n\nMetaLAFFA is a flexible, end-to-end, and compute cluster-compatible metagenomic functional annotation pipeline.\nMetaLAFFA is a pipeline for annotating shotgun metagenomic data with abundances of functional orthology groups. This process consists of several steps to go from raw FASTQs (with sequencing adapters removed) to functional profiles:.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            },
            "ngs-primerplex": {
                "Name": "NGS-PrimerPlex",
                "Description": "High-throughput primer design for multiplex polymerase chain reactions.\n\nNGS-PrimerPlex is a high-throughput tool for mupltiplex primer design.\n\nIt includes four Python-scripts:.\n\nNGS-PrimerPlex can be run as a Docker image. In this way you only need to install Docker (for windows 7 users this install steps should be performed). If you have 'VD-x, VD-t error', you need to turn on virtualization in BIOS CPU section.",
                "GPU": false,
                "CPU": true,
                "ram": false,
                "parallel": false,
                "distributed": false
            },
            "P3BSseq": {
                "Name": "P3BSseq",
                "Description": "Parallel processing pipeline software for automatic analysis of bisulfite sequencing data.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "quickld": {
                "Name": "quickLD",
                "Description": "quickLD (qLD) is a tool to calculate Linkage disequilibrium (the non-random association between alleles at different loci), with highly efficient CPU and GPU kernels that utilize dense linear algebra (DLA) operations.",
                "GPU": true,
                "CPU": true,
                "ram": false,
                "parallel": false,
                "distributed": false
            },
            "refka": {
                "Name": "RefKA",
                "Description": "A fast and efficient long-read genome assembly approach for large and complex genomes.\n\nRecent advances in long-read sequencing have the potential to produce more complete genome assemblies using sequence reads which can span repetitive regions. However, overlap based assembly methods routinely used for this data require significant computing time and resources. We have developed RefKA, a reference-based approach for long read genome assembly. This approach relies on breaking up a closely related reference genome into bins, aligning k-mers unique to each bin with PacBio reads, and then assembling each bin in parallel followed by a final bin-stitching step.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "RelocaTE2": {
                "Name": "RelocaTE2",
                "Description": "a high resolution transposable element insertion site mapping tool for population resequencing.\n\nThis tool is for mapping TEs from resequencing data: Stajich lab.\n\nRelocaTE2: a high resolution transposable element insertion sites mapping tool for population resequencing.\n\nRelocaTE2 is an improved version of RelocaTE (Robb et al., 2013). RelocaTE2 is highly sensitive and accurate in mapping transposable elements (TE) polymorphisms at single base pair resolution. RelocaTE2 uses the reads associated with TEs as seeds to cluster the read pairs on chromosomes. It automatically detects the target site duplication (TSD) of a TE insertion from alignments in each cluster, which enable high resolution mapping of TE polymorphisms. Unlike parallel searching of multi-TE elements in RelocaTE, RelocaTE2 searches all TEs in one cycle, which enables us find polymorphisms of thousands of TEs in an individual genome or large population in a reasonable timeframe without losing sensitivity and specificity",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "tis": {
                "Name": "TIS",
                "Description": "Assessment of methods for Transposon Insertion Sequencing(TIS) analyses.\n\nThe TA are distributed relatively evenly along genome. The Mariner-based transposons can be inserted to impact statistically every gene, with in average more than 30 insertions site per kb. With the low insertion bias, it is easy to build saturated libraries. But local variations means less loci and less statistical power.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            }
        }
    },
    "operation_3227": {
        "Name": "Variant calling",
        "Count": 25,
        "Tools": {
            "basenumber": {
                "Name": "BaseNumber",
                "Description": "High performance of a GPU-accelerated variant calling tool in genome data analysis",
                "GPU": true,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": false
            },
            "BIRD": {
                "Name": "BIRD",
                "Description": "Bayesian Estimation of Genetic Regulatory Effects in High-throughput Reporter Assays | Bayesian Inference of Regulatory Differences | Photo by Bill Majoros. Used with permission | [6/16/2018] First version of BIRD released - The first version of BIRD has been released on GitHub at https://github.com/bmajoros/BIRD | [8/23/2018] Experiment design web tool released - A web tool is now available for power and sample size estimation: http://67.159.92.22:8080/ | BIRD (Bayesian Inference of Regulatory Differences) is a software suite for identifying regulatory variants in data from STARR-seq and other massively parallel reporter assays (MPRAs)",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "circvar-db": {
                "Name": "circVAR database",
                "Description": "circVAR database is genome-wide archive of genetic variants for human circular RNAs\nCircular RNAs (circRNAs), the 3' and 5' ends of which are covalently linked, are a kind of widely distributed and abundant RNAs found in eukaryotic organisms in recent years. They could play as sponges for regulating microRNAs and RNA binding proteins. Our circVAR database aims to provide resources for circRNA-related genetic variants in healthy and diseased populations.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            },
            "cramer": {
                "Name": "CRAMER",
                "Description": "The Cranfield Genome Browser (CRAMER) is a lightweight, highly customizable web-based genome browser supporting multiple visualization instances. CRAMER is a customisable, JavaScript and Jade based genome browser for interactive exploration of genomic data. Data is visualized in the browser, meaning CRAMER can be installed on any website and show data from a wide range of online, ftp links or local sources. CRAMER works with a variety of formats, such as XML, JSON, BED, VCF, GFF, GFF3, BAM or delimited text files, and can be customised to parse and display any data source as required.",
                "GPU": false,
                "CPU": false,
                "ram": true,
                "parallel": false,
                "distributed": false
            },
            "dbgenvoc": {
                "Name": "dbGENVOC",
                "Description": "dbGENVOC, a comprehensive, flexible database framework, developed with an aim to allow potential users to access, query, browse and download clinically relevant somatic and germline variation data from Indian oral cancer patients. This database will store variant calls from various studies that uses massively parallel sequencing to generate genome-scale data.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "deepvariant": {
                "Name": "DeepVariant",
                "Description": "DeepVariant is a deep learning-based variant caller that takes aligned reads (in BAM or CRAM format), produces pileup image tensors from them, classifies each tensor using a convolutional neural network, and finally reports the results in a standard VCF or gVCF file.",
                "GPU": false,
                "CPU": false,
                "ram": true,
                "parallel": false,
                "distributed": false
            },
            "delly2": {
                "Name": "Delly2",
                "Description": "Integrated structural variant prediction method that can discover, genotype and visualize deletions, tandem duplications, inversions and translocations at single-nucleotide resolution in short-read massively parallel sequencing data. It uses paired-ends and split-reads to sensitively and accurately delineate genomic rearrangements throughout the genome. Structural variants can be visualized using Delly-maze and Delly-suave.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "denovocnn": {
                "Name": "DeNovoCNN",
                "Description": "DeNovoCNN is a deep learning approach to call de novo mutations (DNMs) on whole-exome (WES) and whole-genome sequencing (WGS) data. DeNovoCNN uses trio recalibrated BAM/CRAM + VCF (or tab-separated list of variants) files to generate image-like genomic sequence representations and detect DNMs with high accuracy.",
                "GPU": false,
                "CPU": false,
                "ram": true,
                "parallel": false,
                "distributed": false
            },
            "FixVAF": {
                "Name": "FixVAF",
                "Description": "Correcting reference bias from the Illumina Isaac aligner enables analysis of cancer genomes.\n\nCode to remove bias from Isaac aligned data by clipping all reads for variant positions by 5 bases and producing a modified vcf file.\n\nSupport code for NGS copy number algorithms. Takes a file of locations and a [cr:b]am file and generates a count of coverage of each allele [ACGT] at that location (given any filter settings). Altered so that it clips all reads by n bases to reduce reference bias.\n\npython FixVaf.py [vcf file] [bam file] [fasta file].\n\nThe alleleCount package primarily exists to prevent code duplication between some other projects, specifically AscatNGS and Battenberg.\n\nRequires python 3 with psam installed.\n\nThe project previously contained 2 equivalent implementations of allele counting code in perl and C for BAM CRAM processing",
                "GPU": false,
                "CPU": false,
                "ram": true,
                "parallel": false,
                "distributed": false
            },
            "GenomicsDB": {
                "Name": "GenomicsDB",
                "Description": "Advancing clinical cohort selection with genomics analysis on a distributed platform.\n\nHighly performant data storage in C++ for importing, querying and transforming variant data with Java/Spark. Used in gatk4.\n\nSparse Array Storage for Genomics.\n\nGenomicsDB, originally from Intel Health and Lifesciences, is built on top of a fork of htslib and a tile-based array storage system for importing, querying and transforming variant data.\n\nOpen source project providing a collaboration to optimizing sparse array storage for genomics.\n\nUsing high-level APIs provided in C++, Java*, and Spark*, users can both write and read variant records to and from GenomicsDB shared-nothing instances in parallel using multiple processes in a Single Process Multiple Data (SPMD) manner.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": true
            },
            "malacoda": {
                "Name": "malacoda",
                "Description": "Bayesian modelling of high-throughput sequencing assays with malacoda.\n\nThe goal of malacoda is to enable Bayesian analysis of high-throughput genomic assays like massively parallel reporter assays (MPRA) and CRISPR screens.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "mare": {
                "Name": "MaRe",
                "Description": "Processing Big Data with application containers on Apache Spark.\n\nItalian, pronounced: /\u02c8mare/. Noun: Sea.\n\nMaRe has been developed with scientific application in mind. High-throughput methods produced massive datasets in the past decades, and using frameworks like Spark and Hadoop is a natural choice to enable high-throughput analysis. In scientific applications, many tools are highly optimized to resemble, or detect some phenomena that occur in a certain system. Hence, sometimes the effort of reimplementing scientific tools in Spark or Hadoop can't be sustained by research groups. MaRe aims to provide the means to run existing serial tools in MapReduce fashion. Since many of the available scientific tools are trivially parallelizable, MapReduce is an excellent paradigm that can be used to parallelize the computation.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "MaveDB": {
                "Name": "MaveDB",
                "Description": "An open-source platform to distribute and interpret data from multiplexed assays of variant effect.\n\nTable of Multiplexed Assay of Variant Effect (MAVE) studies.\n\nMaveDB - A repository for MAVE assay datasets.\n\nTo cite this document, please use the citation details for MaveDB.\n\nMaveDB is a public repository for datasets from Multiplexed Assays of Variant Effect (MAVEs), such as those generated by deep mutational scanning (DMS) or massively parallel reporter assay (MPRA) experiments.\n\nWelcome to our table of Multiplexed Assay of Variant Effect (MAVE) studies. To contribute a study or amend/expand an existing entry, please use the GitHub issue tracker or create a pull request",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "MySeq": {
                "Name": "MySeq",
                "Description": "Privacy-protecting browser-based personal Genome analysis for genomics education and exploration.\n\nMySeq is a web-application for privacy-protecting interactive analysis of personal genomes (distributed as compressed-and-indexed VCF files) inspired by GENOtation (previously the Interpretome) and DNA.LAND Compass. MySeq is intended for use as a genomics educational platform.\n\nAnalyzing the PTC Tasting Phenotype with MySeq.\n\nThis page is an example analysis of the 'bitter tasting' trait using the MySeq application in an embedded context. Here MySeq is used to both query a whole genome VCF for NA12878 (from Genome in a Bottle) by genomic coordinates and predict the bitter tasting phenotype directly. All of the queries demonstrated here are performed 'live' in the browser, that is these are not pre-generated results. Try MySeq as a 'standalone' application.\n\nMySeq is a single-page web application for privacy-protecting personal genome analysis",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            },
            "nubeam-dedup": {
                "Name": "Nubeam-dedup",
                "Description": "A fast and RAM-efficient tool to de-duplicate sequencing reads without mapping.\n\nnubeam-dedup is a fast and easy-to-use bioinformatics tool removing exact PCR duplicates for sequencing reads, single-end or paired-end. We appreciate your interest in nubeam-dedup. If you use nubeam-dedup, please kindly cite:.",
                "GPU": false,
                "CPU": false,
                "ram": true,
                "parallel": false,
                "distributed": false
            },
            "qbed": {
                "Name": "qBED",
                "Description": "a novel genome browser visualization for point processes.\n\nTransposon calling cards is a genomic assay for identifying transcription factor binding sites in both bulk and single cell experiments. Here we describe the qBED format, an open, text-based standard for encoding and analyzing calling card data. In parallel, we introduce the qBED track on the WashU Epigenome Browser, a novel visualization that enables researchers to inspect calling card data in their genomic context. Finally, through examples, we demonstrate that qBED files can be used to visualize non-calling card datasets, such as CADD scores and GWAS eQTL hits, and may have broad utility to the genomics community",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "quickbam": {
                "Name": "quickBAM",
                "Description": "Parallelized BAM file access API for high-throughput sequence analysis informatics.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "rariant": {
                "Name": "Rariant",
                "Description": "This package identifies single nucleotide variants from sequencing data based on the difference of binomially distributed mismatch rates between matched samples.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            },
            "rubioseq": {
                "Name": "RUbioSeq",
                "Description": "Primary and secondary analysis of resequencing projects by an integrated software suite of parallelized pipelines to detect exome variants (SNVs and CNVs) and to perform Bisulfite-seq analyses automatically.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "seqsphere": {
                "Name": "SeqSphere+",
                "Description": "This software is designed for distributed work-groups (client/server model) and allows automatic processing, assembling and analyzing NGS (e.g., Illumina, Ion Torrent or PacBio) and Sanger capillary-electrophoresis sequence data. It provides with an easy and automated microbial analysis; enabling your lab to employ whole genome microbial typing (cgMLST or MLST+), traditional MLST or eMLST/rMLST sequencing projects.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            },
            "sitepath": {
                "Name": "sitePath",
                "Description": "A visual tool to identify polymorphism clades and help find fixed and parallel mutations.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "somalier": {
                "Name": "somalier",
                "Description": "rapid relatedness estimation for cancer and germline studies using efficient genome sketches.\n\nfast sample-swap and relatedness checks on BAMs/CRAMs/VCFs/GVCFs.\n\nsomalier: extract informative sites, evaluate relatedness, and perform quality-control on BAM/CRAM/BCF/VCF/GVCF.\n\nNote that the somalier relate command runs extremely quickly (< 2 seconds for 600 samples and ~1 minute for 4,500 samples) so it's possible to add/remove samples or adjust a pedigree file and re-run iteratively",
                "GPU": false,
                "CPU": false,
                "ram": true,
                "parallel": false,
                "distributed": false
            },
            "sv-plaudit": {
                "Name": "SV-plaudit",
                "Description": "A cloud-based framework for manually curating thousands of structural variants.\n\nSV-plaudit: A cloud-assisted framework manually curating thousands of structural variants.\n\nSV-plaudit provides a pipeline for creating image views of genomic intervals, automatically storing them in the cloud, deploying a website to view/score them, and retrieving scores for analysis. SV-plaudit supports image generation sequencing data from BAM or CRAM files from Illumina paired-end sequencing, PacBio or Oxford Nanopore Technologies long-read sequencing, or 10X Genomics linked-read sequencing.\n\nSource code and documentation:https://github.com/jbelyeu/SV-plaudit.",
                "GPU": false,
                "CPU": false,
                "ram": true,
                "parallel": false,
                "distributed": false
            },
            "tiddit": {
                "Name": "TIDDIT",
                "Description": "Efficient and comprehensive structural variant caller for massive parallel sequencing data. Identify chromosomal rearrangements using Mate Pair or Paired End sequencing data. It allows identification of intra and inter-chromosomal translocations, deletions, tandem-duplications and inversions, using supplementary alignments as well as discordant pairs.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "vcascale": {
                "Name": "VCaScale",
                "Description": "Variant Calling at Scale is a scalable, parallel and efficient implementation of next generation sequencing data pre-processing and variant calling workflows. Our design tightly integrates most pre-processing workflow stages, using Spark built-in functions to sort reads by coordinates, and mark duplicates efficiently. A cluster scaled DeepVariant for both CPU-only and CPU+GPU clusters is also integrated in this workflow.",
                "GPU": true,
                "CPU": true,
                "ram": false,
                "parallel": true,
                "distributed": false
            }
        }
    },
    "operation_0283": {
        "Name": "Linkage analysis",
        "Count": 2,
        "Tools": {
            "batchmap": {
                "Name": "BatchMap",
                "Description": "Parallel implementation of the OneMap R package for fast computation of F1 linkage maps in outcrossing species.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "gads": {
                "Name": "GADS",
                "Description": "Software for Genetic Analyses of quantitative traits Distributed with Spike on the base of large pedigrees without loops.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            }
        }
    },
    "operation_2436": {
        "Name": "Gene-set enrichment analysis",
        "Count": 7,
        "Tools": {
            "bbrowser": {
                "Name": "BBrowser",
                "Description": "BBrowser allows biologists to handle scRNA-seq data without programming knowledge. Intuitive operation. Functions are updated. It has a new CITE-seq dashboard, a complete package for interactively exploring single-cell gene expression data in parallel with surface protein information.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "chromscape": {
                "Name": "ChromSCape",
                "Description": "ChromSCape is a user-friendly interactive Shiny/R application distributed as a Bioconductor package, that processes single-cell epigenomic data to assist the biological interpretation of chromatin landscapes within cell populations. ChromSCape analyses the distribution of repressive and active histone modifications as well as chromatin accessibility landscapes from single-cell datasets.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            },
            "flexgsea": {
                "Name": "flexgsea",
                "Description": "Flexgsea is a R package to do gene set enrichment analysis. Main advantages:\n  - Allows user defined functions. So you can use you favorite package for differential expression.\n  - Calculates significance by sample permutation.\n  - Parallelization using the foreach package.\n  - Can calculate normalized enrichment scores (NES) and significance based on that.\n  - Implements the weighted KS-like statistic.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "gage": {
                "Name": "gage",
                "Description": "Published method for gene set (enrichment or GSEA) or pathway analysis. It is generally applicable independent of microarray or RNA-Seq data attributes and consistently achieves superior performance over other frequently used methods. We provide functions for basic analysis, result processing and presentation. We have also built pipeline routines for of multiple analyses in a batch, comparison between parallel analyses, and combined analysis of heterogeneous data from different sources/studies.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "gseabenchmarker": {
                "Name": "GSEABenchmarkeR",
                "Description": "It implements an extendable framework for reproducible evaluation of set- and network-based methods for enrichment analysis of gene expression data. This includes support for the efficient execution of these methods on comprehensive real data compendia using parallel computation on standard workstations and institutional computer grids.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "GsVec": {
                "Name": "GsVec",
                "Description": "Comprehensive biological interpretation of gene signatures using semantic distributed representation.\n\nGsVec (Gene signature Vector) is an analysis method that supports the biological interpretation of Gene signature obtained by gene expression analysis of Bioinformatics. The association between the gene signature to be interpreted and the gene signature of the Pathway / Gene Ontology data base is performed by natural language processing",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            },
            "OLOGRAM": {
                "Name": "OLOGRAM",
                "Description": "Determining significance of total overlap length between genomic regions sets.\n\nMOTIVATION:Various bioinformatics analyses provide sets of genomic coordinates of interest. Whether two such sets possess a functional relation is a frequent question. This is often determined by interpreting the statistical significance of their overlaps. However, only few existing methods consider the lengths of the overlap, and they do not provide a resolutive p-value. RESULTS:Here, we introduce OLOGRAM, which performs overlap statistics between sets of genomic regions described in BEDs or GTF. It uses Monte Carlo simulation, taking into account both the distributions of region and inter-region lengths, to fit a negative binomial model of the total overlap length. Exclusion of user-defined genomic areas during the shuffling is supported.",
                "GPU": false,
                "CPU": false,
                "ram": true,
                "parallel": false,
                "distributed": false
            }
        }
    },
    "operation_0233": {
        "Name": "Sequence conversion",
        "Count": 1,
        "Tools": {
            "bigseqkit": {
                "Name": "BigSeqKit",
                "Description": "The Next Generation Sequencing (NGS) raw data are stored in FASTA and FASTQ text-based file formats. Common operations on FASTA/Q files include searching, filtering, sampling, deduplication and sorting, among others. We can find several tools in the literature for FASTA/Q file manipulation but none of them are well fitted for large files of tens of GB (likely TBs in the near future) since mostly they are based on sequential processing. The exception is seqkit that allows some routines to use a few threads but, in any case, the scalability is very limited. To deal with this issue, we introduce BigSeqKit, a parallel toolkit to manipulate FASTA/Q files at scale with speed and scalability at its core. BigSeqKit takes advantage of an HPC-Big Data framework (IgnisHPC) to parallelize and optimize the commands included in seqkit. In this way, in most cases it is from tens to hundreds of times faster than other state-of-the-art tools such as seqkit, samtools and pyfastx.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            }
        }
    },
    "operation_0371": {
        "Name": "DNA translation",
        "Count": 1,
        "Tools": {
            "bigseqkit": {
                "Name": "BigSeqKit",
                "Description": "The Next Generation Sequencing (NGS) raw data are stored in FASTA and FASTQ text-based file formats. Common operations on FASTA/Q files include searching, filtering, sampling, deduplication and sorting, among others. We can find several tools in the literature for FASTA/Q file manipulation but none of them are well fitted for large files of tens of GB (likely TBs in the near future) since mostly they are based on sequential processing. The exception is seqkit that allows some routines to use a few threads but, in any case, the scalability is very limited. To deal with this issue, we introduce BigSeqKit, a parallel toolkit to manipulate FASTA/Q files at scale with speed and scalability at its core. BigSeqKit takes advantage of an HPC-Big Data framework (IgnisHPC) to parallelize and optimize the commands included in seqkit. In this way, in most cases it is from tens to hundreds of times faster than other state-of-the-art tools such as seqkit, samtools and pyfastx.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            }
        }
    },
    "operation_0372": {
        "Name": "DNA transcription",
        "Count": 1,
        "Tools": {
            "bigseqkit": {
                "Name": "BigSeqKit",
                "Description": "The Next Generation Sequencing (NGS) raw data are stored in FASTA and FASTQ text-based file formats. Common operations on FASTA/Q files include searching, filtering, sampling, deduplication and sorting, among others. We can find several tools in the literature for FASTA/Q file manipulation but none of them are well fitted for large files of tens of GB (likely TBs in the near future) since mostly they are based on sequential processing. The exception is seqkit that allows some routines to use a few threads but, in any case, the scalability is very limited. To deal with this issue, we introduce BigSeqKit, a parallel toolkit to manipulate FASTA/Q files at scale with speed and scalability at its core. BigSeqKit takes advantage of an HPC-Big Data framework (IgnisHPC) to parallelize and optimize the commands included in seqkit. In this way, in most cases it is from tens to hundreds of times faster than other state-of-the-art tools such as seqkit, samtools and pyfastx.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            }
        }
    },
    "operation_2403": {
        "Name": "Sequence analysis",
        "Count": 7,
        "Tools": {
            "biocparallel": {
                "Name": "BiocParallel",
                "Description": "This package provides modified versions and novel implementation of functions for parallel evaluation, tailored to use with BioConductor objects.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "Dr.seq2": {
                "Name": "Dr.seq2",
                "Description": "A quality control and analysis pipeline for parallel single cell transcriptome and epigenome data. It provides quality control and analysis functionalities for three data types: single cell transcriptome data, Drop-ChIP data and scATAC-seq data.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "hpg_pore": {
                "Name": "HPG pore",
                "Description": "Toolkit to explore and analyze nanopore sequencing data that can run both on a single computer and on the Hadoop distributed computing framework.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            },
            "navise": {
                "Name": "NaviSE",
                "Description": "User-friendly streamlined tool which performs a fully-automated parallel processing of genome-wide epigenomics data from sequencing files into a final report, built with a comprehensive set of annotated files that are navigated through a graphic user interface.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "rapidgsea": {
                "Name": "rapidGSEA",
                "Description": "We present rapidGSEA \u2013 a software suite consisting of two tools for facilitating permutation-based gene set enrichment analysis(GSEA): cudaGSEA and ompGSEA. cudaGSEA is a CUDA-accelerated tool using fine-grained parallelization schemes on massively parallel architectures while ompGSEA is a coarse-grained multi-threaded tool for multi-core CPUs.",
                "GPU": false,
                "CPU": true,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "sambamba": {
                "Name": "Sambamba",
                "Description": "This tool is a high performance modern robust and fast tool (and library), written in the D programming language, for working with SAM, BAM and CRAM formats.",
                "GPU": false,
                "CPU": false,
                "ram": true,
                "parallel": false,
                "distributed": false
            },
            "sbwt": {
                "Name": "sBWT",
                "Description": "A Burrows\u2013Wheeler transformation BWT based fast indexer/aligner specialized in parallelized indexing and searching for Next Generation Sequencing data.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            }
        }
    },
    "operation_0253": {
        "Name": "Sequence feature detection",
        "Count": 2,
        "Tools": {
            "biosigner": {
                "Name": "biosigner",
                "Description": "This package implements a new method to assess the relevance of the variables for the prediction performances of the classifier. The approach can be run in parallel with the PLS-DA, Random Forest, and SVM binary classifiers. The signatures and the corresponding 'restricted' models are returned, enabling future predictions on new datasets.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "FastFeatGen": {
                "Name": "FastFeatGen",
                "Description": "Faster parallel feature extraction from genome sequences and efficient prediction of DNA N6-methyladenine sites.\n\nFaster parallel feature extraction from genome sequence.\n\nThis is a tool for faster feature extraction from genome sequences and making efficient prediction. To build efficient prediction model, user can go through the following instructions step by step. If user only wants to predict query sequences from our built model, then just go to step Make prediction for query sequences. Currently, FastFeatGen supports text file as shown in dataset.txt file in datasets directory; however, fasta file can also be used with a simple preprocessing",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            }
        }
    },
    "operation_0488": {
        "Name": "Linkage disequilibrium calculation",
        "Count": 5,
        "Tools": {
            "BIRD": {
                "Name": "BIRD",
                "Description": "Bayesian Estimation of Genetic Regulatory Effects in High-throughput Reporter Assays | Bayesian Inference of Regulatory Differences | Photo by Bill Majoros. Used with permission | [6/16/2018] First version of BIRD released - The first version of BIRD has been released on GitHub at https://github.com/bmajoros/BIRD | [8/23/2018] Experiment design web tool released - A web tool is now available for power and sample size estimation: http://67.159.92.22:8080/ | BIRD (Bayesian Inference of Regulatory Differences) is a software suite for identifying regulatory variants in data from STARR-seq and other massively parallel reporter assays (MPRAs)",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "gbc": {
                "Name": "GBC",
                "Description": "Parallel toolkit based on highly addressable byte-encoding blocks for extremely large-scale genotypes of species.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "ldkit": {
                "Name": "LDkit",
                "Description": "A parallel computing toolkit for linkage disequilibrium analysis.\n\nGUI package is under the GUI folder, please double-click the LDkit_GUI.jar to start.\n\nRun using Graphic User Interface (GUI).",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "quickld": {
                "Name": "quickLD",
                "Description": "quickLD (qLD) is a tool to calculate Linkage disequilibrium (the non-random association between alleles at different loci), with highly efficient CPU and GPU kernels that utilize dense linear algebra (DLA) operations.",
                "GPU": true,
                "CPU": true,
                "ram": false,
                "parallel": false,
                "distributed": false
            },
            "snpint-gpu": {
                "Name": "SNPInt-GPU",
                "Description": "SNPInt-GPU is a software providing several methods for statistical epistasis testing. SNPInt-GPU supports GPU acceleration, but can also be used without GPU hardware. The software implements logistic regression (as in PLINK epistasis testing), BOOST, log-linear regression, mutual information (MI) and information gain (IG) for pairwise testing as well as mutual information and information gain for third-order tests.",
                "GPU": true,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": false
            }
        }
    },
    "operation_0484": {
        "Name": "SNP detection",
        "Count": 7,
        "Tools": {
            "bis-snp": {
                "Name": "Bis-SNP",
                "Description": "A package based on the Genome Analysis Toolkit map-reduce framework for genotyping in bisulfite treated massively parallel sequencing on Illumina platform. It uses bayesian inference with either manually specified or automatically estimated methylation probabilities of different cytosine context(not only CpG, CHH, CHG in Bisulfite-seq, but also GCH et.al. in other bisulfite treated sequencing) to determine genotypes and methylation levels simultaneously.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "elssi": {
                "Name": "ELSSI",
                "Description": "Ensemble learning-based approach (ELSSI): parallel SNP-SNP interactions detection by ensemble multi-type detectors.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "ICGRM": {
                "Name": "ICGRM",
                "Description": "Integrative construction of genomic relationship matrix combining multiple genomic regions for big dataset.\n\nBACKGROUND:Genomic prediction is an advanced method for estimating genetic values, which has been widely accepted for genetic evaluation in animal and disease-risk prediction in human. It estimates genetic values with genome-wide distributed SNPs instead of pedigree. The key step of it is to construct genomic relationship matrix (GRM) via genome-wide SNPs; however, usually the calculation of GRM needs huge computer memory especially when the SNP number and sample size are big, so that sometimes it will become computationally prohibitive even for super computer clusters. We herein developed an integrative algorithm to compute GRM.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            },
            "malvirus": {
                "Name": "MALVIRUS",
                "Description": "MALVIRUS is a fast and accurate tool for genotyping haploid individuals that does not require to assemble the read nor mapping them to a reference genome. It is tailored to work with virological data and can genotype an individual directly from sequencing data in minutes.\n\nMALVIRUS is divided into two logically distinct steps: the creation of a variant catalog from a set of assemblies and the genotype calling. The first step is based on mafft and snp-sites, whereas the second step is based on KMC and MALVA.\n\nThe variant catalog can be built once and reused for genotyping multiple individuals.\n\nPlease see the website for additional details.\n\nMALVIRUS is distributed as a Docker image and is publicly available on GitHub and Docker Hub under the terms of the GNU General Public License version 3 or later. MALVIRUS was mainly developed and tested under Ubuntu GNU/Linux version 18.04 but works wherever Docker is available.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            },
            "multinanopolish": {
                "Name": "MultiNanopolish",
                "Description": "Refined grouping method for reducing redundant calculations in nanopolish.\n\nNanopolish is a software package for signal-level analysis of Oxford Nanopore sequencing data. Nanopolish can calculate an improved consensus sequence for a draft genome assembly, detect base modifications, call SNPs and indels with respect to a reference genome and more (see Nanopolish for more details).\n\nWe present an efficient implementation of Nanopolish, called MultiNanopolish. MultiNanopolish use a different iterative calculation strategy to reduce redundant calculations. We propose an abstract concept, namely independent computing unit(GroupTask) which can be distributed to the thread pool for multi-thread concurrent computing.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            },
            "snppar": {
                "Name": "SNPPar",
                "Description": "identifying convergent evolution and other homoplasies from microbial whole-genome alignments.\n\nData and scripts for testing SNPPar with either simulated or empirical datasets.\n\nSNPPar is designed to find homoplasic SNPs based on a user-defined phylogenetic tree - more specifically, it searches for those SNPs that are: parallel - same mutation (eg. A ~> T) @ same position in two (or more) unrelated groups/isolates; convergent - different mutation in resulting in same base (eg. A ~> T, C ~> T) @ same position in two (or more) unrelated groups/isolates; and/or revertant - mutation back to ancestral state (eg. A ~> T ~> A).\n\nThese are self-contained datasets, including reference(s), tree and snp_table(s) required to run SNPPar. The instructions for each are below in 10. Published Datasets.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "wish-r": {
                "Name": "WISH-R",
                "Description": "WISH-R package (WISH-R) can calculate epistatic interactions using a linear or generalized linear model on a genome-wide level using genomic data and phenotype/disease data in a fully parallelized environment, and visualize genome-wide epistasis in many ways.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            }
        }
    },
    "operation_3186": {
        "Name": "Bisulfite mapping",
        "Count": 2,
        "Tools": {
            "bis-snp": {
                "Name": "Bis-SNP",
                "Description": "A package based on the Genome Analysis Toolkit map-reduce framework for genotyping in bisulfite treated massively parallel sequencing on Illumina platform. It uses bayesian inference with either manually specified or automatically estimated methylation probabilities of different cytosine context(not only CpG, CHH, CHG in Bisulfite-seq, but also GCH et.al. in other bisulfite treated sequencing) to determine genotypes and methylation levels simultaneously.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "P3BSseq": {
                "Name": "P3BSseq",
                "Description": "Parallel processing pipeline software for automatic analysis of bisulfite sequencing data.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            }
        }
    },
    "operation_3204": {
        "Name": "Methylation analysis",
        "Count": 2,
        "Tools": {
            "bis-snp": {
                "Name": "Bis-SNP",
                "Description": "A package based on the Genome Analysis Toolkit map-reduce framework for genotyping in bisulfite treated massively parallel sequencing on Illumina platform. It uses bayesian inference with either manually specified or automatically estimated methylation probabilities of different cytosine context(not only CpG, CHH, CHG in Bisulfite-seq, but also GCH et.al. in other bisulfite treated sequencing) to determine genotypes and methylation levels simultaneously.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "MCSeEd": {
                "Name": "MCSeEd",
                "Description": "A reference-free, whole genome profiling system to address cytosine/adenine methylation changes.\n\nMethods for investigating DNA methylation nowadays either require a reference genome and high coverage, or investigate only CG methylation. Moreover, no large-scale analysis can be performed for N6-methyladenosine (6 mA) at an affordable price. Here we describe the methylation content sensitive enzyme double-digest restriction-site-associated DNA (ddRAD) technique (MCSeEd), a reduced-representation, reference-free, cost-effective approach for characterizing whole genome methylation patterns across different methylation contexts (e.g., CG, CHG, CHH, 6 mA). MCSeEd can also detect genetic variations among hundreds of samples. MCSeEd is based on parallel restrictions carried out by combinations of methylation insensitive and sensitive endonucleases, followed by next-generation sequencing.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            }
        }
    },
    "operation_0496": {
        "Name": "Global alignment",
        "Count": 4,
        "Tools": {
            "bitpai": {
                "Name": "BitPAI",
                "Description": "A bit-parallel algorithm for general, integer-scoring global alignment. Integer-scoring schemes assign integer weights for match, mismatch and insertion/deletion. This method uses structural properties in the relationship between adjacent scores in the scoring matrix to construct classes of efficient algorithms, each designed for a particular set of weights.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "GASAL2": {
                "Name": "GASAL2",
                "Description": "a GPU accelerated sequence alignment library for high-throughput NGS data.\n\nGASAL2 - GPU-accelerated DNA alignment library.\n\nGASAL2 is an easy-to-use CUDA library for DNA/RNA sequence alignment algorithms. Currently it supports different kind of alignments:.\n\nA Linux platform with CUDA toolkit 8 or higher is required, along with usual build environment for C and C++ code. GASAL2 has been tested over NVIDIA GPUs with compute capabilities of 2.0, 3.5 and 5.0. Although lower versions of the CUDA framework might work, they have not been tested",
                "GPU": true,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": false
            },
            "msaprobs-mpi": {
                "Name": "MSAProbs-MPI",
                "Description": "Fast and Accurate Multiple Sequence Alignment with MSAProbs-MPI.\n\nParallel and accurate multiple sequence alignment.\n\nMSAProbs is a well-established state-of-the-art multiple sequence alignment algorithm for protein sequences.\n\nMSAProbs-MPI is a parallelization of MSAProbs (v0.9.7) using MPI for distributed-memory systems.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": true
            },
            "retrieve_and_relate": {
                "Name": "Retrieve and Relate",
                "Description": "Retrieve similar sequences beginning from DNA, RNA or Proteins as well as free text - meaning there is no need to set any preliminary search parameters or filters which restrict the search space. Out of the box your search in parallel 11 of the most popular databases. Average alignment takes less then 3 seconds. Adding your own database is as simple as a click of the button.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            }
        }
    },
    "operation_0491": {
        "Name": "Pairwise sequence alignment",
        "Count": 7,
        "Tools": {
            "blvector": {
                "Name": "BLVector",
                "Description": "BLVector is a fast BLAST-Like Aagorithm for multicore CPU with vectorization.  BLVector produces a list in a similar way than BLAST. BLVector provides a score based on the result of a Smith-Waterman algorithm with affine gaps which is the result of applying a score matrix like BLOSUM62 or PAM30.",
                "GPU": false,
                "CPU": true,
                "ram": false,
                "parallel": false,
                "distributed": false
            },
            "deepnog": {
                "Name": "DeepNOG",
                "Description": "DeepNOG is a tool for protein orthologous groups assignment. Assign proteins to orthologous groups (eggNOG 5) on CPUs or GPUs with deep networks. DeepNOG is much faster than alignment-based methods, providing accuracy similar to HMMER.",
                "GPU": true,
                "CPU": true,
                "ram": false,
                "parallel": false,
                "distributed": false
            },
            "GASAL2": {
                "Name": "GASAL2",
                "Description": "a GPU accelerated sequence alignment library for high-throughput NGS data.\n\nGASAL2 - GPU-accelerated DNA alignment library.\n\nGASAL2 is an easy-to-use CUDA library for DNA/RNA sequence alignment algorithms. Currently it supports different kind of alignments:.\n\nA Linux platform with CUDA toolkit 8 or higher is required, along with usual build environment for C and C++ code. GASAL2 has been tested over NVIDIA GPUs with compute capabilities of 2.0, 3.5 and 5.0. Although lower versions of the CUDA framework might work, they have not been tested",
                "GPU": true,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": false
            },
            "lara_2": {
                "Name": "LaRA 2",
                "Description": "Parallel and vectorized program for sequence-structure alignment of RNA sequences.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "msaprobs-mpi": {
                "Name": "MSAProbs-MPI",
                "Description": "Fast and Accurate Multiple Sequence Alignment with MSAProbs-MPI.\n\nParallel and accurate multiple sequence alignment.\n\nMSAProbs is a well-established state-of-the-art multiple sequence alignment algorithm for protein sequences.\n\nMSAProbs-MPI is a parallelization of MSAProbs (v0.9.7) using MPI for distributed-memory systems.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": true
            },
            "scrooge": {
                "Name": "Scrooge",
                "Description": "A fast and memory-frugal genomic sequence aligner for CPUs, GPUs and ASICs.",
                "GPU": true,
                "CPU": true,
                "ram": false,
                "parallel": false,
                "distributed": false
            },
            "winbioinftools": {
                "Name": "WinBioinfTools",
                "Description": "Bioinformatics Tools for Windows Cluster provides: 1) CoCoNUT for pairwise genome comparison, 2) parallel BLAST for biological database search, and 3) parallel global pairwise sequence alignment  running over Windows Cluster running Windows HPC server 2008.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            }
        }
    },
    "operation_0436": {
        "Name": "Coding region prediction",
        "Count": 2,
        "Tools": {
            "cate": {
                "Name": "CATE",
                "Description": "A fast and scalable CUDA implementation to conduct highly parallelized evolutionary tests on large scale genomic data.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "orfipy": {
                "Name": "orfipy",
                "Description": "A fast and flexible tool for extracting ORFs.\n\norfipy is a tool written in python/cython to extract ORFs in extremely an fast and flexible manner. Other popular ORF searching tools are OrfM and getorf. Compared to OrfM and getorf, orfipy provides the most options to fine tune ORF searches. orfipy uses multiple CPU cores and is particularly faster for data containing multiple smaller fasta sequences such as de-novo transcriptome assemblies. Please read the preprint here.",
                "GPU": false,
                "CPU": true,
                "ram": false,
                "parallel": false,
                "distributed": false
            }
        }
    },
    "operation_3197": {
        "Name": "Genetic variation analysis",
        "Count": 10,
        "Tools": {
            "cate": {
                "Name": "CATE",
                "Description": "A fast and scalable CUDA implementation to conduct highly parallelized evolutionary tests on large scale genomic data.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "delly2": {
                "Name": "Delly2",
                "Description": "Integrated structural variant prediction method that can discover, genotype and visualize deletions, tandem duplications, inversions and translocations at single-nucleotide resolution in short-read massively parallel sequencing data. It uses paired-ends and split-reads to sensitively and accurately delineate genomic rearrangements throughout the genome. Structural variants can be visualized using Delly-maze and Delly-suave.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "genomicfiles": {
                "Name": "GenomicFiles",
                "Description": "This package provides infrastructure for parallel computations distributed 'by file' or 'by range'. User defined MAPPER and REDUCER functions provide added flexibility for data combination and manipulation.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": true
            },
            "mendeliht.jl": {
                "Name": "MendelIHT.jl",
                "Description": "Implements iterative hard thresholding as a multiple regression model for GWAS. Built-in support for handling PLINK and VCF files, parallel computing, fits a variety of GLM models, and handles group/weighting SNPs.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "parallelnewhybrid": {
                "Name": "parallelnewhybrid",
                "Description": "An R package for the parallelization of hybrid detection using newhybrid.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "picard_tools": {
                "Name": "Picard",
                "Description": "A set of command line tools for manipulating high-throughput sequencing (HTS) data in formats such as SAM/BAM/CRAM and VCF. Available as a standalone program or within the GATK4 program.",
                "GPU": false,
                "CPU": false,
                "ram": true,
                "parallel": false,
                "distributed": false
            },
            "seqseg": {
                "Name": "SeqSeg",
                "Description": "An algorithm to detect and localize copy-number alterations from massively parallel sequence data.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "sv-gen": {
                "Name": "sv-gen",
                "Description": "Highly portable parallel workflow to generate artificial genomes with structural variants.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "sweed": {
                "Name": "SweeD",
                "Description": "Parallel and checkpointable tool implementing a composite ratio test for detecting selective sweeps. SweeD is based on the SweepFinder algorithm. SweeD can calculate the theoretical SFS of a give demographic model (stepwise changes or with an exponential growth phase + stepwise changes) using the method of Zickovic and Stephan (2011).",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "varsifter": {
                "Name": "VarSifter",
                "Description": "Graphical java program designed to display, sort, filter, and generally sift variation data from massively parallel sequencing experiments.It is designed to read exome-scale variation data in either a tab-delimited text file with header, or an uncompressed VCF file (see User Guide for details.) These files should be pre-generated with desired annotation information one would like to view.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            }
        }
    },
    "operation_0264": {
        "Name": "Alternative splicing prediction",
        "Count": 1,
        "Tools": {
            "catsnap": {
                "Name": "Catsnap",
                "Description": "A user-friendly algorithm for determining the conservation of protein variants reveals extensive parallelisms in the evolution of alternative splicing.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            }
        }
    },
    "operation_0366": {
        "Name": "Protein sequence cleavage",
        "Count": 1,
        "Tools": {
            "cbs_das_protein_viewer": {
                "Name": "CBS DAS protein viewer",
                "Description": "Protein viewer which uses the distributed annotation system (DAS) to integrate and present annotation data from multiple sources for a protein sequence.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            }
        }
    },
    "operation_2451": {
        "Name": "Sequence comparison",
        "Count": 2,
        "Tools": {
            "cbs_das_protein_viewer": {
                "Name": "CBS DAS protein viewer",
                "Description": "Protein viewer which uses the distributed annotation system (DAS) to integrate and present annotation data from multiple sources for a protein sequence.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            },
            "ribodetector": {
                "Name": "RiboDetector",
                "Description": "RiboDetector is a software developed to accurately yet rapidly detect and remove rRNA sequences from metagenomeic, metatranscriptomic, and ncRNA sequencing data. It was developed based on LSTMs and optimized for both GPU and CPU.",
                "GPU": true,
                "CPU": true,
                "ram": false,
                "parallel": false,
                "distributed": false
            }
        }
    },
    "operation_2479": {
        "Name": "Protein sequence analysis",
        "Count": 3,
        "Tools": {
            "cbs_das_protein_viewer": {
                "Name": "CBS DAS protein viewer",
                "Description": "Protein viewer which uses the distributed annotation system (DAS) to integrate and present annotation data from multiple sources for a protein sequence.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            },
            "coils": {
                "Name": "COILS",
                "Description": "Program that compares a sequence to a database of known parallel two-stranded coiled-coils and derives a similarity score. By comparing this score to the distribution of scores in globular and coiled-coil proteins, the program then calculates the probability that the sequence will adopt a coiled-coil conformation.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "vkcdb": {
                "Name": "VKCDB",
                "Description": "The Voltage-gated K(+) Channel DataBase contains full-length or nearly full-length unique channel sequences from Bacteria, Archaea and Eukaryotes. Corresponding nucleotide sequences of the open reading frames corresponding to the amino acid sequences are now available and can be extracted in parallel with sets of protein sequences. Channels are categorized into subfamilies by phylogenetic analysis and by using hidden Markov model analyses.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            }
        }
    },
    "operation_3228": {
        "Name": "Structural variation detection",
        "Count": 4,
        "Tools": {
            "chinook": {
                "Name": "Chinook",
                "Description": "Chinook is a peer-to-peer (P2P) service for the discovery, use and assessment of bioinformatics programs. Chinook Online allows researchers to connect and run distributed bioinformatics programs using a web application.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            },
            "delly2": {
                "Name": "Delly2",
                "Description": "Integrated structural variant prediction method that can discover, genotype and visualize deletions, tandem duplications, inversions and translocations at single-nucleotide resolution in short-read massively parallel sequencing data. It uses paired-ends and split-reads to sensitively and accurately delineate genomic rearrangements throughout the genome. Structural variants can be visualized using Delly-maze and Delly-suave.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "sv-callers": {
                "Name": "sv-callers",
                "Description": "Highly portable parallel workflow to detect structural variants in cancer genomes.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "tiddit": {
                "Name": "TIDDIT",
                "Description": "Efficient and comprehensive structural variant caller for massive parallel sequencing data. Identify chromosomal rearrangements using Mate Pair or Paired End sequencing data. It allows identification of intra and inter-chromosomal translocations, deletions, tandem-duplications and inversions, using supplementary alignments as well as discordant pairs.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            }
        }
    },
    "operation_3891": {
        "Name": "Essential dynamics",
        "Count": 13,
        "Tools": {
            "chromscape": {
                "Name": "ChromSCape",
                "Description": "ChromSCape is a user-friendly interactive Shiny/R application distributed as a Bioconductor package, that processes single-cell epigenomic data to assist the biological interpretation of chromatin landscapes within cell populations. ChromSCape analyses the distribution of repressive and active histone modifications as well as chromatin accessibility landscapes from single-cell datasets.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            },
            "DDVFA": {
                "Name": "DDVFA",
                "Description": "Distributed dual vigilance fuzzy adaptive resonance theory learns online, retrieves arbitrarily-shaped clusters, and mitigates order dependence. Dual Vigilance Fuzzy ART - Companion MATLAB Code. Distributed Dual Vigilance Fuzzy ART - Companion MATLAB Code.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            },
            "dpn-sa": {
                "Name": "DPN-SA",
                "Description": "The deep propensity network using a sparse autoencoder (DPN-SA) is a deep learning architecture for propensity score matching and counterfactual prediction to tackle the problems of high dimensionality, nonlinear/nonparallel treatment assignment, and residual confounding when estimating treatment effects.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "gbc": {
                "Name": "GBC",
                "Description": "Parallel toolkit based on highly addressable byte-encoding blocks for extremely large-scale genotypes of species.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "GLM-PCA": {
                "Name": "GLM-PCA",
                "Description": "Feature selection and dimension reduction for single-cell RNA-Seq based on a multinomial model.\n\nDimension Reduction of Non-Normally Distributed Data.\n\nImplements a generalized version of principal components analysis (GLM-PCA) for dimension reduction of non-normally distributed data such as counts or binary matrices.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            },
            "GsVec": {
                "Name": "GsVec",
                "Description": "Comprehensive biological interpretation of gene signatures using semantic distributed representation.\n\nGsVec (Gene signature Vector) is an analysis method that supports the biological interpretation of Gene signature obtained by gene expression analysis of Bioinformatics. The association between the gene signature to be interpreted and the gene signature of the Pathway / Gene Ontology data base is performed by natural language processing",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            },
            "GWAS-Flow": {
                "Name": "GWAS-Flow",
                "Description": "A GPU accelerated framework for efficient permutation based genome-wide association studies | GPU accelerated GWAS framework based on TensorFlow | GWAS-Flow was written and published in the hope that you might find it useful. If you do and use it for your research please cite the paper published alongside the software, which is currently publicly accessible on the BiorXiv preprint server. https://www.biorxiv.org/content/10.1101/783100v1 doi: 10.1101/783100",
                "GPU": true,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": false
            },
            "PathFlowAI": {
                "Name": "PathFlowAI",
                "Description": "A High-Throughput Workflow for Preprocessing, Deep Learning and Interpretation in Digital Pathology | A Convenient High-Throughput Workflow for Preprocessing, Deep Learning Analytics and Interpretation in Digital Pathology | MedRxiv Manuscript: https://www.medrxiv.org/content/10.1101/19003897v1 | Fig. 1. PathFlowAI Framework: a) Annotations and whole slide images are preprocessed in parallel using Dask; b) Deep learning prediction model is trained on the model; c) Results are visualized; d) UMAP embeddings provide diagnostics; e) SHAP framework is used to find important regions for the prediction",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "pSpatiocyte": {
                "Name": "pSpatiocyte",
                "Description": "a high-performance simulator for intracellular reaction-diffusion systems.\n\na lattice-based particle simulator.\n\nLattice-based stochastic particle simulator.\n\nSpatiocyte \u2014 A lattice-based particle simulator.\n\nSimulate with mass action, Gillespie Next-Reaction and lattice-based particle diffusion and reaction algorithms simultaneously.\n\nThree-dimensional diffusion and reaction in a cubic volume.\n\nParallel version of Spatiocyte (pSpatiocyte): Github",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "rmvp": {
                "Name": "rMVP",
                "Description": "A Memory-efficient, Visualization-enhanced, and Parallel-accelerated tool for Genome-Wide Association Study.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "sepca": {
                "Name": "sePCA",
                "Description": "Rotationally Invariant Exponential Family PCA.\n\nIn photon-limited imaging, the pixel intensities are affected by photon count noise. Many applications require an accurate estimation of the covariance of the underlying 2-D clean images. For example, in X-ray free electron laser (XFEL) single molecule imaging, the covariance matrix of 2-D diffraction images is used to reconstruct the 3-D molecular structure. Accurate estimation of the covariance from low-photon-count images must take into account that pixel intensities are Poisson distributed, hence the classical sample covariance estimator is highly biased. Moreover, in single molecule imaging, including in-plane rotated copies of all images could further improve the accuracy of covariance estimation. In this paper we introduce an efficient and accurate algorithm for covariance matrix estimation of count noise 2-D images, including their uniform planar rotations and possibly reflections",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            },
            "sleepwalk": {
                "Name": "Sleepwalk",
                "Description": "Exploring dimension-reduced embeddings with Sleepwalk.\n\nInteractively Explore Dimension-Reduced Embeddings.\n\nA tool to interactively explore the embeddings created by dimension reduction methods such as Principal Components Analysis (PCA), Multidimensional Scaling (MDS), T-distributed Stochastic Neighbour Embedding (t-SNE), Uniform Manifold Approximation and Projection (UMAP) or any other.\n\nSleepwalk displays a 2D embedding,i.e., a 2D representation of higher-dimensional data points, and whenever the user hovers with the mouse over a data point, all points are coloured according to their distance to the focus point under the mouse cursor.\n\nWhen working with single-cell data, e.g., from single-cell RNA-Seq, we need an intuitive visual representation of our data.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            },
            "yalla": {
                "Name": "yalla",
                "Description": "GPU-Powered Spheroid Models for Mesenchyme and Epithelium",
                "GPU": true,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": false
            }
        }
    },
    "operation_3208": {
        "Name": "Genome visualisation",
        "Count": 6,
        "Tools": {
            "circvar-db": {
                "Name": "circVAR database",
                "Description": "circVAR database is genome-wide archive of genetic variants for human circular RNAs\nCircular RNAs (circRNAs), the 3' and 5' ends of which are covalently linked, are a kind of widely distributed and abundant RNAs found in eukaryotic organisms in recent years. They could play as sponges for regulating microRNAs and RNA binding proteins. Our circVAR database aims to provide resources for circRNA-related genetic variants in healthy and diseased populations.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            },
            "cramer": {
                "Name": "CRAMER",
                "Description": "The Cranfield Genome Browser (CRAMER) is a lightweight, highly customizable web-based genome browser supporting multiple visualization instances. CRAMER is a customisable, JavaScript and Jade based genome browser for interactive exploration of genomic data. Data is visualized in the browser, meaning CRAMER can be installed on any website and show data from a wide range of online, ftp links or local sources. CRAMER works with a variety of formats, such as XML, JSON, BED, VCF, GFF, GFF3, BAM or delimited text files, and can be customised to parse and display any data source as required.",
                "GPU": false,
                "CPU": false,
                "ram": true,
                "parallel": false,
                "distributed": false
            },
            "FunGeCo": {
                "Name": "FunGeCo",
                "Description": "A web based tool for estimation of Functional potential of bacterial genomes and microbiomes using Gene Context information.\n\nFunctional potential of bacterial genomes and microbiomes from gene context information.\n\nThis feature allows the user to input a newly sequenced genome and annotate it using gene context based modules generated using extensive literature mining and manual curation. Users can also carry out comparative analysis (synteny view using parallel coordinates) of the uploaded genome with genomes already sequenced in NCBI using interactive visualizations.\n\nThis feature allows comparison of functional modules in sequenced genomes obtained from NCBI. Users can interactively select upto five genomes which are compared using a synteny based visualization (parallel coordinates) and circular genomic representations. Information about individual modules in all these genomes can also be viewed as tabular outputs",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "hpul": {
                "Name": "Hpul",
                "Description": "Usage of the Sea Urchin Hemicentrotus pulcherrimus Database, HpBase.\n\nHemicentrotus pulcherrimus Genome Resources.\n\nHemicentrotus pulcherrimus Genome and Transcriptome database.\n\nHemicentrotus pulcherrimus (A. Agassiz, 1863) (Animaria: Echinodermata: Echinoidea: Echinoida: Strongylocentrotiae: Hemicentrotus) is the most widely distributed sea urchin in Japan and important marine food resources in eastern Asia. This species has a long history as a model organism in the field of developmental and cell biology since the mid 1900s. The web site provides information on H. pulcherrimus genome and transcriptome for a wide range of biologists.\n\n||| COMMON LINK WITH (PUB. & NAME DIFFERENT) bio.tools/insdc (NIG.AC.JP), bio.tools/dfast (NIG.AC.JP), bio.tools/ddbj (NIG.AC.JP), bio.tools/cibex (NIG.AC.JP)\n\n||| CORRECT NAME OF TOOL COULD ALSO BE 'H pulcherrimus'",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            },
            "qbed": {
                "Name": "qBED",
                "Description": "a novel genome browser visualization for point processes.\n\nTransposon calling cards is a genomic assay for identifying transcription factor binding sites in both bulk and single cell experiments. Here we describe the qBED format, an open, text-based standard for encoding and analyzing calling card data. In parallel, we introduce the qBED track on the WashU Epigenome Browser, a novel visualization that enables researchers to inspect calling card data in their genomic context. Finally, through examples, we demonstrate that qBED files can be used to visualize non-calling card datasets, such as CADD scores and GWAS eQTL hits, and may have broad utility to the genomics community",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "SciApps": {
                "Name": "SciApps",
                "Description": "A Cloud-Based Platform for Analyses and Distribution of the MaizeCODE data.\n\nMaizeCODE is a project aimed at identifying and analyzing functional elements in the maize genome. In its initial phase, MaizeCODE assayed up to five tissues from four maize strains (B73, NC350, W22, TIL11) by RNA-Seq, Chip-Seq, RAMPAGE, and small RNA sequencing. To facilitate reproducible science and provide both human and machine access to the MaizeCODE data, we developed SciApps, a cloud-based portal, for analysis and distribution of both raw data and analysis results. Based on the SciApps workflow platform, we generated new components to support the complete cycle of the MaizeCODE data management",
                "GPU": false,
                "CPU": false,
                "ram": true,
                "parallel": false,
                "distributed": false
            }
        }
    },
    "operation_3198": {
        "Name": "Read mapping",
        "Count": 19,
        "Tools": {
            "cloudburst": {
                "Name": "CloudBurst",
                "Description": "CloudBurst is a parallel read-mapping algorithm optimized for mapping next-generation sequence data to the human genome and other reference genomes.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "CSMD": {
                "Name": "Computation Subtraction-based Microbiome Discovery (CSMD)",
                "Description": "A computational subtraction-based microbiome discovery pipeline for species-level characterization of clinical metagenomic samples.\n\nA computational pipeline for high-resolution profiling of low abundance microbiome in clinical samples using whole genome shotgun sequencing.\n\nComputation Subtraction-based Microbiome Discovery (CSMD).\n\nCSMD will work with a series of libraries listed in Table 2, including human-related genomes or sequences (21G) and all RefSeq bacteria genomes (150G, as of November 2018). The build process will then require approximately 500GB of additional disk space and 200GB of RAM. These genomes or sequences can be found in DBPATH/hg38/SEQ, DBPATH/AHG/SEQ, DBPATH/EHG/SEQ and DBPATH/RefSeq/bacteria/SEQ, respectively. And the indexed files will be saved in DBPATH/hg38, DBPATH/AHG, DBPATH/EHG and DBPATH/RefSeq/bacteria, respectively",
                "GPU": false,
                "CPU": false,
                "ram": true,
                "parallel": false,
                "distributed": false
            },
            "coverageview": {
                "Name": "CoverageView",
                "Description": "This package provides a framework for the visualization of genome coverage profiles. It can be used for ChIP-seq experiments, but it can be also used for genome-wide nucleosome positioning experiments or other experiment types where it is important to have a framework in order to inspect how the coverage distributed across the genome.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            },
            "curc": {
                "Name": "CURC",
                "Description": "A GPU-accelerated reference-free compressor for high-throughput sequencing reads of FASTQ files.",
                "GPU": true,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": false
            },
            "distmap": {
                "Name": "distmap",
                "Description": "A Toolkit for Distributed Short Read Mapping on a Hadoop Cluster.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            },
            "ExpansionHunter_Denovo": {
                "Name": "ExpansionHunter Denovo",
                "Description": "A computational method for locating known and novel repeat expansions in short-read sequencing data.\n\nA suite of tools for detecting expansions of short tandem repeats.\n\nExpansionHunter Denovo (EHdn) is a suite of tools for detecting novel expansions of short tandem repeats (STRs). EHdn is intended for analysis of a collection of BAM/CRAM files containing alignments of short (100-200bp) reads.",
                "GPU": false,
                "CPU": false,
                "ram": true,
                "parallel": false,
                "distributed": false
            },
            "FixVAF": {
                "Name": "FixVAF",
                "Description": "Correcting reference bias from the Illumina Isaac aligner enables analysis of cancer genomes.\n\nCode to remove bias from Isaac aligned data by clipping all reads for variant positions by 5 bases and producing a modified vcf file.\n\nSupport code for NGS copy number algorithms. Takes a file of locations and a [cr:b]am file and generates a count of coverage of each allele [ACGT] at that location (given any filter settings). Altered so that it clips all reads by n bases to reduce reference bias.\n\npython FixVaf.py [vcf file] [bam file] [fasta file].\n\nThe alleleCount package primarily exists to prevent code duplication between some other projects, specifically AscatNGS and Battenberg.\n\nRequires python 3 with psam installed.\n\nThe project previously contained 2 equivalent implementations of allele counting code in perl and C for BAM CRAM processing",
                "GPU": false,
                "CPU": false,
                "ram": true,
                "parallel": false,
                "distributed": false
            },
            "Flint": {
                "Name": "Flint",
                "Description": "Large scale microbiome profiling in the cloud | Main repository of the Flint project for Spark and Amazon EMR | This is the main repository of the Flint project for Amazon Web Services. Flint is a metagenomics profiling pipeline that is built on top of the Apache Spark framework, and is designed for fast real-time profiling of metagenomic samples against a large collection of reference genomes. Flint takes advantage of Spark's built-in parallelism and streaming engine architecture to quickly map reads against a large reference collection of bacterial genomes",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "gpmeta": {
                "Name": "GPMeta",
                "Description": "GPU-accelerated method for ultrarapid pathogen identification from metagenomic sequences.",
                "GPU": true,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": false
            },
            "ioncram": {
                "Name": "IonCRAM",
                "Description": "A reference-based compression tool for ion torrent sequence files.\n\nIonCram is the first compression tool that efficiently compresses the Ion Torrent BAM files. IonCram extends the popular CRAM program by improving the compression of the flow signals. IonCram could improve the compression of CRAM by 13% achieving an overall space saving of about 45%.",
                "GPU": false,
                "CPU": false,
                "ram": true,
                "parallel": false,
                "distributed": false
            },
            "myrialign": {
                "Name": "Myrialign",
                "Description": "Software to align short reads produced by a short read genome sequencer to a reference genome. It performs brute force alignment using a variant on the 'bitap' algorithm that aligns several thousand reads to a reference in parallel. It uses bit-parallelism, multiple processors, and Cell SPUs if available.\nIt will find alignments with any number of errors up to a user specified cutoff. The emphasis is on doing a 100% accurate search as fast as is possible.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "nubeam-dedup": {
                "Name": "Nubeam-dedup",
                "Description": "A fast and RAM-efficient tool to de-duplicate sequencing reads without mapping.\n\nnubeam-dedup is a fast and easy-to-use bioinformatics tool removing exact PCR duplicates for sequencing reads, single-end or paired-end. We appreciate your interest in nubeam-dedup. If you use nubeam-dedup, please kindly cite:.",
                "GPU": false,
                "CPU": false,
                "ram": true,
                "parallel": false,
                "distributed": false
            },
            "PaSGAL": {
                "Name": "PaSGAL",
                "Description": "PaSGAL (Parallel Sequence to Graph Aligner) is designed to accelerate local sequence alignment of sequences to directed acyclic sequence graphs (DAGs), e.g., variation graphs, splicing graphs.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "samscope": {
                "Name": "Samscope",
                "Description": "Lightweight SAM/BAM file viewer that makes visually exploring NGS data intuitively. It uses multiple layers to simultaneously (or sequentially) view SAM/BAM related features like coverage or allele frequency, or ChIP-SEQ features like polarity from as many files as you like. The paging-friendly binary file layout makes it feasible to browse data sets far larger than the system's available RAM.",
                "GPU": false,
                "CPU": false,
                "ram": true,
                "parallel": false,
                "distributed": false
            },
            "scrooge": {
                "Name": "Scrooge",
                "Description": "A fast and memory-frugal genomic sequence aligner for CPUs, GPUs and ASICs.",
                "GPU": true,
                "CPU": true,
                "ram": false,
                "parallel": false,
                "distributed": false
            },
            "seqsphere": {
                "Name": "SeqSphere+",
                "Description": "This software is designed for distributed work-groups (client/server model) and allows automatic processing, assembling and analyzing NGS (e.g., Illumina, Ion Torrent or PacBio) and Sanger capillary-electrophoresis sequence data. It provides with an easy and automated microbial analysis; enabling your lab to employ whole genome microbial typing (cgMLST or MLST+), traditional MLST or eMLST/rMLST sequencing projects.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            },
            "sneakysnake": {
                "Name": "SneakySnake",
                "Description": "A Fast and Accurate Universal Genome Pre-Alignment Filter for CPUs, GPUs, and FPGAs.\n\nThe first and the only pre-alignment filtering algorithm that works efficiently and fast on modern CPU, FPGA, and GPU architectures. SneakySnake greatly (by more than two orders of magnitude) expedites sequence alignment calculation for both short (Illumina) and long (ONT and PacBio) reads.",
                "GPU": true,
                "CPU": true,
                "ram": false,
                "parallel": false,
                "distributed": false
            },
            "soap3-gpu": {
                "Name": "SOAP3",
                "Description": "SOAP3 is a GPU-based software for aligning short reads to a reference sequence.",
                "GPU": true,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": false
            },
            "sv-gen": {
                "Name": "sv-gen",
                "Description": "Highly portable parallel workflow to generate artificial genomes with structural variants.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            }
        }
    },
    "operation_3801": {
        "Name": "Spectral library search",
        "Count": 2,
        "Tools": {
            "clustersheep": {
                "Name": "ClusterSheep",
                "Description": "ClusterSheep is a GPU/CUDA-accelerated software tool for large-scale clustering of tandem mass spectra from shotgun proteomics.",
                "GPU": true,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": false
            },
            "mr-mspolygraph": {
                "Name": "MR-MSPOLYGRAPH",
                "Description": "MR-MSPOLYGRAPH is a MapReduce based implementation for parallelizing peptide identification from mass spectrometry data",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            }
        }
    },
    "operation_0492": {
        "Name": "Multiple sequence alignment",
        "Count": 4,
        "Tools": {
            "cmsa": {
                "Name": "CMSA",
                "Description": "A heterogeneous CPU/GPU computing system for multiple similar RNA/DNA sequence alignment.",
                "GPU": true,
                "CPU": true,
                "ram": false,
                "parallel": false,
                "distributed": false
            },
            "msaprobs-mpi": {
                "Name": "MSAProbs-MPI",
                "Description": "Fast and Accurate Multiple Sequence Alignment with MSAProbs-MPI.\n\nParallel and accurate multiple sequence alignment.\n\nMSAProbs is a well-established state-of-the-art multiple sequence alignment algorithm for protein sequences.\n\nMSAProbs-MPI is a parallelization of MSAProbs (v0.9.7) using MPI for distributed-memory systems.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": true
            },
            "retrieve_and_relate": {
                "Name": "Retrieve and Relate",
                "Description": "Retrieve similar sequences beginning from DNA, RNA or Proteins as well as free text - meaning there is no need to set any preliminary search parameters or filters which restrict the search space. Out of the box your search in parallel 11 of the most popular databases. Average alignment takes less then 3 seconds. Adding your own database is as simple as a click of the button.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "Treerecs": {
                "Name": "Treerecs",
                "Description": "Treerecs is an open-source (species- and gene-) tree reconciliation software distributed under the GNU AGPL licence.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            }
        }
    },
    "operation_3280": {
        "Name": "Named-entity and concept recognition",
        "Count": 1,
        "Tools": {
            "cogstack": {
                "Name": "CogStack",
                "Description": "Experiences of deploying integrated information retrieval and extraction services in a large National Health Service Foundation Trust hospital.\n\nCogStack is a lightweight distributed, fault tolerant database processing architecture and ecosystem, intended to make NLP processing and preprocessing easier in resource constrained environments.\n\nCogStack is a lightweight distributed, fault tolerant database processing architecture, intended to make NLP processing and preprocessing easier in resource constained environments.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            }
        }
    },
    "operation_0295": {
        "Name": "Structure alignment",
        "Count": 3,
        "Tools": {
            "comer2": {
                "Name": "COMER2",
                "Description": "GPU-accelerated sensitive and specific homology searches.\n\nCOMER2, cross-platform software for protein remote homology search.\n\nThe COMER method based on sequence profile-profile comparison is one of the most sensitive and accurate computational tools developed for protein alignment and homology search. COMER version 2.1 (COMER2) represents one of the fastest implementations of calculations for sensitive protein homology search. High COMER2 performance is achieved by harnessing the power of the Graphics processing unit (GPU). Hence, a GPU is expected to be installed on the system.\n\nCOMER2, a cross-platform software package for protein remote homology search and alignment.",
                "GPU": true,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": false
            },
            "gpu-cassert": {
                "Name": "GPU-CASSERT",
                "Description": "The GPU-based implementation of the CASSERT algorithm for protein 3D structure similarity searching. The algorithm is based on the two-phase alignment of protein structures when matching fragments of compared proteins.",
                "GPU": true,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": false
            },
            "lara_2": {
                "Name": "LaRA 2",
                "Description": "Parallel and vectorized program for sequence-structure alignment of RNA sequences.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            }
        }
    },
    "operation_0300": {
        "Name": "Sequence profile alignment",
        "Count": 1,
        "Tools": {
            "comer2": {
                "Name": "COMER2",
                "Description": "GPU-accelerated sensitive and specific homology searches.\n\nCOMER2, cross-platform software for protein remote homology search.\n\nThe COMER method based on sequence profile-profile comparison is one of the most sensitive and accurate computational tools developed for protein alignment and homology search. COMER version 2.1 (COMER2) represents one of the fastest implementations of calculations for sensitive protein homology search. High COMER2 performance is achieved by harnessing the power of the Graphics processing unit (GPU). Hence, a GPU is expected to be installed on the system.\n\nCOMER2, a cross-platform software package for protein remote homology search and alignment.",
                "GPU": true,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": false
            }
        }
    },
    "operation_0390": {
        "Name": "Protein peeling",
        "Count": 1,
        "Tools": {
            "compact": {
                "Name": "CompaCt",
                "Description": "CompaCt performs automated integrative comparative analysis of large-scale (protein) interaction datasets, identifying groups of interactors (e.g., protein complexes) in parallel in multiple species, allowing systematic identification and comparison of conserved as well as taxon-specific components of protein complexes and other interactions.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            }
        }
    },
    "operation_2949": {
        "Name": "Protein-protein interaction analysis",
        "Count": 3,
        "Tools": {
            "compact": {
                "Name": "CompaCt",
                "Description": "CompaCt performs automated integrative comparative analysis of large-scale (protein) interaction datasets, identifying groups of interactors (e.g., protein complexes) in parallel in multiple species, allowing systematic identification and comparison of conserved as well as taxon-specific components of protein complexes and other interactions.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "dasmiweb": {
                "Name": "DASMIweb",
                "Description": "Server that allows integration, analysis and quantitative assessment of distributed sources of protein and domain interactions. Users can query numerous sources simultaneously, which can then be configured and can support incorporation of user data.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            },
            "diamin": {
                "Name": "DIAMIN",
                "Description": "DIAMIN is a high-level software library to facilitate the development of distributed applications for the efficient analysis of large-scale molecular interaction networks.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            }
        }
    },
    "operation_3478": {
        "Name": "Phylogenetic reconstruction",
        "Count": 2,
        "Tools": {
            "compact": {
                "Name": "CompaCt",
                "Description": "CompaCt performs automated integrative comparative analysis of large-scale (protein) interaction datasets, identifying groups of interactors (e.g., protein complexes) in parallel in multiple species, allowing systematic identification and comparison of conserved as well as taxon-specific components of protein complexes and other interactions.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "ParGenes": {
                "Name": "ParGenes",
                "Description": "Tool for massively parallel model selection and phylogenetic tree inference on thousands of genes.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            }
        }
    },
    "operation_3663": {
        "Name": "Homology-based gene prediction",
        "Count": 2,
        "Tools": {
            "compact": {
                "Name": "CompaCt",
                "Description": "CompaCt performs automated integrative comparative analysis of large-scale (protein) interaction datasets, identifying groups of interactors (e.g., protein complexes) in parallel in multiple species, allowing systematic identification and comparison of conserved as well as taxon-specific components of protein complexes and other interactions.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "porthomcl": {
                "Name": "PorthoMCL",
                "Description": "Parallel orthology prediction using MCL for the realm of massive genome availability.\n\nParallel implementation of OrthoMCL.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            }
        }
    },
    "operation_3454": {
        "Name": "Phasing",
        "Count": 10,
        "Tools": {
            "CSMD": {
                "Name": "Computation Subtraction-based Microbiome Discovery (CSMD)",
                "Description": "A computational subtraction-based microbiome discovery pipeline for species-level characterization of clinical metagenomic samples.\n\nA computational pipeline for high-resolution profiling of low abundance microbiome in clinical samples using whole genome shotgun sequencing.\n\nComputation Subtraction-based Microbiome Discovery (CSMD).\n\nCSMD will work with a series of libraries listed in Table 2, including human-related genomes or sequences (21G) and all RefSeq bacteria genomes (150G, as of November 2018). The build process will then require approximately 500GB of additional disk space and 200GB of RAM. These genomes or sequences can be found in DBPATH/hg38/SEQ, DBPATH/AHG/SEQ, DBPATH/EHG/SEQ and DBPATH/RefSeq/bacteria/SEQ, respectively. And the indexed files will be saved in DBPATH/hg38, DBPATH/AHG, DBPATH/EHG and DBPATH/RefSeq/bacteria, respectively",
                "GPU": false,
                "CPU": false,
                "ram": true,
                "parallel": false,
                "distributed": false
            },
            "corenup": {
                "Name": "CORENup",
                "Description": "CORENup is a deep learning model for nucleosome identification. CORENup processes a DNA sequence as input using one-hot representation and combines in a parallel fashion a fully convolutional neural network and a recurrent layer. These two parallel levels are devoted to catching both non periodic and periodic DNA string features.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "fits": {
                "Name": "FITs",
                "Description": "Forest of imputation trees for recovering true signals in single-cell open chromatin profiles.\n\nForest of Imputation Trees (FITs) is a method to impute highly sparse and noisy data-sets from single cell epigenome profiling.\n\nFITs work in two phases. It has been made so to handle very large read-count matrixes and to get better imputation. In phase-1 it builds multiple imputation trees and from every tree it extracts 1 or 2 imputed version of original read-count matrix. One can run phase-1 of FITs in parallel processing mode also, where multiple trees can be build using several processors.After phase-1, the phase-2 part of FITs is used to accumulate the most relevant imputed version for every cell.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "ioncram": {
                "Name": "IonCRAM",
                "Description": "A reference-based compression tool for ion torrent sequence files.\n\nIonCram is the first compression tool that efficiently compresses the Ion Torrent BAM files. IonCram extends the popular CRAM program by improving the compression of the flow signals. IonCram could improve the compression of CRAM by 13% achieving an overall space saving of about 45%.",
                "GPU": false,
                "CPU": false,
                "ram": true,
                "parallel": false,
                "distributed": false
            },
            "medicc2": {
                "Name": "MEDICC2",
                "Description": "Whole-genome doubling-aware copy number phylogenies for cancer evolution with MEDICC2. Chromosomal instability (CIN) and somatic copy number alterations (SCNA) play a key role in the evolutionary process that shapes cancer genomes. SCNAs comprise many classes of clinically relevant events, such as localised amplifications, gains, losses, loss-of-heterozygosity (LOH) events, and recently discovered parallel evolutionary events revealed by multi-sample phasing. These events frequently appear jointly with whole genome doubling (WGD), a transformative event in tumour evolution, which generates tetraploid or near-tetraploid cells. WGD events are often clonal, occuring before the emergence of the most recent common ancestor, and have been associated with increased CIN, poor patient outcome and are currently being investigated as potential therapeutic targets",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "mp-nerf": {
                "Name": "MP-NeRF",
                "Description": "A Massively Parallel Method for Accelerating Protein Structure Reconstruction from Internal Coordinates.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "SciApps": {
                "Name": "SciApps",
                "Description": "A Cloud-Based Platform for Analyses and Distribution of the MaizeCODE data.\n\nMaizeCODE is a project aimed at identifying and analyzing functional elements in the maize genome. In its initial phase, MaizeCODE assayed up to five tissues from four maize strains (B73, NC350, W22, TIL11) by RNA-Seq, Chip-Seq, RAMPAGE, and small RNA sequencing. To facilitate reproducible science and provide both human and machine access to the MaizeCODE data, we developed SciApps, a cloud-based portal, for analysis and distribution of both raw data and analysis results. Based on the SciApps workflow platform, we generated new components to support the complete cycle of the MaizeCODE data management",
                "GPU": false,
                "CPU": false,
                "ram": true,
                "parallel": false,
                "distributed": false
            },
            "snapMRF": {
                "Name": "snapMRF",
                "Description": "GPU-accelerated magnetic resonance fingerprinting dictionary generation and matching using extended phase graphs.",
                "GPU": true,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": false
            },
            "tensorpac": {
                "Name": "Tensorpac",
                "Description": "Tensorpac is an Python open-source toolbox for computing Phase-Amplitude Coupling (PAC) using tensors and parallel computing for an efficient, and highly flexible modular implementation of PAC metrics both known and novel. Check out our documentation for details.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "tinker-hp": {
                "Name": "Tinker-HP",
                "Description": "Tinker-HP is a tool for high-performance massively parallel evolution of tinker on CPUs & GPUs. It is used to accelerating molecular dynamics simulations of large complex systems with advanced point dipole polarizable force fields using GPUs and multi-GPU systems.",
                "GPU": true,
                "CPU": true,
                "ram": false,
                "parallel": true,
                "distributed": false
            }
        }
    },
    "operation_3460": {
        "Name": "Taxonomic classification",
        "Count": 2,
        "Tools": {
            "CSMD": {
                "Name": "Computation Subtraction-based Microbiome Discovery (CSMD)",
                "Description": "A computational subtraction-based microbiome discovery pipeline for species-level characterization of clinical metagenomic samples.\n\nA computational pipeline for high-resolution profiling of low abundance microbiome in clinical samples using whole genome shotgun sequencing.\n\nComputation Subtraction-based Microbiome Discovery (CSMD).\n\nCSMD will work with a series of libraries listed in Table 2, including human-related genomes or sequences (21G) and all RefSeq bacteria genomes (150G, as of November 2018). The build process will then require approximately 500GB of additional disk space and 200GB of RAM. These genomes or sequences can be found in DBPATH/hg38/SEQ, DBPATH/AHG/SEQ, DBPATH/EHG/SEQ and DBPATH/RefSeq/bacteria/SEQ, respectively. And the indexed files will be saved in DBPATH/hg38, DBPATH/AHG, DBPATH/EHG and DBPATH/RefSeq/bacteria, respectively",
                "GPU": false,
                "CPU": false,
                "ram": true,
                "parallel": false,
                "distributed": false
            },
            "metacram": {
                "Name": "MetaCRAM",
                "Description": "Pipeline for taxonomy identification and lossless compression of FASTA-format metagenomic reads. \u00a0It integrates algorithms for taxonomy identification, read alignment, assembly, and finally, a reference-based compression method in a parallel manner.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            }
        }
    },
    "operation_0432": {
        "Name": "Nucleosome position prediction",
        "Count": 1,
        "Tools": {
            "corenup": {
                "Name": "CORENup",
                "Description": "CORENup is a deep learning model for nucleosome identification. CORENup processes a DNA sequence as input using one-hot representation and combines in a parallel fashion a fully convolutional neural network and a recurrent layer. These two parallel levels are devoted to catching both non periodic and periodic DNA string features.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            }
        }
    },
    "operation_2995": {
        "Name": "Sequence classification",
        "Count": 1,
        "Tools": {
            "corenup": {
                "Name": "CORENup",
                "Description": "CORENup is a deep learning model for nucleosome identification. CORENup processes a DNA sequence as input using one-hot representation and combines in a parallel fashion a fully convolutional neural network and a recurrent layer. These two parallel levels are devoted to catching both non periodic and periodic DNA string features.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            }
        }
    },
    "operation_0564": {
        "Name": "Sequence visualisation",
        "Count": 1,
        "Tools": {
            "coverageview": {
                "Name": "CoverageView",
                "Description": "This package provides a framework for the visualization of genome coverage profiles. It can be used for ChIP-seq experiments, but it can be also used for genome-wide nucleosome positioning experiments or other experiment types where it is important to have a framework in order to inspect how the coverage distributed across the genome.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            }
        }
    },
    "operation_3631": {
        "Name": "Peptide identification",
        "Count": 2,
        "Tools": {
            "croco-xlink": {
                "Name": "CroCo",
                "Description": "A a user-centred tool to convert results from crosslinking mass spectrometry experiments | Convert data formats from chemical cross-linking mass spectrometry (XL-MS) | The CroCo cross-link converter \u2014 CroCo documentation | CroCo converts multiple data format from cross-linking mass spectrometry software tools to xTable format (in csv format) | The CroCo cross-link converter \u00b6 | CroCo converts multiple data format from cross-linking mass spectrometry software tools to xTable format (in csv format). It is distributed as graphical programme to be run from an executable and as a Python module to be integrated into workflows",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            },
            "mr-mspolygraph": {
                "Name": "MR-MSPOLYGRAPH",
                "Description": "MR-MSPOLYGRAPH is a MapReduce based implementation for parallelizing peptide identification from mass spectrometry data",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            }
        }
    },
    "operation_3218": {
        "Name": "Sequencing quality control",
        "Count": 6,
        "Tools": {
            "cuda-ec": {
                "Name": "CUDA-EC",
                "Description": "A scalable parallel algorithm for correcting sequencing errors in high-throughput short-read data so that error-free reads can be available before DNA fragment assembly.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "Dr.seq2": {
                "Name": "Dr.seq2",
                "Description": "A quality control and analysis pipeline for parallel single cell transcriptome and epigenome data. It provides quality control and analysis functionalities for three data types: single cell transcriptome data, Drop-ChIP data and scATAC-seq data.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "FQStat": {
                "Name": "FQStat",
                "Description": "A parallel architecture for very high-speed assessment of sequencing quality metrics | BACKGROUND:High throughput DNA RNA sequencing has revolutionized biological and clinical research. Sequencing is widely used, and generates very large amounts of data, mainly due to reduced cost and advanced technologies. Quickly assessing the quality of giga-to-tera base levels of sequencing data has become a routine but important task. Identification and elimination of low-quality sequence data is crucial for reliability of downstream analysis results. There is a need for a high-speed tool that uses optimized parallel programming for batch processing and simply gauges the quality of sequencing data from multiple datasets independent of any other processing steps. RESULTS:FQStat is a stand-alone, platform-independent software tool that assesses the quality of FASTQ files using parallel programming",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "MasterOfPores": {
                "Name": "MasterOfPores",
                "Description": "Parallel and scalable workflow for the analysis of Oxford Nanopore direct RNA sequencing datasets.\n\nNextflow pipeline for analysis of Nanopore reads (from RNA/cDNA/DNA).\n\nPlease read the documentation here: https://biocorecrg.github.io/master_of_pores/.\n\nNextflow pipeline for analysis of Nanopore data from direct RNA sequencing. This is a joint project between CRG bioinformatics core and Epitranscriptomics and RNA Dynamics research group.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "rqc": {
                "Name": "Rqc",
                "Description": "Optimised tool designed for quality control and assessment of high-throughput sequencing data that performs parallel processing of entire files and produces a report which contains a set of high-resolution graphics.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "rseqrep": {
                "Name": "RSEQREP",
                "Description": "Cloud-enabled framework that allows users to execute start-to-end gene-level RNA-Seq analysis. It works with unstranded, stranded, and paired-end sequence FASTQ files. It automatically executes a series of customizable steps including reference alignment, CRAM compression, reference alignment QC, data normalization, multivariate data visualization, identification of differentially expressed genes, heatmaps, co-expressed gene clusters, enriched pathways, and a series of custom visualizations.",
                "GPU": false,
                "CPU": false,
                "ram": true,
                "parallel": false,
                "distributed": false
            }
        }
    },
    "operation_0238": {
        "Name": "Sequence motif discovery",
        "Count": 2,
        "Tools": {
            "cuda-meme": {
                "Name": "CUDA-MEME",
                "Description": "Motif discovery software based on MEME algorithm for a single GPU device using CUDA programming model. At present, it only supports the OOPS and ZOOPS models.",
                "GPU": true,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": false
            },
            "rpmcmc": {
                "Name": "RPMCMC",
                "Description": "A parallel MCMC algorithm for discovering diverse motifs from large sequence sets.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            }
        }
    },
    "operation_0481": {
        "Name": "Loop modelling",
        "Count": 2,
        "Tools": {
            "cudammc": {
                "Name": "cudaMMC",
                "Description": "GPU-enhanced multiscale Monte Carlo chromatin 3d modelling.",
                "GPU": true,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": false
            },
            "hisif": {
                "Name": "HiSIF",
                "Description": "Modeling and analysis of Hi-C data by HiSIF identifies characteristic promoter-distal loops.\n\nHiSIF - HiC Significant Interacting Fragments.\n\nHiSIF was implemented by using C++/C with parallel processing being written in C. It has been compiled and run exclusively on Linux operating systems. This tool only requires the g++ compiler and a reference genome for HG19. Standalone CERN ROOT C++ framework is used to extract fit parameters of the CTS interactions. A small C tool is provided to process the initial data from NCBI. HiSIF supports all of the available three Hi-C protocols (Hi-C, TCC and in situ Hi-C). The tool is named from the fact that it is designed to find the significant interactions from a given sample of Hi-C reads.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            }
        }
    },
    "operation_0531": {
        "Name": "Heat map generation",
        "Count": 2,
        "Tools": {
            "cudammc": {
                "Name": "cudaMMC",
                "Description": "GPU-enhanced multiscale Monte Carlo chromatin 3d modelling.",
                "GPU": true,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": false
            },
            "scdrake": {
                "Name": "scdrake",
                "Description": "Scdrake is a highly scalable, reproducible and configurable pipeline for scRNA-seq data prepared by a popular 10x Genomics droplet-based technology. Scdrake is implemented as a package for the R language and is built on top of the drake package, a Make-like pipeline toolkit. Scdrake currently provides common steps of scRNA-seq data analysis: quality control and filtering of cells and genes, normalization, dimensionality reduction, clustering, finding of cluster markers and differentially expressed genes between clusters, and integration of multiple datasets. All pipeline steps are accompanied by rich graphical outputs and reports in HTML format.\n\nThanks to the drake package, all intermediate results can be reused, and the pipeline can be easily extended by users to incorporate custom analyses. Also, drake analyzes which parts of the pipeline are already done or haven't changed since the last run, and which can be run in parallel, resulting in great execution speed.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            }
        }
    },
    "operation_0232": {
        "Name": "Sequence merging",
        "Count": 1,
        "Tools": {
            "curc": {
                "Name": "CURC",
                "Description": "A GPU-accelerated reference-free compressor for high-throughput sequencing reads of FASTQ files.",
                "GPU": true,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": false
            }
        }
    },
    "operation_3211": {
        "Name": "Genome indexing",
        "Count": 9,
        "Tools": {
            "cuttlefish": {
                "Name": "Cuttlefish",
                "Description": "Cuttlefish is a fast, parallel, and very lightweight memory tool to construct the compacted de Bruijn graph from genome reference(s). Cuttlefish is a tool for constructing the (colored) compacted de Bruijn graph from a collection of one or more genome references. Cuttlefish introduces a novel modeling scheme of the de Bruijn graph vertices as finite-state automata, and constrains the state-space for the automata to enable tracking of their transitioning states with very low memory usage. Cuttlefish is also fast and highly parallelizable. Experimental results demonstrate that the algorithm scales much better than existing approaches, especially as the number and scale of the input references grow.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "Flint": {
                "Name": "Flint",
                "Description": "Large scale microbiome profiling in the cloud | Main repository of the Flint project for Spark and Amazon EMR | This is the main repository of the Flint project for Amazon Web Services. Flint is a metagenomics profiling pipeline that is built on top of the Apache Spark framework, and is designed for fast real-time profiling of metagenomic samples against a large collection of reference genomes. Flint takes advantage of Spark's built-in parallelism and streaming engine architecture to quickly map reads against a large reference collection of bacterial genomes",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "galaxytrakr": {
                "Name": "GalaxyTrakr",
                "Description": "A distributed analysis tool for public health whole genome sequence data accessible to non-bioinformaticians.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            },
            "kmerkeys": {
                "Name": "KmerKeys",
                "Description": "KmerKeys is a web resource for searching indexed genome assemblies and variants. It provides performant, rapid query speeds for cloud computation on genome assemblies. It enable fuzzy as well as exact k-mer-based searches of assemblies. To enable robust and speedy performance, the website implements cache-friendly hash tables, memory mapping and massive parallel processing. Our method employs a scalable and efficient data structure that can be used to jointly index and search a large collection of human genome assembly information. One can include variant databases and their associated metadata such as the gnomAD population variant catalog. This feature enables the incorporation of future genomic information into sequencing analysis.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "mkesa": {
                "Name": "mkESA",
                "Description": "Open source program for constructing enhanced suffix arrays (ESAs) from biological sequence data. The program is based on our implementation of Manzini's lightweight Deep-Shallow algorithm [1], which can also utilize multiple CPUs/cores for some extra speed-up. The generated output is compatible with the output of mkvtree from the Vmatch package written by Stefan Kurtz.",
                "GPU": false,
                "CPU": true,
                "ram": false,
                "parallel": false,
                "distributed": false
            },
            "reindeer": {
                "Name": "REINDEER",
                "Description": "efficient indexing of k-mer presence and abundance in sequencing datasets.\n\nREINDEER builds a data-structure that indexes k-mers and their abundances in a collection of datasets (raw RNA-seq or metagenomic reads for instance). Then, a sequence (FASTA) can be queried for its presence and abundance in each indexed dataset. While other tools (e.g. SBT, BIGSI) were also designed for large-scale k-mer presence/absence queries, retrieving abundances was so far unsupported (except for single datasets, e.g. using some k-mer counters like KMC, Jellyfish). REINDEER combines fast queries, small index size, and low memory footprint during indexing and queries. We showed it allows to index 2585 RNA-seq datasets (~4 billions k-mers) using less than 60GB of RAM and a final index size lower than 60GB on the disk. Then, a REINDEER index can either be queried on disk (experimental feature, low RAM usage) or be loaded in RAM for faster queries.",
                "GPU": false,
                "CPU": false,
                "ram": true,
                "parallel": false,
                "distributed": false
            },
            "retrieve_and_relate": {
                "Name": "Retrieve and Relate",
                "Description": "Retrieve similar sequences beginning from DNA, RNA or Proteins as well as free text - meaning there is no need to set any preliminary search parameters or filters which restrict the search space. Out of the box your search in parallel 11 of the most popular databases. Average alignment takes less then 3 seconds. Adding your own database is as simple as a click of the button.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "sbwt": {
                "Name": "sBWT",
                "Description": "A Burrows\u2013Wheeler transformation BWT based fast indexer/aligner specialized in parallelized indexing and searching for Next Generation Sequencing data.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "vcascale": {
                "Name": "VCaScale",
                "Description": "Variant Calling at Scale is a scalable, parallel and efficient implementation of next generation sequencing data pre-processing and variant calling workflows. Our design tightly integrates most pre-processing workflow stages, using Spark built-in functions to sort reads by coordinates, and mark duplicates efficiently. A cluster scaled DeepVariant for both CPU-only and CPU+GPU clusters is also integrated in this workflow.",
                "GPU": true,
                "CPU": true,
                "ram": false,
                "parallel": true,
                "distributed": false
            }
        }
    },
    "operation_3472": {
        "Name": "k-mer counting",
        "Count": 11,
        "Tools": {
            "cuttlefish": {
                "Name": "Cuttlefish",
                "Description": "Cuttlefish is a fast, parallel, and very lightweight memory tool to construct the compacted de Bruijn graph from genome reference(s). Cuttlefish is a tool for constructing the (colored) compacted de Bruijn graph from a collection of one or more genome references. Cuttlefish introduces a novel modeling scheme of the de Bruijn graph vertices as finite-state automata, and constrains the state-space for the automata to enable tracking of their transitioning states with very low memory usage. Cuttlefish is also fast and highly parallelizable. Experimental results demonstrate that the algorithm scales much better than existing approaches, especially as the number and scale of the input references grow.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "GenomeScope_2.0": {
                "Name": "GenomeScope 2.0",
                "Description": "Reference-free profiling of polyploid genomes | We have developed GenomeScope 2.0, which applies classical insights from combinatorial theory to establish a detailed mathematical model of how k-mer frequencies will be distributed in heterozygous and polyploid genomes | Average k-mer coverage for polyploid genome | Upload results from running Jellyfish or KMC",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            },
            "gpu-darwin": {
                "Name": "GPU-Darwin",
                "Description": "GPU acceleration of Darwin read overlapper for de novo assembly of long DNA reads.\n\nThis repository contains a GPU implementation of Darwin [1][2], a hardware-friendly DNA aligner.\n\nIt consists of two parts: D-SOFT and GACT, which represent typical seed-and-extend methods. D-SOFT (Diagonal-band based Seed Overlapping based Filtration Technique) filters the search space by counting non-overlapping bases in matching Kmers in a band of diagonals. GACT (Genomic Alignment using Constant Tracebackmemory) can align reads of arbitrary length using constant memory for the compute-intensive step.\n\nThis implementation can be used to run on CPU only, or use the GPU-accelerated version. For more choices between individual optimizations, go back to commit e472745e.",
                "GPU": true,
                "CPU": true,
                "ram": false,
                "parallel": false,
                "distributed": false
            },
            "haslr": {
                "Name": "HASLR",
                "Description": "Fast Hybrid Assembly of Long Reads.\n\nHASLR is a tool for rapid genome assembly of long sequencing reads. HASLR is a hybrid tool which means it requires long reads generated by Third Generation Sequencing technologies (such as PacBio or Oxford Nanopore) together with Next Generation Sequencing reads (such as Illumina) from the same sample. HASLR is capable of assembling large genomes on a single computing node. Our experiments show that it can assemble a CHM1 human dataset in less than 10 hours using 64 CPU threads.",
                "GPU": false,
                "CPU": true,
                "ram": false,
                "parallel": false,
                "distributed": false
            },
            "kmerkeys": {
                "Name": "KmerKeys",
                "Description": "KmerKeys is a web resource for searching indexed genome assemblies and variants. It provides performant, rapid query speeds for cloud computation on genome assemblies. It enable fuzzy as well as exact k-mer-based searches of assemblies. To enable robust and speedy performance, the website implements cache-friendly hash tables, memory mapping and massive parallel processing. Our method employs a scalable and efficient data structure that can be used to jointly index and search a large collection of human genome assembly information. One can include variant databases and their associated metadata such as the gnomAD population variant catalog. This feature enables the incorporation of future genomic information into sequencing analysis.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "MetaSpark": {
                "Name": "MetaSpark:",
                "Description": "Spark-based distributed processing tool to recruit metagenomic reads to reference genomes.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            },
            "nthits": {
                "Name": "ntHits",
                "Description": "De novo repeat identification of genomics data using a streaming approach.\n\nntHits is a method for identifying repeats in high-throughput DNA sequencing data.\n\nntHits uses OpenMP for parallelization, which requires a modern compiler such as GCC 4.2 or greater. If you have an older compiler, it is best to upgrade your compiler if possible. If you have multiple versions of GCC installed, you can specify a different compiler:.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "ParLECH": {
                "Name": "ParLECH",
                "Description": "A hybrid and scalable error correction algorithm for indel and substitution errors of long reads.\n\nBACKGROUND:Long-read sequencing has shown the promises to overcome the short length limitations of second-generation sequencing by providing more complete assembly. However, the computation of the long sequencing reads is challenged by their higher error rates (e.g., 13% vs. 1%) and higher cost ($0.3 vs. $0.03 per Mbp) compared to the short reads. METHODS:In this paper, we present a new hybrid error correction tool, called ParLECH (Parallel Long-read Error Correction using Hybrid methodology). The error correction algorithm of ParLECH is distributed in nature and efficiently utilizes the k-mer coverage information of high throughput Illumina short-read sequences to rectify the PacBio long-read sequences.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": true
            },
            "refka": {
                "Name": "RefKA",
                "Description": "A fast and efficient long-read genome assembly approach for large and complex genomes.\n\nRecent advances in long-read sequencing have the potential to produce more complete genome assemblies using sequence reads which can span repetitive regions. However, overlap based assembly methods routinely used for this data require significant computing time and resources. We have developed RefKA, a reference-based approach for long read genome assembly. This approach relies on breaking up a closely related reference genome into bins, aligning k-mers unique to each bin with PacBio reads, and then assembling each bin in parallel followed by a final bin-stitching step.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "reindeer": {
                "Name": "REINDEER",
                "Description": "efficient indexing of k-mer presence and abundance in sequencing datasets.\n\nREINDEER builds a data-structure that indexes k-mers and their abundances in a collection of datasets (raw RNA-seq or metagenomic reads for instance). Then, a sequence (FASTA) can be queried for its presence and abundance in each indexed dataset. While other tools (e.g. SBT, BIGSI) were also designed for large-scale k-mer presence/absence queries, retrieving abundances was so far unsupported (except for single datasets, e.g. using some k-mer counters like KMC, Jellyfish). REINDEER combines fast queries, small index size, and low memory footprint during indexing and queries. We showed it allows to index 2585 RNA-seq datasets (~4 billions k-mers) using less than 60GB of RAM and a final index size lower than 60GB on the disk. Then, a REINDEER index can either be queried on disk (experimental feature, low RAM usage) or be loaded in RAM for faster queries.",
                "GPU": false,
                "CPU": false,
                "ram": true,
                "parallel": false,
                "distributed": false
            },
            "SWAPCounter": {
                "Name": "SWAPCounter",
                "Description": "Counting Kmers for Biological Sequences at Large Scale.\n\nThis is a distributed kmer counting tools for TB-PB sequencing dataset",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            }
        }
    },
    "operation_0571": {
        "Name": "Expression data visualisation",
        "Count": 2,
        "Tools": {
            "d-ee": {
                "Name": "D-EE",
                "Description": "D-EE is a distributed dimensionality reduction and visualization tool. Its distributed storage and distributed computation technique allow us to efficiently analyze large-scale single-cell data at the cost of constant time speedup.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            },
            "rseqrep": {
                "Name": "RSEQREP",
                "Description": "Cloud-enabled framework that allows users to execute start-to-end gene-level RNA-Seq analysis. It works with unstranded, stranded, and paired-end sequence FASTQ files. It automatically executes a series of customizable steps including reference alignment, CRAM compression, reference alignment QC, data normalization, multivariate data visualization, identification of differentially expressed genes, heatmaps, co-expressed gene clusters, enriched pathways, and a series of custom visualizations.",
                "GPU": false,
                "CPU": false,
                "ram": true,
                "parallel": false,
                "distributed": false
            }
        }
    },
    "operation_0276": {
        "Name": "Protein interaction network analysis",
        "Count": 1,
        "Tools": {
            "dasmiweb": {
                "Name": "DASMIweb",
                "Description": "Server that allows integration, analysis and quantitative assessment of distributed sources of protein and domain interactions. Users can query numerous sources simultaneously, which can then be configured and can support incorporation of user data.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            }
        }
    },
    "operation_3644": {
        "Name": "de Novo sequencing",
        "Count": 6,
        "Tools": {
            "datma": {
                "Name": "DATMA",
                "Description": "DATMA (Distributed AuTomatic Metagenomic Assembly and annotation framework) is a distributed automatic pipeline for fast metagenomic analysis that includes: sequencing quality control, 16S-identification, reads binning, de novo assembly, ORF detection and taxonomic annotation.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            },
            "denovocnn": {
                "Name": "DeNovoCNN",
                "Description": "DeNovoCNN is a deep learning approach to call de novo mutations (DNMs) on whole-exome (WES) and whole-genome sequencing (WGS) data. DeNovoCNN uses trio recalibrated BAM/CRAM + VCF (or tab-separated list of variants) files to generate image-like genomic sequence representations and detect DNMs with high accuracy.",
                "GPU": false,
                "CPU": false,
                "ram": true,
                "parallel": false,
                "distributed": false
            },
            "MRUniNovo": {
                "Name": "MRUniNovo",
                "Description": "Tool for de novo peptide sequencing utilizing the hadoop distributed computing framework.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            },
            "nthits": {
                "Name": "ntHits",
                "Description": "De novo repeat identification of genomics data using a streaming approach.\n\nntHits is a method for identifying repeats in high-throughput DNA sequencing data.\n\nntHits uses OpenMP for parallelization, which requires a modern compiler such as GCC 4.2 or greater. If you have an older compiler, it is best to upgrade your compiler if possible. If you have multiple versions of GCC installed, you can specify a different compiler:.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "perceptron": {
                "Name": "PERCEPTRON",
                "Description": "PERCEPTRON is an open-source GPU-accelerated proteoform identification pipeline for top-down proteomics. PERCEPTRON is a freely available web-based proteoform identification pipeline for Top-Down Proteomics (TDP).",
                "GPU": true,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": false
            },
            "rhinella": {
                "Name": "Rhinella arenarum transcriptome",
                "Description": "The common toad Rhinella arenarum is widely distributed in Argentina, where it is utilised as an autochthonous model in ecotoxicological research and environmental toxicology. However, the lack of a reference genome makes molecular assays and gene expression studies difficult to carry out on this non-model species. To address this issue, we performed a genome-wide transcriptome analysis on R. arenarum larvae through massive RNA sequencing, followed by de novo assembly, annotation, and gene prediction. We obtained 57,407 well-annotated transcripts representing 99.4% of transcriptome completeness (available at http: rhinella.uncoma.edu.ar). We also defined a set of 52,800 high-confidence lncRNA transcripts and demonstrated the reliability of the transcriptome data to perform phylogenetic analysis",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            }
        }
    },
    "operation_3798": {
        "Name": "Read binning",
        "Count": 3,
        "Tools": {
            "datma": {
                "Name": "DATMA",
                "Description": "DATMA (Distributed AuTomatic Metagenomic Assembly and annotation framework) is a distributed automatic pipeline for fast metagenomic analysis that includes: sequencing quality control, 16S-identification, reads binning, de novo assembly, ORF detection and taxonomic annotation.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            },
            "maude": {
                "Name": "MAUDE",
                "Description": "Inferring expression changes in sorting-based CRISPR screens.\n\nMAUDE: Mean Alterations Using Discrete Expression.\n\nMAUDE is an R package for finding differences in means of normally distributed (or nearly so) data, via measuring abundances in discrete bins.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            },
            "refka": {
                "Name": "RefKA",
                "Description": "A fast and efficient long-read genome assembly approach for large and complex genomes.\n\nRecent advances in long-read sequencing have the potential to produce more complete genome assemblies using sequence reads which can span repetitive regions. However, overlap based assembly methods routinely used for this data require significant computing time and resources. We have developed RefKA, a reference-based approach for long read genome assembly. This approach relies on breaking up a closely related reference genome into bins, aligning k-mers unique to each bin with PacBio reads, and then assembling each bin in parallel followed by a final bin-stitching step.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            }
        }
    },
    "operation_3928": {
        "Name": "Pathway analysis",
        "Count": 2,
        "Tools": {
            "deepnog": {
                "Name": "DeepNOG",
                "Description": "DeepNOG is a tool for protein orthologous groups assignment. Assign proteins to orthologous groups (eggNOG 5) on CPUs or GPUs with deep networks. DeepNOG is much faster than alignment-based methods, providing accuracy similar to HMMER.",
                "GPU": true,
                "CPU": true,
                "ram": false,
                "parallel": false,
                "distributed": false
            },
            "petal": {
                "Name": "PETAL",
                "Description": "PETAL (ParallEl paThways AnaLyzer): a python tool for deep analysis of biological pathways.\n\n\nPETAL software is written in the Python 3 programming language. It contains a set of tools for pathway analysis and discovery of novel therapeutic targets. The approach allows you to scan and perform a in-depth search of the biological pathway to analyze less recurrent pathways, detect nodes that are far from the initial target nodes and showing the pathway of origin from which it was taken the gene.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            }
        }
    },
    "operation_3902": {
        "Name": "RNA binding site prediction",
        "Count": 1,
        "Tools": {
            "deepRAM": {
                "Name": "deepRAM",
                "Description": "Comprehensive evaluation of deep learning architectures for prediction of DNA/RNA sequence binding specificities | End-to-end deep learning toolkit for predicting protein binding sites and motifs | deepRAM is an end-to-end deep learning toolkit for predicting protein binding sites and motifs. It helps users run experiments using many state-of-the-art deep learning methods and addresses the challenge of selecting model parameters in deep learning models using a fully automatic model selection strategy. This helps avoid hand-tuning and thus removes any bias in running experiments, making it user friendly without losing its flexibility. While it was designed with ChIP-seq and CLIP-seq data in mind, it can be used for any DNA/RNA sequence binary classification problem",
                "GPU": false,
                "CPU": false,
                "ram": true,
                "parallel": false,
                "distributed": false
            }
        }
    },
    "operation_0272": {
        "Name": "Residue contact prediction",
        "Count": 1,
        "Tools": {
            "deeptrio": {
                "Name": "DeepTrio",
                "Description": "A ternary prediction system for protein-protein interaction using mask multiple parallel convolutional neural networks.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            }
        }
    },
    "operation_0478": {
        "Name": "Molecular docking",
        "Count": 3,
        "Tools": {
            "deeptrio": {
                "Name": "DeepTrio",
                "Description": "A ternary prediction system for protein-protein interaction using mask multiple parallel convolutional neural networks.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "gramm-x": {
                "Name": "GRAMM-X",
                "Description": "GRAMM-X is a protein docking server.",
                "GPU": false,
                "CPU": false,
                "ram": true,
                "parallel": false,
                "distributed": false
            },
            "spark-vs": {
                "Name": "Spark-VS",
                "Description": "Spark-based library for setting up massively parallel Structure-Based Virtual Screening (SBVS) pipelines in Spark.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            }
        }
    },
    "operation_2492": {
        "Name": "Protein interaction prediction",
        "Count": 4,
        "Tools": {
            "deeptrio": {
                "Name": "DeepTrio",
                "Description": "A ternary prediction system for protein-protein interaction using mask multiple parallel convolutional neural networks.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "node2loc": {
                "Name": "node2loc",
                "Description": "Predicting protein subcellular location using learned distributed representations from a protein-protein network | Predicting protein subcellular location using node embedding | we present a deep learning based method, node2loc, to predict protein subcellular location. node2loc first learns distributed representations of proteins in a protein-protein network, which acquires representations from unlabeled data for downstream tasks. Then the learned representations are further fed into a recurrent neural network (RNN) to predict subcellular locations | To identify the functions of a protein, we first need know where this protein is located. Interacting proteins tend to locate in the same subcellular location. Thus, it is imperative to take the protein-protein interactions into account for computational identification of protein subcellular locations",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            },
            "profeatx": {
                "Name": "ProFeatX",
                "Description": "A parallelized protein feature extraction suite for machine learning.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "promocell": {
                "Name": "ProMoCell",
                "Description": "ProMoCell (Protein interaction-based functional Modules of the Cell of an organism) is a network-based zoning approach that can determine the functional modules of a cell of an organism and can potentially be utilized for parallel whole-cell simulation. ProMoCell is a single-click web service and it is very simple, user-friendly and easy to use. Presumably, no other web services like ProMoCell exists till date.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            }
        }
    },
    "operation_3094": {
        "Name": "Protein interaction network prediction",
        "Count": 1,
        "Tools": {
            "deeptrio": {
                "Name": "DeepTrio",
                "Description": "A ternary prediction system for protein-protein interaction using mask multiple parallel convolutional neural networks.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            }
        }
    },
    "operation_3675": {
        "Name": "Variant filtering",
        "Count": 2,
        "Tools": {
            "denovocnn": {
                "Name": "DeNovoCNN",
                "Description": "DeNovoCNN is a deep learning approach to call de novo mutations (DNMs) on whole-exome (WES) and whole-genome sequencing (WGS) data. DeNovoCNN uses trio recalibrated BAM/CRAM + VCF (or tab-separated list of variants) files to generate image-like genomic sequence representations and detect DNMs with high accuracy.",
                "GPU": false,
                "CPU": false,
                "ram": true,
                "parallel": false,
                "distributed": false
            },
            "GoldenMutagenesis": {
                "Name": "GoldenMutagenesis",
                "Description": "The Golden Gate cloning technique has been proven to be a highly efficient toolbox for a variety of cloning setups. Based on its modular concept it is particularly suitable for the use in multiple-site mutagenesis approaches. In this technical note we developed a protocol termed Golden Mutagenesis for the rapid, easy, reliable and cheap formation of mutagenesis libraries. One to five positions could be altered in parallel or simultaneously within two days. To facilitate the implementation of this technique, this R-library has been developed for the automated primer design and the graphical evaluation of sequencing results to determine the quality of the library.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            }
        }
    },
    "operation_3704": {
        "Name": "Ion counting",
        "Count": 1,
        "Tools": {
            "diapasef": {
                "Name": "diaPASEF",
                "Description": "diaPASEF is an appproch for parallel accumulation-serial fragmentation combined with data-independent acquisition.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            }
        }
    },
    "operation_3767": {
        "Name": "Protein identification",
        "Count": 2,
        "Tools": {
            "diapasef": {
                "Name": "diaPASEF",
                "Description": "diaPASEF is an appproch for parallel accumulation-serial fragmentation combined with data-independent acquisition.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "isgp-drlf": {
                "Name": "isGP-DRLF",
                "Description": "Identification of Sub-Golgi protein localization by use of deep representation learning features.\n\nif computing on a GPU, it would be fasster.",
                "GPU": true,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": false
            }
        }
    },
    "operation_3680": {
        "Name": "RNA-Seq analysis",
        "Count": 3,
        "Tools": {
            "Dr.seq2": {
                "Name": "Dr.seq2",
                "Description": "A quality control and analysis pipeline for parallel single cell transcriptome and epigenome data. It provides quality control and analysis functionalities for three data types: single cell transcriptome data, Drop-ChIP data and scATAC-seq data.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "FB5P-seq": {
                "Name": "FB5P-seq",
                "Description": "FACS-based 5-prime end single-cell RNAseq for integrative analysis of transcriptome and antigen receptor repertoire in B and T cells.\n\nFB5P-seq: FACS-based 5'-end single-cell RNA-seq.\n\nCopyright 2019: PMlab, Centre d'Immunologie de Marseille-Luminy This work is distributed under the terms of the GNU General Public License. It is free to use for all purposes.\n\nFB5P-seq is a computational pipeline to process single-cell RNA sequencing (scRNAseq) data produced with the FB5P-seq protocol designed by the Milpied lab at Centre d'Immunologie de Marseille-Luminy. The pipeline relies on 5 main softwares:",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            },
            "watchdog": {
                "Name": "Watchdog",
                "Description": "Workflow management system for the automated and distributed analysis of large-scale experimental data",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            }
        }
    },
    "operation_3482": {
        "Name": "Antimicrobial resistance prediction",
        "Count": 1,
        "Tools": {
            "DRAMP": {
                "Name": "DRAMP",
                "Description": "updated data repository of antimicrobial peptides | Browse, Create and Mining Antimicrobial Peptides | 157 new entries are added to in DRAMP. 33 entries are natural AMPs including 31 animal AMPs and 2 plant AMPs. 124 entries are synthetic AMPs | A brief introduction to DRAMP database | DRAMP database is an information portal to biological active peptides. Peptides in this database come from three sources : Public databases (Swiss-Prot, PDB, PubMed), Clinical antimicrobial peptides (preclinical and clinical) and Patents | DRAMP(Data repository of antimicrobial peptides) is an open-access and manually curated database harboring diverse annotations of AMPs including sequences, structures, activities, physicochemical, patent, clinical and reference information | We are responsible for maintaining the website daily and updating the database regularly",
                "GPU": false,
                "CPU": false,
                "ram": true,
                "parallel": false,
                "distributed": false
            }
        }
    },
    "operation_3646": {
        "Name": "Peptide database search",
        "Count": 3,
        "Tools": {
            "DRAMP": {
                "Name": "DRAMP",
                "Description": "updated data repository of antimicrobial peptides | Browse, Create and Mining Antimicrobial Peptides | 157 new entries are added to in DRAMP. 33 entries are natural AMPs including 31 animal AMPs and 2 plant AMPs. 124 entries are synthetic AMPs | A brief introduction to DRAMP database | DRAMP database is an information portal to biological active peptides. Peptides in this database come from three sources : Public databases (Swiss-Prot, PDB, PubMed), Clinical antimicrobial peptides (preclinical and clinical) and Patents | DRAMP(Data repository of antimicrobial peptides) is an open-access and manually curated database harboring diverse annotations of AMPs including sequences, structures, activities, physicochemical, patent, clinical and reference information | We are responsible for maintaining the website daily and updating the database regularly",
                "GPU": false,
                "CPU": false,
                "ram": true,
                "parallel": false,
                "distributed": false
            },
            "mr-mspolygraph": {
                "Name": "MR-MSPOLYGRAPH",
                "Description": "MR-MSPOLYGRAPH is a MapReduce based implementation for parallelizing peptide identification from mass spectrometry data",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "SW-Tandem": {
                "Name": "SW-Tandem",
                "Description": "Tool for large-scale peptide identification with parallel spectrum dot product on Sunway TaihuLight.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            }
        }
    },
    "operation_3455": {
        "Name": "Molecular replacement",
        "Count": 1,
        "Tools": {
            "easyamber": {
                "Name": "easyAmber",
                "Description": "EasyAmber is a comprehensive toolbox to automate the molecular dynamics simulation of proteins. EasyAmber is a set of wrapper scripts to automate the molecular dynamics routines implemented in the Amber package. The toolbox can address a wide set of tasks in computational biology struggling to account for protein flexibility, and supports the full-atom model building, optimization/equilibration of the molecular system, classical/conventional and accelerated molecular dynamics simulations. The easyAmber software takes the molecular dynamics to the next level in terms of usability for complex processing of large volumes of data. It implements advanced MD protocols, but is highly automated and easy-to-operate to attract a broad audience. The toolbox can be used on a personal desktop station equipped with a gaming GPU-accelerator, as well as help to manage huge workloads on a powerful supercomputer.",
                "GPU": true,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": false
            }
        }
    },
    "operation_0379": {
        "Name": "Repeat sequence detection",
        "Count": 1,
        "Tools": {
            "ExpansionHunter_Denovo": {
                "Name": "ExpansionHunter Denovo",
                "Description": "A computational method for locating known and novel repeat expansions in short-read sequencing data.\n\nA suite of tools for detecting expansions of short tandem repeats.\n\nExpansionHunter Denovo (EHdn) is a suite of tools for detecting novel expansions of short tandem repeats (STRs). EHdn is intended for analysis of a collection of BAM/CRAM files containing alignments of short (100-200bp) reads.",
                "GPU": false,
                "CPU": false,
                "ram": true,
                "parallel": false,
                "distributed": false
            }
        }
    },
    "operation_3185": {
        "Name": "Base-calling",
        "Count": 3,
        "Tools": {
            "f5c": {
                "Name": "f5c",
                "Description": "GPU Accelerated Adaptive Banded Event Alignment for Rapid Comparative Nanopore Signal Analysis | Re-engineered and optimised Nanopolish call-methylation module (supports CUDA acceleration) | An optimised re-implementation of the call-methylation module in Nanopolish. Given a set of basecalled Nanopore reads and the raw signals, f5c detects the methylated cytosine bases. f5c can optionally utilise NVIDIA graphics cards for acceleration",
                "GPU": true,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": false
            },
            "MasterOfPores": {
                "Name": "MasterOfPores",
                "Description": "Parallel and scalable workflow for the analysis of Oxford Nanopore direct RNA sequencing datasets.\n\nNextflow pipeline for analysis of Nanopore reads (from RNA/cDNA/DNA).\n\nPlease read the documentation here: https://biocorecrg.github.io/master_of_pores/.\n\nNextflow pipeline for analysis of Nanopore data from direct RNA sequencing. This is a joint project between CRG bioinformatics core and Epitranscriptomics and RNA Dynamics research group.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "multinanopolish": {
                "Name": "MultiNanopolish",
                "Description": "Refined grouping method for reducing redundant calculations in nanopolish.\n\nNanopolish is a software package for signal-level analysis of Oxford Nanopore sequencing data. Nanopolish can calculate an improved consensus sequence for a draft genome assembly, detect base modifications, call SNPs and indels with respect to a reference genome and more (see Nanopolish for more details).\n\nWe present an efficient implementation of Nanopolish, called MultiNanopolish. MultiNanopolish use a different iterative calculation strategy to reduce redundant calculations. We propose an abstract concept, namely independent computing unit(GroupTask) which can be distributed to the thread pool for multi-thread concurrent computing.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            }
        }
    },
    "operation_0324": {
        "Name": "Phylogenetic analysis",
        "Count": 1,
        "Tools": {
            "fastme": {
                "Name": "FastME",
                "Description": "Distance algorithms to infer phylogenies. It's based on balanced minimum evolution, which is the very principle of NJ. It includes Nearest Neighbor Interchange (NNI) and also Subtree Pruning and Regrafting (SPR), while remaining as fast as NJ and providing a number of facilities: distance estimation for DNA and proteins with various models and options, bootstrapping, and parallel computations.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            }
        }
    },
    "operation_0540": {
        "Name": "Phylogenetic inference (from molecular sequences)",
        "Count": 2,
        "Tools": {
            "fastme": {
                "Name": "FastME",
                "Description": "Distance algorithms to infer phylogenies. It's based on balanced minimum evolution, which is the very principle of NJ. It includes Nearest Neighbor Interchange (NNI) and also Subtree Pruning and Regrafting (SPR), while remaining as fast as NJ and providing a number of facilities: distance estimation for DNA and proteins with various models and options, bootstrapping, and parallel computations.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "veryfasttree": {
                "Name": "VeryFastTree",
                "Description": "VeryFastTree is a highly-tuned implementation of the FastTree-2 tool that takes advantage of parallelization and vectorization strategies to speed up the inference of phylogenies for huge alignments. It is important to highlight that VeryFastTree keeps unchanged the phases, methods and heuristics used by FastTree-2 to estimate the phylogenetic tree. In this way, it produces trees with the same topological accuracy than FastTree-2. In addition, unlike the parallel version of FastTree-2, VeryFastTree is deterministic.\n\nTo facilitate the adoption from the research community, VeryFastTree keeps exactly the same command line arguments than FastTree-2. In this way, it is only necessary to replace the call to FastTree-2 by a call to VeryFastTree using the same options to increase the overall performance.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            }
        }
    },
    "operation_3219": {
        "Name": "Read pre-processing",
        "Count": 2,
        "Tools": {
            "flexbar": {
                "Name": "Flexbar",
                "Description": "Flexible barcode and adapter removal. It demultiplexes barcoded runs and removes adapter sequences. Several adapter removal presets for Illumina libraries are included. Computes exact overlap alignments using SIMD and multicore parallelism. Moreover, trimming and filtering features are provided. It increases read mapping rates and improves genome as well as transcriptome assemblies.  The software supports data in fasta and fastq format from multiple sequencing platforms.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "tis": {
                "Name": "TIS",
                "Description": "Assessment of methods for Transposon Insertion Sequencing(TIS) analyses.\n\nThe TA are distributed relatively evenly along genome. The Mariner-based transposons can be inserted to impact statistically every gene, with in average more than 30 insertions site per kb. With the low insertion bias, it is easy to build saturated libraries. But local variations means less loci and less statistical power.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            }
        }
    },
    "operation_3237": {
        "Name": "Primer removal",
        "Count": 3,
        "Tools": {
            "flexbar": {
                "Name": "Flexbar",
                "Description": "Flexible barcode and adapter removal. It demultiplexes barcoded runs and removes adapter sequences. Several adapter removal presets for Illumina libraries are included. Computes exact overlap alignments using SIMD and multicore parallelism. Moreover, trimming and filtering features are provided. It increases read mapping rates and improves genome as well as transcriptome assemblies.  The software supports data in fasta and fastq format from multiple sequencing platforms.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "gprimer": {
                "Name": "GPrimer",
                "Description": "GPrimer is a fast GPU-based pipeline for primerdesign for qPCR experiments.",
                "GPU": true,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": false
            },
            "ngs-primerplex": {
                "Name": "NGS-PrimerPlex",
                "Description": "High-throughput primer design for multiplex polymerase chain reactions.\n\nNGS-PrimerPlex is a high-throughput tool for mupltiplex primer design.\n\nIt includes four Python-scripts:.\n\nNGS-PrimerPlex can be run as a Docker image. In this way you only need to install Docker (for windows 7 users this install steps should be performed). If you have 'VD-x, VD-t error', you need to turn on virtualization in BIOS CPU section.",
                "GPU": false,
                "CPU": true,
                "ram": false,
                "parallel": false,
                "distributed": false
            }
        }
    },
    "operation_3180": {
        "Name": "Sequence assembly validation",
        "Count": 1,
        "Tools": {
            "FQStat": {
                "Name": "FQStat",
                "Description": "A parallel architecture for very high-speed assessment of sequencing quality metrics | BACKGROUND:High throughput DNA RNA sequencing has revolutionized biological and clinical research. Sequencing is widely used, and generates very large amounts of data, mainly due to reduced cost and advanced technologies. Quickly assessing the quality of giga-to-tera base levels of sequencing data has become a routine but important task. Identification and elimination of low-quality sequence data is crucial for reliability of downstream analysis results. There is a need for a high-speed tool that uses optimized parallel programming for batch processing and simply gauges the quality of sequencing data from multiple datasets independent of any other processing steps. RESULTS:FQStat is a stand-alone, platform-independent software tool that assesses the quality of FASTQ files using parallel programming",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            }
        }
    },
    "operation_0306": {
        "Name": "Text mining",
        "Count": 2,
        "Tools": {
            "FunGeCo": {
                "Name": "FunGeCo",
                "Description": "A web based tool for estimation of Functional potential of bacterial genomes and microbiomes using Gene Context information.\n\nFunctional potential of bacterial genomes and microbiomes from gene context information.\n\nThis feature allows the user to input a newly sequenced genome and annotate it using gene context based modules generated using extensive literature mining and manual curation. Users can also carry out comparative analysis (synteny view using parallel coordinates) of the uploaded genome with genomes already sequenced in NCBI using interactive visualizations.\n\nThis feature allows comparison of functional modules in sequenced genomes obtained from NCBI. Users can interactively select upto five genomes which are compared using a synteny based visualization (parallel coordinates) and circular genomic representations. Information about individual modules in all these genomes can also be viewed as tabular outputs",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "paramed": {
                "Name": "ParaMed",
                "Description": "A parallel corpus for English-Chinese translation in the biomedical domain.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            }
        }
    },
    "operation_0292": {
        "Name": "Sequence alignment",
        "Count": 15,
        "Tools": {
            "g-blastn": {
                "Name": "G-BLASTN",
                "Description": "GPU-accelerated nucleotide alignment tool based on the widely used NCBI-BLAST.",
                "GPU": true,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": false
            },
            "gpmeta": {
                "Name": "GPMeta",
                "Description": "GPU-accelerated method for ultrarapid pathogen identification from metagenomic sequences.",
                "GPU": true,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": false
            },
            "h-blast": {
                "Name": "H-BLAST",
                "Description": "Fast protein sequence alignment toolkit on heterogeneous computers with GPUs .",
                "GPU": true,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": false
            },
            "mica-aligner": {
                "Name": "MICA-aligner",
                "Description": "New short-read aligner that is optimized in view of MIC\u2019s limitation and the extra parallelism inside each MIC core.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "mummergpu": {
                "Name": "MUMmerGPU",
                "Description": "MUMmerGPU is a low cost, ultra-fast sequence alignment program designed to handle the increasing volume of data produced by HTS.",
                "GPU": true,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": false
            },
            "mutationTCN": {
                "Name": "mutationTCN",
                "Description": "Prediction of Mutation Effects using a Deep Temporal Convolutional Network.\n\nThis is the code for the paper Prediction of Mutation Effects using a Deep Temporal Convolutional Network. https://academic.oup.com/bioinformatics/advance-article/doi/10.1093/bioinformatics/btz873/5634146.\n\nThe code is compatible with tensorflow-gpu=1.10.0 and python=2.7",
                "GPU": true,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": false
            },
            "myrialign": {
                "Name": "Myrialign",
                "Description": "Software to align short reads produced by a short read genome sequencer to a reference genome. It performs brute force alignment using a variant on the 'bitap' algorithm that aligns several thousand reads to a reference in parallel. It uses bit-parallelism, multiple processors, and Cell SPUs if available.\nIt will find alignments with any number of errors up to a user specified cutoff. The emphasis is on doing a 100% accurate search as fast as is possible.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "porthomcl": {
                "Name": "PorthoMCL",
                "Description": "Parallel orthology prediction using MCL for the realm of massive genome availability.\n\nParallel implementation of OrthoMCL.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "sambamba": {
                "Name": "Sambamba",
                "Description": "This tool is a high performance modern robust and fast tool (and library), written in the D programming language, for working with SAM, BAM and CRAM formats.",
                "GPU": false,
                "CPU": false,
                "ram": true,
                "parallel": false,
                "distributed": false
            },
            "sbwt": {
                "Name": "sBWT",
                "Description": "A Burrows\u2013Wheeler transformation BWT based fast indexer/aligner specialized in parallelized indexing and searching for Next Generation Sequencing data.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "seal": {
                "Name": "SEAL",
                "Description": "Seal is a suite of distributed applications for aligning short DNA reads, manipulating and analyzing short read alignments. It is generally run on the Hadoop framework, which makes it particularly well suited for processing large data sets.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            },
            "sneakysnake": {
                "Name": "SneakySnake",
                "Description": "A Fast and Accurate Universal Genome Pre-Alignment Filter for CPUs, GPUs, and FPGAs.\n\nThe first and the only pre-alignment filtering algorithm that works efficiently and fast on modern CPU, FPGA, and GPU architectures. SneakySnake greatly (by more than two orders of magnitude) expedites sequence alignment calculation for both short (Illumina) and long (ONT and PacBio) reads.",
                "GPU": true,
                "CPU": true,
                "ram": false,
                "parallel": false,
                "distributed": false
            },
            "soap3-gpu": {
                "Name": "SOAP3",
                "Description": "SOAP3 is a GPU-based software for aligning short reads to a reference sequence.",
                "GPU": true,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": false
            },
            "swipe": {
                "Name": "SWIPE",
                "Description": "Tool for performing rapid local alignment searches in amino acid or nucleotide sequence databases. It is a highly optimized implementation of the Smith-Waterman algoritm using SIMD parallel computing technology available on common CPUs.",
                "GPU": false,
                "CPU": true,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "winbioinftools": {
                "Name": "WinBioinfTools",
                "Description": "Bioinformatics Tools for Windows Cluster provides: 1) CoCoNUT for pairwise genome comparison, 2) parallel BLAST for biological database search, and 3) parallel global pairwise sequence alignment  running over Windows Cluster running Windows HPC server 2008.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            }
        }
    },
    "operation_0346": {
        "Name": "Sequence similarity search",
        "Count": 4,
        "Tools": {
            "g-blastn": {
                "Name": "G-BLASTN",
                "Description": "GPU-accelerated nucleotide alignment tool based on the widely used NCBI-BLAST.",
                "GPU": true,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": false
            },
            "h-blast": {
                "Name": "H-BLAST",
                "Description": "Fast protein sequence alignment toolkit on heterogeneous computers with GPUs .",
                "GPU": true,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": false
            },
            "ngs-primerplex": {
                "Name": "NGS-PrimerPlex",
                "Description": "High-throughput primer design for multiplex polymerase chain reactions.\n\nNGS-PrimerPlex is a high-throughput tool for mupltiplex primer design.\n\nIt includes four Python-scripts:.\n\nNGS-PrimerPlex can be run as a Docker image. In this way you only need to install Docker (for windows 7 users this install steps should be performed). If you have 'VD-x, VD-t error', you need to turn on virtualization in BIOS CPU section.",
                "GPU": false,
                "CPU": true,
                "ram": false,
                "parallel": false,
                "distributed": false
            },
            "sledgehmmer": {
                "Name": "SledgeHMMER",
                "Description": "Tool for searching the Pfam database using a parallelized version of the program hmmpfam. The user can perform queries with one or more sequences at a time and then receive the results by e-mail.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            }
        }
    },
    "operation_3216": {
        "Name": "Scaffolding",
        "Count": 5,
        "Tools": {
            "galaxytrakr": {
                "Name": "GalaxyTrakr",
                "Description": "A distributed analysis tool for public health whole genome sequence data accessible to non-bioinformaticians.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            },
            "haslr": {
                "Name": "HASLR",
                "Description": "Fast Hybrid Assembly of Long Reads.\n\nHASLR is a tool for rapid genome assembly of long sequencing reads. HASLR is a hybrid tool which means it requires long reads generated by Third Generation Sequencing technologies (such as PacBio or Oxford Nanopore) together with Next Generation Sequencing reads (such as Illumina) from the same sample. HASLR is capable of assembling large genomes on a single computing node. Our experiments show that it can assemble a CHM1 human dataset in less than 10 hours using 64 CPU threads.",
                "GPU": false,
                "CPU": true,
                "ram": false,
                "parallel": false,
                "distributed": false
            },
            "pe-assembler": {
                "Name": "PE-Assembler",
                "Description": "A simple 3' extension approach to assembling paired-end reads and capable of parallelization.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "pgcloser": {
                "Name": "PGcloser",
                "Description": "Fast Parallel Gap-Closing Tool Using Long-Reads or Contigs to Fill Gaps in Genomes.\n\nThis tool is for gap-closing in the genome using long-reads or contigs. PGcloser contains 7 modules: SplitFa, ExtrGap, BwtBuilt, CompGap, ClsGap, MergFa and GetCls.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "trap-seq": {
                "Name": "TRAP-seq",
                "Description": "Massively parallel quantification of CRISPR editing in cells by TRAP-seq enables better design of Cas9, ABE, CBE gRNAs of high efficiency and accuracy.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            }
        }
    },
    "operation_0315": {
        "Name": "Expression profile comparison",
        "Count": 1,
        "Tools": {
            "Gene2vec": {
                "Name": "Gene2vec",
                "Description": "Machine learning method that utilizes transcriptome-wide gene co-expression to generate a distributed representation of genes.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            }
        }
    },
    "operation_3766": {
        "Name": "Weighted correlation network analysis",
        "Count": 3,
        "Tools": {
            "Gene2vec": {
                "Name": "Gene2vec",
                "Description": "Machine learning method that utilizes transcriptome-wide gene co-expression to generate a distributed representation of genes.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            },
            "mcpnet": {
                "Name": "MCPNet",
                "Description": "Parallel maximum capacity-based genome-scale gene network construction framework.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "wish-r": {
                "Name": "WISH-R",
                "Description": "WISH-R package (WISH-R) can calculate epistatic interactions using a linear or generalized linear model on a genome-wide level using genomic data and phenotype/disease data in a fully parallelized environment, and visualize genome-wide epistasis in many ways.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            }
        }
    },
    "operation_0544": {
        "Name": "Species tree construction",
        "Count": 2,
        "Tools": {
            "GeneRax": {
                "Name": "GeneRax",
                "Description": "A tool for species tree-aware maximum likelihood based gene tree inference under gene duplication, transfer, and loss | GeneRax is a parallel tool for species tree-aware maximum likelihood based gene tree inference under gene duplication, transfer, and loss",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "starbeast3": {
                "Name": "StarBeast3",
                "Description": "BEAST 2 based package for Bayesian multispecies coalescent (MSC) analyses using efficient and parallelised MCMC operators.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            }
        }
    },
    "operation_0547": {
        "Name": "Phylogenetic inference (maximum likelihood and Bayesian methods)",
        "Count": 3,
        "Tools": {
            "GeneRax": {
                "Name": "GeneRax",
                "Description": "A tool for species tree-aware maximum likelihood based gene tree inference under gene duplication, transfer, and loss | GeneRax is a parallel tool for species tree-aware maximum likelihood based gene tree inference under gene duplication, transfer, and loss",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "starbeast3": {
                "Name": "StarBeast3",
                "Description": "BEAST 2 based package for Bayesian multispecies coalescent (MSC) analyses using efficient and parallelised MCMC operators.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "veryfasttree": {
                "Name": "VeryFastTree",
                "Description": "VeryFastTree is a highly-tuned implementation of the FastTree-2 tool that takes advantage of parallelization and vectorization strategies to speed up the inference of phylogenies for huge alignments. It is important to highlight that VeryFastTree keeps unchanged the phases, methods and heuristics used by FastTree-2 to estimate the phylogenetic tree. In this way, it produces trees with the same topological accuracy than FastTree-2. In addition, unlike the parallel version of FastTree-2, VeryFastTree is deterministic.\n\nTo facilitate the adoption from the research community, VeryFastTree keeps exactly the same command line arguments than FastTree-2. In this way, it is only necessary to replace the call to FastTree-2 by a call to VeryFastTree using the same options to increase the overall performance.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            }
        }
    },
    "operation_0552": {
        "Name": "Phylogenetic tree bootstrapping",
        "Count": 2,
        "Tools": {
            "GeneRax": {
                "Name": "GeneRax",
                "Description": "A tool for species tree-aware maximum likelihood based gene tree inference under gene duplication, transfer, and loss | GeneRax is a parallel tool for species tree-aware maximum likelihood based gene tree inference under gene duplication, transfer, and loss",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "ParGenes": {
                "Name": "ParGenes",
                "Description": "Tool for massively parallel model selection and phylogenetic tree inference on thousands of genes.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            }
        }
    },
    "operation_3563": {
        "Name": "RNA-seq read count analysis",
        "Count": 2,
        "Tools": {
            "GLM-PCA": {
                "Name": "GLM-PCA",
                "Description": "Feature selection and dimension reduction for single-cell RNA-Seq based on a multinomial model.\n\nDimension Reduction of Non-Normally Distributed Data.\n\nImplements a generalized version of principal components analysis (GLM-PCA) for dimension reduction of non-normally distributed data such as counts or binary matrices.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            },
            "scdrake": {
                "Name": "scdrake",
                "Description": "Scdrake is a highly scalable, reproducible and configurable pipeline for scRNA-seq data prepared by a popular 10x Genomics droplet-based technology. Scdrake is implemented as a package for the R language and is built on top of the drake package, a Make-like pipeline toolkit. Scdrake currently provides common steps of scRNA-seq data analysis: quality control and filtering of cells and genes, normalization, dimensionality reduction, clustering, finding of cluster markers and differentially expressed genes between clusters, and integration of multiple datasets. All pipeline steps are accompanied by rich graphical outputs and reports in HTML format.\n\nThanks to the drake package, all intermediate results can be reused, and the pipeline can be easily extended by users to incorporate custom analyses. Also, drake analyzes which parts of the pipeline are already done or haven't changed since the last run, and which can be run in parallel, resulting in great execution speed.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            }
        }
    },
    "operation_0302": {
        "Name": "Protein threading",
        "Count": 4,
        "Tools": {
            "gpu-i-tasser": {
                "Name": "GPU-I-TASSER",
                "Description": "A GPU accelerated I-TASSER protein structure prediction tool.",
                "GPU": true,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": false
            },
            "HPCCS": {
                "Name": "HPCCS",
                "Description": "Collision Cross Section Calculations Using HPCCS.\n\nThe High Performance Collision Cross Section (HPCCS) is a new software for fast and accurate calculation of CCS for molecular ions. Based on the Trajectory Method (TM), HPCCS was parallelized and optimized to be an user-friendly program.\n\nHigh Performance Collision Cross Section Calculation \u2013 HPCCS",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "lara_2": {
                "Name": "LaRA 2",
                "Description": "Parallel and vectorized program for sequence-structure alignment of RNA sequences.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "profeatx": {
                "Name": "ProFeatX",
                "Description": "A parallelized protein feature extraction suite for machine learning.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            }
        }
    },
    "operation_1777": {
        "Name": "Protein function prediction",
        "Count": 1,
        "Tools": {
            "gpu-i-tasser": {
                "Name": "GPU-I-TASSER",
                "Description": "A GPU accelerated I-TASSER protein structure prediction tool.",
                "GPU": true,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": false
            }
        }
    },
    "operation_2404": {
        "Name": "Sequence motif analysis",
        "Count": 1,
        "Tools": {
            "gpumotif": {
                "Name": "GPUmotif",
                "Description": "GPU-accelerated ultra-fast and energy-efficient motif analysis program.",
                "GPU": true,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": false
            }
        }
    },
    "operation_0441": {
        "Name": "cis-regulatory element prediction",
        "Count": 2,
        "Tools": {
            "GRAM": {
                "Name": "GRAM",
                "Description": "A GeneRAlized Model to predict the molecular effect of a non-coding variant in a cell-type specific manner | GRAM: A GeneRAlized Model to predict the molecular effect of a non-coding variant in a cell type-specific manner",
                "GPU": false,
                "CPU": false,
                "ram": true,
                "parallel": false,
                "distributed": false
            },
            "RAMPAGE": {
                "Name": "RAMPAGE",
                "Description": "> VERY_LOW CONFIDENCE! | > CORRECT NAME OF TOOL COULD ALSO BE 'Alu', 'III-transcribed', 'Pol III-transcribed', 'III-transcribed Alu' | Genome-wide analysis of polymerase III-transcribed Alu elements suggests cell-type-specific enhancer function | Pipeline to identify expressed Alu elements using RAMPAGE | A schematic flow shows the pipeline",
                "GPU": false,
                "CPU": false,
                "ram": true,
                "parallel": false,
                "distributed": false
            }
        }
    },
    "operation_3232": {
        "Name": "Gene expression QTL analysis",
        "Count": 5,
        "Tools": {
            "GRAM": {
                "Name": "GRAM",
                "Description": "A GeneRAlized Model to predict the molecular effect of a non-coding variant in a cell-type specific manner | GRAM: A GeneRAlized Model to predict the molecular effect of a non-coding variant in a cell type-specific manner",
                "GPU": false,
                "CPU": false,
                "ram": true,
                "parallel": false,
                "distributed": false
            },
            "mendeliht.jl": {
                "Name": "MendelIHT.jl",
                "Description": "Implements iterative hard thresholding as a multiple regression model for GWAS. Built-in support for handling PLINK and VCF files, parallel computing, fits a variety of GLM models, and handles group/weighting SNPs.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "plexdb": {
                "Name": "PLEXdb",
                "Description": "Unified gene expression resource for plants and plant pathogens. It is a genotype to phenotype, hypothesis building information warehouse, leveraging highly parallel expression data with seamless portals to related genetic, physical, and pathway data.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "RAMPAGE": {
                "Name": "RAMPAGE",
                "Description": "> VERY_LOW CONFIDENCE! | > CORRECT NAME OF TOOL COULD ALSO BE 'Alu', 'III-transcribed', 'Pol III-transcribed', 'III-transcribed Alu' | Genome-wide analysis of polymerase III-transcribed Alu elements suggests cell-type-specific enhancer function | Pipeline to identify expressed Alu elements using RAMPAGE | A schematic flow shows the pipeline",
                "GPU": false,
                "CPU": false,
                "ram": true,
                "parallel": false,
                "distributed": false
            },
            "rvpedigree": {
                "Name": "RVPedigree",
                "Description": "Family-based rare variant association tests for normally and non-normally distributed quantitative traits. Calculation of kinship matrices, various options for coping with non-normality, three different ways of estimating statistical significance incorporating triaging to enable efficient use of the most computationally-intensive calculations, and a parallelization option for genome-wide analysis.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": true
            }
        }
    },
    "operation_0482": {
        "Name": "Protein-ligand docking",
        "Count": 2,
        "Tools": {
            "gramm-x": {
                "Name": "GRAMM-X",
                "Description": "GRAMM-X is a protein docking server.",
                "GPU": false,
                "CPU": false,
                "ram": true,
                "parallel": false,
                "distributed": false
            },
            "PepVis": {
                "Name": "PepVis",
                "Description": "PepVis tool is a python based GUI pipeline which can be used to model and prepare large-scale peptide structure from the sequence and also to perform large-scale peptide virtual screening. PepVis integrates ModPep and Gromacs for modelling and structure optimization of the peptides, while it integrates AutoDock Vina,ZDOCK, AutoDock CrankPep(ADCP) for performing peptide virtual screening. \nThe protein-peptide complexes can be rescored using ZRANK2 and the flexible refinement of the large protein-peptide complexes can also be performed using FlexPepDock. The parallel job execution has been implemented using GNU parallel and the user can provide inputs using GUI which will produce the bash script based on the customized input provided by the user and can be run in terminal.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            }
        }
    },
    "operation_0440": {
        "Name": "Promoter prediction",
        "Count": 1,
        "Tools": {
            "grgmf": {
                "Name": "GRGMF",
                "Description": "A graph regularized generalized matrix factorization model for predicting links in biomedical bipartite networks.\n\nThis code is the implementation of GRGMF, which is both CPU and CUDA compatible(CUDA is preferred).",
                "GPU": false,
                "CPU": true,
                "ram": false,
                "parallel": false,
                "distributed": false
            }
        }
    },
    "operation_0463": {
        "Name": "miRNA target prediction",
        "Count": 2,
        "Tools": {
            "grgmf": {
                "Name": "GRGMF",
                "Description": "A graph regularized generalized matrix factorization model for predicting links in biomedical bipartite networks.\n\nThis code is the implementation of GRGMF, which is both CPU and CUDA compatible(CUDA is preferred).",
                "GPU": false,
                "CPU": true,
                "ram": false,
                "parallel": false,
                "distributed": false
            },
            "normirazor": {
                "Name": "NormiRazor",
                "Description": "Tool applying GPU-accelerated computing for determination of internal references in microRNA transcription studies.\n\nGitLab is a single application for the entire software development lifecycle. From project planning and source code management to CI/CD, monitoring, and security.",
                "GPU": true,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": false
            }
        }
    },
    "operation_0313": {
        "Name": "Expression profile clustering",
        "Count": 7,
        "Tools": {
            "HCCPred": {
                "Name": "HCCPred",
                "Description": "Identification of Platform-Independent Diagnostic Biomarker Panel for Hepatocellular Carcinoma using Large-scale Transcriptomics Data | A webserver to predict Hepatocellular carcinoma (HCC) | Pipeline Differential Expression Analysis | HCCpred is a web-bench for the prediction of tumorous and non-tumorous Hepatocellular Carcinoma (HCC) patients. Our major prediction modules based on the robust biomarkers such as 3-Gene HCC Biomarker, 4-Gene HCC Biomarker, 5-Gene HCC Biomarker. These HCC biomarkers identified using gene expression profiles of a total of 3,961 samples include 2,306 HCC and 1,655 non-tumorous samples. The datasets derived from various profiling platforms such as Affymatrix, Illumina, High-througput and Agilent. The user can also analyse the expression pattern of any of 26 'core genes of HCC' in cancerous vs normal conditions",
                "GPU": true,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": false
            },
            "plexdb": {
                "Name": "PLEXdb",
                "Description": "Unified gene expression resource for plants and plant pathogens. It is a genotype to phenotype, hypothesis building information warehouse, leveraging highly parallel expression data with seamless portals to related genetic, physical, and pathway data.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "rseqrep": {
                "Name": "RSEQREP",
                "Description": "Cloud-enabled framework that allows users to execute start-to-end gene-level RNA-Seq analysis. It works with unstranded, stranded, and paired-end sequence FASTQ files. It automatically executes a series of customizable steps including reference alignment, CRAM compression, reference alignment QC, data normalization, multivariate data visualization, identification of differentially expressed genes, heatmaps, co-expressed gene clusters, enriched pathways, and a series of custom visualizations.",
                "GPU": false,
                "CPU": false,
                "ram": true,
                "parallel": false,
                "distributed": false
            },
            "scamace": {
                "Name": "scAMACE",
                "Description": "scAMACE (integrative Analysis of single-cell Methylation, chromatin ACcessibility, and gene Expression). Python implementation (both CPU and GPU version) to a model-based approach to the joint analysis of single-cell data on chromatin accessibility, gene expression and methylation.",
                "GPU": true,
                "CPU": true,
                "ram": false,
                "parallel": false,
                "distributed": false
            },
            "scawmv": {
                "Name": "scAWMV",
                "Description": "An adaptively weighted multi-view learning framework for the integrative analysis of parallel scRNA-seq and scATAC-seq data.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "scdrake": {
                "Name": "scdrake",
                "Description": "Scdrake is a highly scalable, reproducible and configurable pipeline for scRNA-seq data prepared by a popular 10x Genomics droplet-based technology. Scdrake is implemented as a package for the R language and is built on top of the drake package, a Make-like pipeline toolkit. Scdrake currently provides common steps of scRNA-seq data analysis: quality control and filtering of cells and genes, normalization, dimensionality reduction, clustering, finding of cluster markers and differentially expressed genes between clusters, and integration of multiple datasets. All pipeline steps are accompanied by rich graphical outputs and reports in HTML format.\n\nThanks to the drake package, all intermediate results can be reused, and the pipeline can be easily extended by users to incorporate custom analyses. Also, drake analyzes which parts of the pipeline are already done or haven't changed since the last run, and which can be run in parallel, resulting in great execution speed.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "scigans": {
                "Name": "scIGANs",
                "Description": "single-cell RNA-seq imputation using generative adversarial networks.\n\nGenerative adversarial networks for single-cell RNA-seq imputation.\n\nThe data and codes for reproducing all Figures and Tables in the manuscript of scIGANs.\n\nscIGANs is a computational tool for single-cell RNA-seq imputation and denoise using Generative Adversarial Networks (GANs). Build on PyTorch, scIGNAs enables GPU acceleration inaddition to CPU computing as long as the GPUs are available.",
                "GPU": true,
                "CPU": true,
                "ram": false,
                "parallel": false,
                "distributed": false
            }
        }
    },
    "operation_3894": {
        "Name": "DNA profiling",
        "Count": 1,
        "Tools": {
            "HIrisPlex-S": {
                "Name": "HIrisPlex-S",
                "Description": "Massively parallel sequencing solutions for two common forensically used platforms | HIrisPlex-S Eye, Hair and Skin Colour DNA Phenotyping Webtool | 8px 9px 10px 11px 12px 13px 14px 15px 16px 17px 18px | With the advancement of DNA phenotyping as a tool in Forensic and Anthropological usage, we now provide an easy to use interactive website to predict eye, hair and skin colour from DNA using the IrisPlex, HIrisPlex and HIrisPlex-S systems",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            }
        }
    },
    "operation_3206": {
        "Name": "Whole genome methylation analysis",
        "Count": 2,
        "Tools": {
            "hpg-dhunter": {
                "Name": "HPG-DHunter",
                "Description": "An ultrafast, friendly tool for DMR detection and visualization.\n\nIf you want to use this tool just now, there is an executable file for Linux x86_64 systems. This compressed file is available at releases page. But, previously, CUDA and Nvidia drivers must be installed in your system. For that, you can go to System requirements section.\n\nHPG-Dhunter is an interactive tool for detecting Differentially Methylathed Regions (DMRs) and visualizing DNA methylation signals. It is based on building a methylation signal from the information yielded by HPG-HMapper, and using a NVidia GPU and the CUDA programming model to compute the Discrete Wavelet Transform (DWT) of this methylation signal. The transformation of the signals in turn allows the comparison of different signals at low resolution levels, easily identifying DMRs with a low workload, when compared to other strategies. HPG-Dhunter is part of the HPG-MSuite.",
                "GPU": true,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": false
            },
            "methpanel": {
                "Name": "MethPanel",
                "Description": "A parallel pipeline and interactive analysis tool for multiplex bisulphite PCR sequencing to assess DNA methylation biomarker panels for disease detection.\n\nMethPanel is a computational pipeline in Linux operating system with an interactive graphical interface for rapid analysis of multiplex bisulphite PCR sequencing data. The tool covers a complete analysis workflow from genomic alignment to DNA methylation calling and supports an unlimited number of PCR amplicons and input samples. Moreover MethPanel offers important and unique features, such as a epipolymorphism score and a bisulphite PCR bias correction. MethPanel can be run in parallel by samples on either a personal computer or a high performance computer. The outputs are automatically forwarded to a shinyApp for convenient display, visualisation and sharing of data with collaborators and clinicians.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            }
        }
    },
    "operation_3809": {
        "Name": "DMR identification",
        "Count": 1,
        "Tools": {
            "hpg-dhunter": {
                "Name": "HPG-DHunter",
                "Description": "An ultrafast, friendly tool for DMR detection and visualization.\n\nIf you want to use this tool just now, there is an executable file for Linux x86_64 systems. This compressed file is available at releases page. But, previously, CUDA and Nvidia drivers must be installed in your system. For that, you can go to System requirements section.\n\nHPG-Dhunter is an interactive tool for detecting Differentially Methylathed Regions (DMRs) and visualizing DNA methylation signals. It is based on building a methylation signal from the information yielded by HPG-HMapper, and using a NVidia GPU and the CUDA programming model to compute the Discrete Wavelet Transform (DWT) of this methylation signal. The transformation of the signals in turn allows the comparison of different signals at low resolution levels, easily identifying DMRs with a low workload, when compared to other strategies. HPG-Dhunter is part of the HPG-MSuite.",
                "GPU": true,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": false
            }
        }
    },
    "operation_3258": {
        "Name": "Transcriptome assembly",
        "Count": 3,
        "Tools": {
            "hpul": {
                "Name": "Hpul",
                "Description": "Usage of the Sea Urchin Hemicentrotus pulcherrimus Database, HpBase.\n\nHemicentrotus pulcherrimus Genome Resources.\n\nHemicentrotus pulcherrimus Genome and Transcriptome database.\n\nHemicentrotus pulcherrimus (A. Agassiz, 1863) (Animaria: Echinodermata: Echinoidea: Echinoida: Strongylocentrotiae: Hemicentrotus) is the most widely distributed sea urchin in Japan and important marine food resources in eastern Asia. This species has a long history as a model organism in the field of developmental and cell biology since the mid 1900s. The web site provides information on H. pulcherrimus genome and transcriptome for a wide range of biologists.\n\n||| COMMON LINK WITH (PUB. & NAME DIFFERENT) bio.tools/insdc (NIG.AC.JP), bio.tools/dfast (NIG.AC.JP), bio.tools/ddbj (NIG.AC.JP), bio.tools/cibex (NIG.AC.JP)\n\n||| CORRECT NAME OF TOOL COULD ALSO BE 'H pulcherrimus'",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            },
            "orfipy": {
                "Name": "orfipy",
                "Description": "A fast and flexible tool for extracting ORFs.\n\norfipy is a tool written in python/cython to extract ORFs in extremely an fast and flexible manner. Other popular ORF searching tools are OrfM and getorf. Compared to OrfM and getorf, orfipy provides the most options to fine tune ORF searches. orfipy uses multiple CPU cores and is particularly faster for data containing multiple smaller fasta sequences such as de-novo transcriptome assemblies. Please read the preprint here.",
                "GPU": false,
                "CPU": true,
                "ram": false,
                "parallel": false,
                "distributed": false
            },
            "rhinella": {
                "Name": "Rhinella arenarum transcriptome",
                "Description": "The common toad Rhinella arenarum is widely distributed in Argentina, where it is utilised as an autochthonous model in ecotoxicological research and environmental toxicology. However, the lack of a reference genome makes molecular assays and gene expression studies difficult to carry out on this non-model species. To address this issue, we performed a genome-wide transcriptome analysis on R. arenarum larvae through massive RNA sequencing, followed by de novo assembly, annotation, and gene prediction. We obtained 57,407 well-annotated transcripts representing 99.4% of transcriptome completeness (available at http: rhinella.uncoma.edu.ar). We also defined a set of 52,800 high-confidence lncRNA transcripts and demonstrated the reliability of the transcriptome data to perform phylogenetic analysis",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            }
        }
    },
    "operation_0303": {
        "Name": "Fold recognition",
        "Count": 2,
        "Tools": {
            "iblp": {
                "Name": "iBLP",
                "Description": "An XGBoost-Based Predictor for Identifying Bioluminescent Proteins.\n\nThe role of this page is a brief introduction to iBLP.\n\n\nBioluminescent proteins are a class of proteins that widely distributed in many living organisms with various mechanisms of light emission including bioluminescence and chemiluminescence from luminous organisms.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            },
            "Wang-xiaoheng": {
                "Name": "Wang-xiaoheng",
                "Description": "Prediction of protein structural classes by different feature expressions based on 2-D wavelet denoising and fusion.\n\n2D-wavelet-for-protein-structural-classes-prediction We constructed a prediction model based on wavelet denoising using different feature expression methods. A new fusion idea, first fuse and then denoise, is proposed in this article. Two types of pseudo amino acid compositions are utilized to distill feature vectors. Then, a two-dimensional (2-D) wavelet denoising algorithm is used to remove the redundant information from two extracted feature vectors. The two feature vectors based on parallel 2-D wavelet denoising are fused, which is known as PWD-FU-PseAAC. The project includes three original datasets, source code for two-dimensional wavelet denoising and source code for feature vector prediction",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            }
        }
    },
    "operation_3458": {
        "Name": "Single particle alignment and classification",
        "Count": 2,
        "Tools": {
            "imagehts": {
                "Name": "imageHTS",
                "Description": "R package dedicated to the analysis of high-throughput microscopy-based screens. The package provides a modular and extensible framework to segment cells, extract quantitative cell features, predict cell types and browse screen data through web interfaces. Designed to operate in distributed environments, it provides a standardized access to remote data and facilitates the dissemination of high-throughput microscopy-based datasets.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            },
            "isac": {
                "Name": "ISAC",
                "Description": "Accelerated 2D Classification With ISAC Using GPUs.",
                "GPU": true,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": false
            }
        }
    },
    "operation_2489": {
        "Name": "Subcellular localisation prediction",
        "Count": 4,
        "Tools": {
            "isgp-drlf": {
                "Name": "isGP-DRLF",
                "Description": "Identification of Sub-Golgi protein localization by use of deep representation learning features.\n\nif computing on a GPU, it would be fasster.",
                "GPU": true,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": false
            },
            "MetaSanity": {
                "Name": "MetaSanity",
                "Description": "An integrated, customizable microbial genome evaluation and annotation pipeline.\n\nPipeline for major biological analyses.\n\nMetaSanity v1.1.1 - 2020 version.\n\nMetaSanity v1.1.1 provides a unified workflow for genome assessment and functional annotation that combines all outputs into a single queryable database \u2013 all within an easily distributed Docker image",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            },
            "node2loc": {
                "Name": "node2loc",
                "Description": "Predicting protein subcellular location using learned distributed representations from a protein-protein network | Predicting protein subcellular location using node embedding | we present a deep learning based method, node2loc, to predict protein subcellular location. node2loc first learns distributed representations of proteins in a protein-protein network, which acquires representations from unlabeled data for downstream tasks. Then the learned representations are further fed into a recurrent neural network (RNN) to predict subcellular locations | To identify the functions of a protein, we first need know where this protein is located. Interacting proteins tend to locate in the same subcellular location. Thus, it is imperative to take the protein-protein interactions into account for computational identification of protein subcellular locations",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            },
            "prottrans": {
                "Name": "ProtTrans",
                "Description": "ProtTrans is providing state of the art pre-trained models for proteins. ProtTrans was trained on thousands of GPUs from Summit and hundreds of Google TPUs using various Transformers Models.",
                "GPU": true,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": false
            }
        }
    },
    "operation_1781": {
        "Name": "Gene regulatory network analysis",
        "Count": 1,
        "Tools": {
            "jfuzzymachine": {
                "Name": "JFuzzyMachine",
                "Description": "A Multistaged Hyperparallel Optimization of the Fuzzy-Logic Mechanistic Model of Molecular Regulation.\n\nElucidating mechanistic relationships among intracellular macromolecules is fundamental to understanding the molecular basis of normal and diseased processes. The classical fuzzy logic approach employs varying degrees of truth to describe relationships between interacting molecules. jFuzzyMachine implements the fuzzy logic approach to elucidate mechanistic relationships among biological molecules and makes more readily available the fuzzy logic inference approach in a freely available tool.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            }
        }
    },
    "operation_3625": {
        "Name": "Relation extraction",
        "Count": 1,
        "Tools": {
            "jfuzzymachine": {
                "Name": "JFuzzyMachine",
                "Description": "A Multistaged Hyperparallel Optimization of the Fuzzy-Logic Mechanistic Model of Molecular Regulation.\n\nElucidating mechanistic relationships among intracellular macromolecules is fundamental to understanding the molecular basis of normal and diseased processes. The classical fuzzy logic approach employs varying degrees of truth to describe relationships between interacting molecules. jFuzzyMachine implements the fuzzy logic approach to elucidate mechanistic relationships among biological molecules and makes more readily available the fuzzy logic inference approach in a freely available tool.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            }
        }
    },
    "operation_0502": {
        "Name": "RNA secondary structure alignment",
        "Count": 1,
        "Tools": {
            "lara_2": {
                "Name": "LaRA 2",
                "Description": "Parallel and vectorized program for sequence-structure alignment of RNA sequences.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            }
        }
    },
    "operation_3638": {
        "Name": "SILAC",
        "Count": 1,
        "Tools": {
            "MAP": {
                "Name": "MAP",
                "Description": "Model-based analysis of proteomic data to detect proteins with significant abundance changes.\n\nMAP (Model-based Analysis of Proteomic data), is designed to statistically compare the proteomic profiles generated from different biological samples using the isotope labeling based mass spectrometry (MS) technique and directly identify proteins with significant abundance changes. Unlike many existing tools for this purpose, it does not require parallel/additional technical replicates to fathom technical variations; instead, MAP uses a novel step-by-step regression analysis to directly model technical variations from the profiles under comparison. Therefore, experimental designs and their expenses can be simplified and reduced for more practices",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            }
        }
    },
    "operation_3450": {
        "Name": "Neurite measurement",
        "Count": 2,
        "Tools": {
            "MARGO": {
                "Name": "MARGO",
                "Description": "MARGO (Massively Automated Real-time GUI for Object-tracking).\n\nFast object tracking in real time allows convenient tracking of very large numbers of animals and closed-loop experiments that control stimuli for many animals in parallel. We developed MARGO, a MATLAB-based, real-time animal tracking suite for custom behavioral experiments. We demonstrated that MARGO can rapidly and accurately track large numbers of animals in parallel over very long timescales, typically when spatially separated such as in multiwell plates. We incorporated control of peripheral hardware, and implemented a flexible software architecture for defining new experimental routines. These features enable closed-loop delivery of stimuli to many individuals simultaneously. We highlight MARGO's ability to coordinate tracking and hardware control with two custom behavioral assays (measuring phototaxis and optomotor response) and one optogenetic operant conditioning assay.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "neurodevsim": {
                "Name": "NeuroDevSim",
                "Description": "NeuroDevSim is a Neural Development Simulator for Linux of MacOS environments. It is a parallel and phenomenological computational framework to grow large numbers of neuronal morphologies (and resultant microcircuits) simultaneously according to growth-rules expressed in terms of interactions with the environment and internal variables:.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            }
        }
    },
    "operation_3215": {
        "Name": "Peak detection",
        "Count": 1,
        "Tools": {
            "masserstein": {
                "Name": "Masserstein",
                "Description": "Robust linear deconvolution by optimal transport.\n\nThis repository contains software tools which allow to compare spectra using the Wasserstein distance and estimate relative abundances of molecules from the spectrum by minimizing the Wasserstein distance.\n\nThe tools are distributed as a Python3 package called masserstein. Basic functionality is also available as a set of commandline applications: WSDistance to compute the Wasserstein distance and WSDeconv to estimate proportions.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            }
        }
    },
    "operation_3860": {
        "Name": "Spectrum calculation",
        "Count": 2,
        "Tools": {
            "masserstein": {
                "Name": "Masserstein",
                "Description": "Robust linear deconvolution by optimal transport.\n\nThis repository contains software tools which allow to compare spectra using the Wasserstein distance and estimate relative abundances of molecules from the spectrum by minimizing the Wasserstein distance.\n\nThe tools are distributed as a Python3 package called masserstein. Basic functionality is also available as a set of commandline applications: WSDistance to compute the Wasserstein distance and WSDeconv to estimate proportions.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            },
            "NMF-RI": {
                "Name": "NMF-RI",
                "Description": "Blind spectral unmixing of highly mixed multispectral flow and image cytometry data.\n\nMatlab code to spectrally unmix highly mixed multispectral flow and image cytometry data.\n\nTo use NMF-RI on new data (tissue or flow cytometry) we recommend to use the \u00b4main.m\u00b4 code distributed and load new cytometry data to the existing folder hierarchy.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            }
        }
    },
    "operation_0428": {
        "Name": "PolyA signal detection",
        "Count": 1,
        "Tools": {
            "MasterOfPores": {
                "Name": "MasterOfPores",
                "Description": "Parallel and scalable workflow for the analysis of Oxford Nanopore direct RNA sequencing datasets.\n\nNextflow pipeline for analysis of Nanopore reads (from RNA/cDNA/DNA).\n\nPlease read the documentation here: https://biocorecrg.github.io/master_of_pores/.\n\nNextflow pipeline for analysis of Nanopore data from direct RNA sequencing. This is a joint project between CRG bioinformatics core and Epitranscriptomics and RNA Dynamics research group.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            }
        }
    },
    "operation_0323": {
        "Name": "Phylogenetic inference",
        "Count": 3,
        "Tools": {
            "medicc2": {
                "Name": "MEDICC2",
                "Description": "Whole-genome doubling-aware copy number phylogenies for cancer evolution with MEDICC2. Chromosomal instability (CIN) and somatic copy number alterations (SCNA) play a key role in the evolutionary process that shapes cancer genomes. SCNAs comprise many classes of clinically relevant events, such as localised amplifications, gains, losses, loss-of-heterozygosity (LOH) events, and recently discovered parallel evolutionary events revealed by multi-sample phasing. These events frequently appear jointly with whole genome doubling (WGD), a transformative event in tumour evolution, which generates tetraploid or near-tetraploid cells. WGD events are often clonal, occuring before the emergence of the most recent common ancestor, and have been associated with increased CIN, poor patient outcome and are currently being investigated as potential therapeutic targets",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "sitepath": {
                "Name": "sitePath",
                "Description": "A visual tool to identify polymorphism clades and help find fixed and parallel mutations.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "Treerecs": {
                "Name": "Treerecs",
                "Description": "Treerecs is an open-source (species- and gene-) tree reconciliation software distributed under the GNU AGPL licence.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            }
        }
    },
    "operation_0487": {
        "Name": "Haplotype mapping",
        "Count": 3,
        "Tools": {
            "medicc2": {
                "Name": "MEDICC2",
                "Description": "Whole-genome doubling-aware copy number phylogenies for cancer evolution with MEDICC2. Chromosomal instability (CIN) and somatic copy number alterations (SCNA) play a key role in the evolutionary process that shapes cancer genomes. SCNAs comprise many classes of clinically relevant events, such as localised amplifications, gains, losses, loss-of-heterozygosity (LOH) events, and recently discovered parallel evolutionary events revealed by multi-sample phasing. These events frequently appear jointly with whole genome doubling (WGD), a transformative event in tumour evolution, which generates tetraploid or near-tetraploid cells. WGD events are often clonal, occuring before the emergence of the most recent common ancestor, and have been associated with increased CIN, poor patient outcome and are currently being investigated as potential therapeutic targets",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "parallelgwas": {
                "Name": "parallelGWAS",
                "Description": "Developing parallel computing tools for genome-wide association studies.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "rck": {
                "Name": "RCK",
                "Description": "Reconstruction of clone- and haplotype-specific cancer genome karyotypes from bulk tumor samples.\n\nReconstruction of clone- and haplotype-specific Cancer Karyotypes.\n\nNOTE: this repository contains only the initial version of RCK at the time of its publication.\n\nRCK - is a method for Reconstruction of clone- and haplotype-specific Cancer Karyotypes from tumor mixtures, distributed both as a standalone software package and as a Python library under the MIT licence.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            }
        }
    },
    "operation_3745": {
        "Name": "Ancestral reconstruction",
        "Count": 2,
        "Tools": {
            "medicc2": {
                "Name": "MEDICC2",
                "Description": "Whole-genome doubling-aware copy number phylogenies for cancer evolution with MEDICC2. Chromosomal instability (CIN) and somatic copy number alterations (SCNA) play a key role in the evolutionary process that shapes cancer genomes. SCNAs comprise many classes of clinically relevant events, such as localised amplifications, gains, losses, loss-of-heterozygosity (LOH) events, and recently discovered parallel evolutionary events revealed by multi-sample phasing. These events frequently appear jointly with whole genome doubling (WGD), a transformative event in tumour evolution, which generates tetraploid or near-tetraploid cells. WGD events are often clonal, occuring before the emergence of the most recent common ancestor, and have been associated with increased CIN, poor patient outcome and are currently being investigated as potential therapeutic targets",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "snppar": {
                "Name": "SNPPar",
                "Description": "identifying convergent evolution and other homoplasies from microbial whole-genome alignments.\n\nData and scripts for testing SNPPar with either simulated or empirical datasets.\n\nSNPPar is designed to find homoplasic SNPs based on a user-defined phylogenetic tree - more specifically, it searches for those SNPs that are: parallel - same mutation (eg. A ~> T) @ same position in two (or more) unrelated groups/isolates; convergent - different mutation in resulting in same base (eg. A ~> T, C ~> T) @ same position in two (or more) unrelated groups/isolates; and/or revertant - mutation back to ancestral state (eg. A ~> T ~> A).\n\nThese are self-contained datasets, including reference(s), tree and snp_table(s) required to run SNPPar. The instructions for each are below in 10. Published Datasets.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            }
        }
    },
    "operation_3660": {
        "Name": "Metabolic network modelling",
        "Count": 1,
        "Tools": {
            "Metage2Metabo": {
                "Name": "Metage2Metabo",
                "Description": "metabolic complementarity applied to genomes of large-scale microbiotas for the identification of keystone species.\n\nFrom annotated genomes to metabolic screening in large scale microbiotas.\n\nMetage2metabo is a Python3 (Python >= 3.6) tool to perform graph-based metabolic analysis starting from annotated genomes (reference genomes or metagenome-assembled genomes). It uses Pathway Tools in a automatic and parallel way to reconstruct metabolic networks for a large number of genomes. The obtained metabolic networks are then analyzed individually and collectively in order to get the added value of metabolic cooperation in microbiota over individual metabolism and to identify and screen interesting organisms among all.\n\nm2m \u2014 metage2metabo documentation.\n\nFree document hosting provided by Read the Docs",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            }
        }
    },
    "operation_3207": {
        "Name": "Gene methylation analysis",
        "Count": 2,
        "Tools": {
            "methpanel": {
                "Name": "MethPanel",
                "Description": "A parallel pipeline and interactive analysis tool for multiplex bisulphite PCR sequencing to assess DNA methylation biomarker panels for disease detection.\n\nMethPanel is a computational pipeline in Linux operating system with an interactive graphical interface for rapid analysis of multiplex bisulphite PCR sequencing data. The tool covers a complete analysis workflow from genomic alignment to DNA methylation calling and supports an unlimited number of PCR amplicons and input samples. Moreover MethPanel offers important and unique features, such as a epipolymorphism score and a bisulphite PCR bias correction. MethPanel can be run in parallel by samples on either a personal computer or a high performance computer. The outputs are automatically forwarded to a shinyApp for convenient display, visualisation and sharing of data with collaborators and clinicians.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "scamace": {
                "Name": "scAMACE",
                "Description": "scAMACE (integrative Analysis of single-cell Methylation, chromatin ACcessibility, and gene Expression). Python implementation (both CPU and GPU version) to a model-based approach to the joint analysis of single-cell data on chromatin accessibility, gene expression and methylation.",
                "GPU": true,
                "CPU": true,
                "ram": false,
                "parallel": false,
                "distributed": false
            }
        }
    },
    "operation_3919": {
        "Name": "Methylation calling",
        "Count": 1,
        "Tools": {
            "methpanel": {
                "Name": "MethPanel",
                "Description": "A parallel pipeline and interactive analysis tool for multiplex bisulphite PCR sequencing to assess DNA methylation biomarker panels for disease detection.\n\nMethPanel is a computational pipeline in Linux operating system with an interactive graphical interface for rapid analysis of multiplex bisulphite PCR sequencing data. The tool covers a complete analysis workflow from genomic alignment to DNA methylation calling and supports an unlimited number of PCR amplicons and input samples. Moreover MethPanel offers important and unique features, such as a epipolymorphism score and a bisulphite PCR bias correction. MethPanel can be run in parallel by samples on either a personal computer or a high performance computer. The outputs are automatically forwarded to a shinyApp for convenient display, visualisation and sharing of data with collaborators and clinicians.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            }
        }
    },
    "operation_2089": {
        "Name": "Sequence alignment refinement",
        "Count": 1,
        "Tools": {
            "modorama": {
                "Name": "MODORAMA",
                "Description": "At MODORAMA two applications can be run: MODexplorer, an integrated tool for exploring protein sequence, structure and function relationships, and MODalign, a rich alignment editor to improve target-template alignments",
                "GPU": false,
                "CPU": false,
                "ram": true,
                "parallel": false,
                "distributed": false
            }
        }
    },
    "operation_3230": {
        "Name": "Read depth analysis",
        "Count": 1,
        "Tools": {
            "mosdepth": {
                "Name": "mosdepth",
                "Description": "Fast BAM/CRAM depth calculation for WGS, exome, or targeted sequencing.",
                "GPU": false,
                "CPU": false,
                "ram": true,
                "parallel": false,
                "distributed": false
            }
        }
    },
    "operation_0278": {
        "Name": "RNA secondary structure prediction",
        "Count": 2,
        "Tools": {
            "mpgafold": {
                "Name": "MPGAfold",
                "Description": "Massively parallel genetic algorithm that predicts RNA secondary structure.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "rna-stability": {
                "Name": "rna-stability",
                "Description": "Parallel processing framework for large-scale generation of secondary RNA structures and folding statistics for the transcriptome of any species.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            }
        }
    },
    "operation_3647": {
        "Name": "Blind peptide database search",
        "Count": 1,
        "Tools": {
            "mr-mspolygraph": {
                "Name": "MR-MSPOLYGRAPH",
                "Description": "MR-MSPOLYGRAPH is a MapReduce based implementation for parallelizing peptide identification from mass spectrometry data",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            }
        }
    },
    "operation_0470": {
        "Name": "Protein secondary structure prediction (coils)",
        "Count": 1,
        "Tools": {
            "mri-image-snr-computer": {
                "Name": "MRI parallel image SNR Computer",
                "Description": "Compute SNR for MRI parallel images using different reconstruction methods. There are three methods we used here to compute the SNR of MR images: ACR, SoS, and OPT.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            }
        }
    },
    "operation_0476": {
        "Name": "Ab initio structure prediction",
        "Count": 1,
        "Tools": {
            "MRUniNovo": {
                "Name": "MRUniNovo",
                "Description": "Tool for de novo peptide sequencing utilizing the hadoop distributed computing framework.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            }
        }
    },
    "operation_0415": {
        "Name": "Nucleic acid feature detection",
        "Count": 2,
        "Tools": {
            "navise": {
                "Name": "NaviSE",
                "Description": "User-friendly streamlined tool which performs a fully-automated parallel processing of genome-wide epigenomics data from sequencing files into a final report, built with a comprehensive set of annotated files that are navigated through a graphic user interface.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "quest": {
                "Name": "QuEST",
                "Description": "Kernel Density Estimator-based package for analysis of massively parallel sequencing data from chromatin immunoprecipitations (ChIP-seq or ChIPseq).",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            }
        }
    },
    "operation_3792": {
        "Name": "miRNA expression analysis",
        "Count": 1,
        "Tools": {
            "normirazor": {
                "Name": "NormiRazor",
                "Description": "Tool applying GPU-accelerated computing for determination of internal references in microRNA transcription studies.\n\nGitLab is a single application for the entire software development lifecycle. From project planning and source code management to CI/CD, monitoring, and security.",
                "GPU": true,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": false
            }
        }
    },
    "operation_0322": {
        "Name": "Molecular model refinement",
        "Count": 1,
        "Tools": {
            "openmdlr": {
                "Name": "OpenMDlr",
                "Description": "Parallel, open-source tools for general protein structure modeling and refinement from pairwise distances.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            }
        }
    },
    "operation_0231": {
        "Name": "Sequence editing",
        "Count": 1,
        "Tools": {
            "pardre": {
                "Name": "ParDRe",
                "Description": "De novo parallel tool to remove duplicated and near-duplicated reads through the clustering of Single-End or Paired-End sequences from fasta or fastq files.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            }
        }
    },
    "operation_0325": {
        "Name": "Phylogenetic tree comparison",
        "Count": 1,
        "Tools": {
            "ParGenes": {
                "Name": "ParGenes",
                "Description": "Tool for massively parallel model selection and phylogenetic tree inference on thousands of genes.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            }
        }
    },
    "operation_2575": {
        "Name": "Binding site prediction",
        "Count": 3,
        "Tools": {
            "parkvfinder": {
                "Name": "parKVFinder",
                "Description": "Parallel KVFinder (parKVFinder) is an open-source software designed for the detection and spatial characterization (shape, volume, area and surrounding residues) of any type of biomolecular cavity. parKVFinder is available alongside an easy-to-use PyMOL plugin (PyMOL2 parKVFinder Tools) with an intuitive graphical user interface that allows users to explore customizable parameters for cavity detection and characterization.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "probis": {
                "Name": "ProBiS",
                "Description": "Web server which detects protein binding sites based on local structural alignments. Algorithms have been parallelized to allow for faster computing against the PDB. Pre-calculated protein similarity profiles for over 29,000 non-redundant proteins are also available.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "pykvfinder": {
                "Name": "pyKVFinder",
                "Description": "Python-C Parallel KVFinder (pyKVFinder) is an efficient and integrable Python package for biomolecular cavity detection and characterization in data science. Besides conventional cavity properties such as volume and area, which are stored as Python dictionaries, pyKVFinder computes cavity depth and hydropathy. Similar to cavity points, these spatial and physicochemical properties are stored as Python ndarrays and can be visualized using Python molecular visualization widgets. In general, pyKVFinder is designed for efficient scripting routines built on easy-to-handle data structures, such as Python dictionaries and NumPy N-dimensional arrays (ndarrays), and can be building blocks for data science and drug design applications.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            }
        }
    },
    "operation_3351": {
        "Name": "Molecular surface analysis",
        "Count": 2,
        "Tools": {
            "parkvfinder": {
                "Name": "parKVFinder",
                "Description": "Parallel KVFinder (parKVFinder) is an open-source software designed for the detection and spatial characterization (shape, volume, area and surrounding residues) of any type of biomolecular cavity. parKVFinder is available alongside an easy-to-use PyMOL plugin (PyMOL2 parKVFinder Tools) with an intuitive graphical user interface that allows users to explore customizable parameters for cavity detection and characterization.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "pykvfinder": {
                "Name": "pyKVFinder",
                "Description": "Python-C Parallel KVFinder (pyKVFinder) is an efficient and integrable Python package for biomolecular cavity detection and characterization in data science. Besides conventional cavity properties such as volume and area, which are stored as Python dictionaries, pyKVFinder computes cavity depth and hydropathy. Similar to cavity points, these spatial and physicochemical properties are stored as Python ndarrays and can be visualized using Python molecular visualization widgets. In general, pyKVFinder is designed for efficient scripting routines built on easy-to-handle data structures, such as Python dictionaries and NumPy N-dimensional arrays (ndarrays), and can be building blocks for data science and drug design applications.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            }
        }
    },
    "operation_0504": {
        "Name": "Multiple structure alignment",
        "Count": 1,
        "Tools": {
            "parmatt": {
                "Name": "parMatt",
                "Description": "parMatt: parallel multiple alignment of protein 3D-structures with translations and twists for distributed-memory systems. parMatt is based on a popular Matt software.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": true
            }
        }
    },
    "operation_0449": {
        "Name": "Sequence alignment analysis (site correlation)",
        "Count": 1,
        "Tools": {
            "parmigene": {
                "Name": "parmigene",
                "Description": "The package provides a parallel estimation of the mutual information based on entropy estimates from k-nearest neighbours distances and algorithms for the reconstruction of gene regulatory networks.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            }
        }
    },
    "operation_0418": {
        "Name": "Protein signal peptide detection",
        "Count": 2,
        "Tools": {
            "PepVis": {
                "Name": "PepVis",
                "Description": "PepVis tool is a python based GUI pipeline which can be used to model and prepare large-scale peptide structure from the sequence and also to perform large-scale peptide virtual screening. PepVis integrates ModPep and Gromacs for modelling and structure optimization of the peptides, while it integrates AutoDock Vina,ZDOCK, AutoDock CrankPep(ADCP) for performing peptide virtual screening. \nThe protein-peptide complexes can be rescored using ZRANK2 and the flexible refinement of the large protein-peptide complexes can also be performed using FlexPepDock. The parallel job execution has been implemented using GNU parallel and the user can provide inputs using GUI which will produce the bash script based on the customized input provided by the user and can be run in terminal.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "SigUNet": {
                "Name": "SigUNet",
                "Description": "signal peptide recognition based on semantic segmentation.\n\nA signal peptide predictor based on deep learning.\n\nFor CPU: pip3 install -r requirement.cpu.txt.\n\nFor GPU (suggest): pip3 install -r requirement.gpu.txt",
                "GPU": true,
                "CPU": true,
                "ram": false,
                "parallel": false,
                "distributed": false
            }
        }
    },
    "operation_3899": {
        "Name": "Protein-protein docking",
        "Count": 2,
        "Tools": {
            "PepVis": {
                "Name": "PepVis",
                "Description": "PepVis tool is a python based GUI pipeline which can be used to model and prepare large-scale peptide structure from the sequence and also to perform large-scale peptide virtual screening. PepVis integrates ModPep and Gromacs for modelling and structure optimization of the peptides, while it integrates AutoDock Vina,ZDOCK, AutoDock CrankPep(ADCP) for performing peptide virtual screening. \nThe protein-peptide complexes can be rescored using ZRANK2 and the flexible refinement of the large protein-peptide complexes can also be performed using FlexPepDock. The parallel job execution has been implemented using GNU parallel and the user can provide inputs using GUI which will produce the bash script based on the customized input provided by the user and can be run in terminal.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "prosettac": {
                "Name": "PRosettaC",
                "Description": "Rosetta Based Modeling of PROTAC Mediated Ternary Complexes.\n\nInstallation requirements for PRosettaC:.\n\nPRosettaC is a computational protocol for the prediction of PROTAC-induced ternary complexes. It was benchmarked against ten available ternary complex crystal structures, and was able to predict six of them to atomic accuracy in one of the top three clusters.\n\nThe protocol receives as input, two protein structures (protein target and E3 ligase), including their appropriate ligands (binders), as well as the PROTAC chemical structure in a SMILES representation, and outputs predicted models for the ternary complex.\n\nto /etc/pbs.conf (on all cluster nodes). Another option is to write this line to a file, e.g. env.txt, and then set the enrionment parameter SCHEDULER_PARAMS=/Path_to_env.txt before starting PRosettaC (see below 'Additional parameters').",
                "GPU": false,
                "CPU": false,
                "ram": true,
                "parallel": false,
                "distributed": false
            }
        }
    },
    "operation_3645": {
        "Name": "PTM identification",
        "Count": 1,
        "Tools": {
            "perceptron": {
                "Name": "PERCEPTRON",
                "Description": "PERCEPTRON is an open-source GPU-accelerated proteoform identification pipeline for top-down proteomics. PERCEPTRON is a freely available web-based proteoform identification pipeline for Top-Down Proteomics (TDP).",
                "GPU": true,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": false
            }
        }
    },
    "operation_3925": {
        "Name": "Network visualisation",
        "Count": 1,
        "Tools": {
            "petal": {
                "Name": "PETAL",
                "Description": "PETAL (ParallEl paThways AnaLyzer): a python tool for deep analysis of biological pathways.\n\n\nPETAL software is written in the Python 3 programming language. It contains a set of tools for pathway analysis and discovery of novel therapeutic targets. The approach allows you to scan and perform a in-depth search of the biological pathway to analyze less recurrent pathways, detect nodes that are far from the initial target nodes and showing the pathway of origin from which it was taken the gene.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            }
        }
    },
    "operation_3226": {
        "Name": "Variant prioritisation",
        "Count": 1,
        "Tools": {
            "Phen2Gene": {
                "Name": "Phen2Gene",
                "Description": "Phen2Gene is a phenotype-driven gene prioritization tool, that takes HPO (Human Phenotype Ontology) IDs as inputs, searches and prioritizes candidate causal disease genes. It is distributed under the MIT License by Wang Genomics Lab. Additionally, we have provided a web server and an associated RESTful API service for running Phen2Gene. Finally, a mobile app for Phen2Gene and several other genetic diagnostic tools from our lab is being tested and will be available soon.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            }
        }
    },
    "operation_0509": {
        "Name": "Local structure alignment",
        "Count": 1,
        "Tools": {
            "probis": {
                "Name": "ProBiS",
                "Description": "Web server which detects protein binding sites based on local structural alignments. Algorithms have been parallelized to allow for faster computing against the PDB. Pre-calculated protein similarity profiles for over 29,000 non-redundant proteins are also available.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            }
        }
    },
    "operation_0533": {
        "Name": "Expression profile pathway mapping",
        "Count": 1,
        "Tools": {
            "promocell": {
                "Name": "ProMoCell",
                "Description": "ProMoCell (Protein interaction-based functional Modules of the Cell of an organism) is a network-based zoning approach that can determine the functional modules of a cell of an organism and can potentially be utilized for parallel whole-cell simulation. ProMoCell is a single-click web service and it is very simple, user-friendly and easy to use. Presumably, no other web services like ProMoCell exists till date.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            }
        }
    },
    "operation_3938": {
        "Name": "Virtual screening",
        "Count": 4,
        "Tools": {
            "prosettac": {
                "Name": "PRosettaC",
                "Description": "Rosetta Based Modeling of PROTAC Mediated Ternary Complexes.\n\nInstallation requirements for PRosettaC:.\n\nPRosettaC is a computational protocol for the prediction of PROTAC-induced ternary complexes. It was benchmarked against ten available ternary complex crystal structures, and was able to predict six of them to atomic accuracy in one of the top three clusters.\n\nThe protocol receives as input, two protein structures (protein target and E3 ligase), including their appropriate ligands (binders), as well as the PROTAC chemical structure in a SMILES representation, and outputs predicted models for the ternary complex.\n\nto /etc/pbs.conf (on all cluster nodes). Another option is to write this line to a file, e.g. env.txt, and then set the enrionment parameter SCHEDULER_PARAMS=/Path_to_env.txt before starting PRosettaC (see below 'Additional parameters').",
                "GPU": false,
                "CPU": false,
                "ram": true,
                "parallel": false,
                "distributed": false
            },
            "ramd": {
                "Name": "RAMD",
                "Description": "Efficient random acceleration molecular dynamics simulation and interaction fingerprint analysis of ligand trajectories.\n\nRandom Acceleration Molecular Dynamics (RAMD).\n\nRandom Acceleration Molecular Dynamics (RAMD) is a method to carry out molecular dynamics simulations with an additional randomly oriented force applied to a molecule in the system.",
                "GPU": false,
                "CPU": false,
                "ram": true,
                "parallel": false,
                "distributed": false
            },
            "reframe": {
                "Name": "ReFRAME",
                "Description": "The ReFRAME library as a comprehensive drug repurposing library and its application to the treatment of cryptosporidiosis.\n\nReframeDB is an open and extendable drug repurposing database and screening set of 12,000 compounds.",
                "GPU": false,
                "CPU": false,
                "ram": true,
                "parallel": false,
                "distributed": false
            },
            "uni_dock": {
                "Name": "Uni-Dock",
                "Description": "GPU-accelerated docking.",
                "GPU": true,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": false
            }
        }
    },
    "operation_2483": {
        "Name": "Structure comparison",
        "Count": 1,
        "Tools": {
            "pykvfinder": {
                "Name": "pyKVFinder",
                "Description": "Python-C Parallel KVFinder (pyKVFinder) is an efficient and integrable Python package for biomolecular cavity detection and characterization in data science. Besides conventional cavity properties such as volume and area, which are stored as Python dictionaries, pyKVFinder computes cavity depth and hydropathy. Similar to cavity points, these spatial and physicochemical properties are stored as Python ndarrays and can be visualized using Python molecular visualization widgets. In general, pyKVFinder is designed for efficient scripting routines built on easy-to-handle data structures, such as Python dictionaries and NumPy N-dimensional arrays (ndarrays), and can be building blocks for data science and drug design applications.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            }
        }
    },
    "operation_0387": {
        "Name": "Molecular surface calculation",
        "Count": 1,
        "Tools": {
            "pyspawn": {
                "Name": "PySpawn",
                "Description": "Software for Nonadiabatic Quantum Molecular Dynamics.\n\nThe ab initio multiple spawning (AIMS) method enables nonadiabatic quantum molecular dynamics simulations in an arbitrary number of dimensions, with potential energy surfaces provided by electronic structure calculations performed on-the-fly. However, the intricacy of the AIMS algorithm complicates software development, deployment on modern shared computer resources, and postsimulation data analysis. PySpawn is a nonadiabatic molecular dynamics software package that addresses these issues. The program is designed to be easily interfaced with electronic structure software, and an interface to the TeraChem software package is described here. PySpawn introduces a task-based reorganization of the AIMS algorithm, allowing fine-grained restart capability and setting the stage for efficient parallelization in a future release",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            }
        }
    },
    "operation_0239": {
        "Name": "Sequence motif recognition",
        "Count": 1,
        "Tools": {
            "qpms9": {
                "Name": "qPMS9",
                "Description": "Parallel exact qPMS (quorum Planted Motif Search) algorithm that offers significant runtime improvements on DNA and protein datasets.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            }
        }
    },
    "operation_0443": {
        "Name": "trans-regulatory element prediction",
        "Count": 1,
        "Tools": {
            "RAMPAGE": {
                "Name": "RAMPAGE",
                "Description": "> VERY_LOW CONFIDENCE! | > CORRECT NAME OF TOOL COULD ALSO BE 'Alu', 'III-transcribed', 'Pol III-transcribed', 'III-transcribed Alu' | Genome-wide analysis of polymerase III-transcribed Alu elements suggests cell-type-specific enhancer function | Pipeline to identify expressed Alu elements using RAMPAGE | A schematic flow shows the pipeline",
                "GPU": false,
                "CPU": false,
                "ram": true,
                "parallel": false,
                "distributed": false
            }
        }
    },
    "operation_3461": {
        "Name": "Virulence prediction",
        "Count": 1,
        "Tools": {
            "readscan": {
                "Name": "Readscan",
                "Description": "This is a highly scalable parallel program to identify non-host sequences (of potential pathogen origin) and estimate their genome relative abundance in high-throughput sequence datasets.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            }
        }
    },
    "operation_0523": {
        "Name": "Mapping assembly",
        "Count": 1,
        "Tools": {
            "refka": {
                "Name": "RefKA",
                "Description": "A fast and efficient long-read genome assembly approach for large and complex genomes.\n\nRecent advances in long-read sequencing have the potential to produce more complete genome assemblies using sequence reads which can span repetitive regions. However, overlap based assembly methods routinely used for this data require significant computing time and resources. We have developed RefKA, a reference-based approach for long read genome assembly. This approach relies on breaking up a closely related reference genome into bins, aligning k-mers unique to each bin with PacBio reads, and then assembling each bin in parallel followed by a final bin-stitching step.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            }
        }
    },
    "operation_0416": {
        "Name": "Epitope mapping",
        "Count": 1,
        "Tools": {
            "retrieve_and_relate": {
                "Name": "Retrieve and Relate",
                "Description": "Retrieve similar sequences beginning from DNA, RNA or Proteins as well as free text - meaning there is no need to set any preliminary search parameters or filters which restrict the search space. Out of the box your search in parallel 11 of the most popular databases. Average alignment takes less then 3 seconds. Adding your own database is as simple as a click of the button.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            }
        }
    },
    "operation_3182": {
        "Name": "Genome alignment",
        "Count": 3,
        "Tools": {
            "retrieve_and_relate": {
                "Name": "Retrieve and Relate",
                "Description": "Retrieve similar sequences beginning from DNA, RNA or Proteins as well as free text - meaning there is no need to set any preliminary search parameters or filters which restrict the search space. Out of the box your search in parallel 11 of the most popular databases. Average alignment takes less then 3 seconds. Adding your own database is as simple as a click of the button.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "scrooge": {
                "Name": "Scrooge",
                "Description": "A fast and memory-frugal genomic sequence aligner for CPUs, GPUs and ASICs.",
                "GPU": true,
                "CPU": true,
                "ram": false,
                "parallel": false,
                "distributed": false
            },
            "snppar": {
                "Name": "SNPPar",
                "Description": "identifying convergent evolution and other homoplasies from microbial whole-genome alignments.\n\nData and scripts for testing SNPPar with either simulated or empirical datasets.\n\nSNPPar is designed to find homoplasic SNPs based on a user-defined phylogenetic tree - more specifically, it searches for those SNPs that are: parallel - same mutation (eg. A ~> T) @ same position in two (or more) unrelated groups/isolates; convergent - different mutation in resulting in same base (eg. A ~> T, C ~> T) @ same position in two (or more) unrelated groups/isolates; and/or revertant - mutation back to ancestral state (eg. A ~> T ~> A).\n\nThese are self-contained datasets, including reference(s), tree and snp_table(s) required to run SNPPar. The instructions for each are below in 10. Published Datasets.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            }
        }
    },
    "operation_2454": {
        "Name": "Gene prediction",
        "Count": 1,
        "Tools": {
            "rhinella": {
                "Name": "Rhinella arenarum transcriptome",
                "Description": "The common toad Rhinella arenarum is widely distributed in Argentina, where it is utilised as an autochthonous model in ecotoxicological research and environmental toxicology. However, the lack of a reference genome makes molecular assays and gene expression studies difficult to carry out on this non-model species. To address this issue, we performed a genome-wide transcriptome analysis on R. arenarum larvae through massive RNA sequencing, followed by de novo assembly, annotation, and gene prediction. We obtained 57,407 well-annotated transcripts representing 99.4% of transcriptome completeness (available at http: rhinella.uncoma.edu.ar). We also defined a set of 52,800 high-confidence lncRNA transcripts and demonstrated the reliability of the transcriptome data to perform phylogenetic analysis",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            }
        }
    },
    "operation_3187": {
        "Name": "Sequence contamination filtering",
        "Count": 1,
        "Tools": {
            "ribodetector": {
                "Name": "RiboDetector",
                "Description": "RiboDetector is a software developed to accurately yet rapidly detect and remove rRNA sequences from metagenomeic, metatranscriptomic, and ncRNA sequencing data. It was developed based on LSTMs and optimized for both GPU and CPU.",
                "GPU": true,
                "CPU": true,
                "ram": false,
                "parallel": false,
                "distributed": false
            }
        }
    },
    "operation_3642": {
        "Name": "Dimethyl",
        "Count": 1,
        "Tools": {
            "rKIN": {
                "Name": "rKIN",
                "Description": "Kernel-based method for estimating isotopic niche size and overlap.\n\nThe isotopic niche of consumers represents biologically relevant information on resource and habitat use. Several tools have been developed to quantify niche size and overlap. Nonetheless, methods adapted by spatial ecologists to quantify animal home ranges can be modified for use in stable isotope ecology when data are not normally distributed in bivariate space. We offer a tool that draws on existing spatial metrics, such as Minimum Convex Polygon (MCP) and Standard Ellipse Area (SEA), and add novel metrics using Kernel Utilization Density (KUD) estimators to measure isotopic niche size and overlap. We present examples using empirical and simulated data to demonstrate the performance of the package Kernel Isotopic Niches in R (rKIN) under various scenarios.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            }
        }
    },
    "operation_3791": {
        "Name": "Collapsing methods",
        "Count": 1,
        "Tools": {
            "rmvp": {
                "Name": "rMVP",
                "Description": "A Memory-efficient, Visualization-enhanced, and Parallel-accelerated tool for Genome-Wide Association Study.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            }
        }
    },
    "operation_2439": {
        "Name": "RNA secondary structure analysis",
        "Count": 1,
        "Tools": {
            "rna-stability": {
                "Name": "rna-stability",
                "Description": "Parallel processing framework for large-scale generation of secondary RNA structures and folding statistics for the transcriptome of any species.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            }
        }
    },
    "operation_2935": {
        "Name": "Clustering profile plotting",
        "Count": 1,
        "Tools": {
            "scdrake": {
                "Name": "scdrake",
                "Description": "Scdrake is a highly scalable, reproducible and configurable pipeline for scRNA-seq data prepared by a popular 10x Genomics droplet-based technology. Scdrake is implemented as a package for the R language and is built on top of the drake package, a Make-like pipeline toolkit. Scdrake currently provides common steps of scRNA-seq data analysis: quality control and filtering of cells and genes, normalization, dimensionality reduction, clustering, finding of cluster markers and differentially expressed genes between clusters, and integration of multiple datasets. All pipeline steps are accompanied by rich graphical outputs and reports in HTML format.\n\nThanks to the drake package, all intermediate results can be reused, and the pipeline can be easily extended by users to incorporate custom analyses. Also, drake analyzes which parts of the pipeline are already done or haven't changed since the last run, and which can be run in parallel, resulting in great execution speed.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            }
        }
    },
    "operation_2938": {
        "Name": "Dendrogram visualisation",
        "Count": 1,
        "Tools": {
            "scdrake": {
                "Name": "scdrake",
                "Description": "Scdrake is a highly scalable, reproducible and configurable pipeline for scRNA-seq data prepared by a popular 10x Genomics droplet-based technology. Scdrake is implemented as a package for the R language and is built on top of the drake package, a Make-like pipeline toolkit. Scdrake currently provides common steps of scRNA-seq data analysis: quality control and filtering of cells and genes, normalization, dimensionality reduction, clustering, finding of cluster markers and differentially expressed genes between clusters, and integration of multiple datasets. All pipeline steps are accompanied by rich graphical outputs and reports in HTML format.\n\nThanks to the drake package, all intermediate results can be reused, and the pipeline can be easily extended by users to incorporate custom analyses. Also, drake analyzes which parts of the pipeline are already done or haven't changed since the last run, and which can be run in parallel, resulting in great execution speed.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            }
        }
    },
    "operation_3214": {
        "Name": "Spectral analysis",
        "Count": 1,
        "Tools": {
            "sdams": {
                "Name": "SDAMS",
                "Description": "This Package utilizes a Semi-parametric Differential Abundance analysis (SDA) method for metabolomics and proteomics data from mass spectrometry. SDA is able to robustly handle non-normally distributed data and provides a clear quantification of the effect size.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            }
        }
    },
    "operation_0258": {
        "Name": "Sequence alignment analysis",
        "Count": 1,
        "Tools": {
            "seal": {
                "Name": "SEAL",
                "Description": "Seal is a suite of distributed applications for aligning short DNA reads, manipulating and analyzing short read alignments. It is generally run on the Hadoop framework, which makes it particularly well suited for processing large data sets.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            }
        }
    },
    "operation_0252": {
        "Name": "Peptide immunogenicity prediction",
        "Count": 1,
        "Tools": {
            "simcov": {
                "Name": "SIMCoV",
                "Description": "Spatially distributed infection increases viral load in a computational model of SARS-CoV-2 lung infection.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            }
        }
    },
    "operation_3446": {
        "Name": "Cell migration analysis",
        "Count": 1,
        "Tools": {
            "simcov": {
                "Name": "SIMCoV",
                "Description": "Spatially distributed infection increases viral load in a computational model of SARS-CoV-2 lung infection.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            }
        }
    },
    "operation_3504": {
        "Name": "Variant pattern analysis",
        "Count": 1,
        "Tools": {
            "scg": {
                "Name": "Single Cell Genotyper (SCG)",
                "Description": "A new statistical model and machine learning inference algorithm designed to determine the pattern of how DNA mutations are distributed in individual cells of a tumour. The software provides implementation of several probabilistic models for clustering single cell (nucleus) data and inferring clonal genotypes.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            }
        }
    },
    "operation_0326": {
        "Name": "Phylogenetic tree editing",
        "Count": 2,
        "Tools": {
            "sitepath": {
                "Name": "sitePath",
                "Description": "A visual tool to identify polymorphism clades and help find fixed and parallel mutations.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            },
            "Treerecs": {
                "Name": "Treerecs",
                "Description": "Treerecs is an open-source (species- and gene-) tree reconciliation software distributed under the GNU AGPL licence.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            }
        }
    },
    "operation_0567": {
        "Name": "Phylogenetic tree visualisation",
        "Count": 1,
        "Tools": {
            "sitepath": {
                "Name": "sitePath",
                "Description": "A visual tool to identify polymorphism clades and help find fixed and parallel mutations.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            }
        }
    },
    "operation_0551": {
        "Name": "Phylogenetic tree topology analysis",
        "Count": 1,
        "Tools": {
            "starbeast3": {
                "Name": "StarBeast3",
                "Description": "BEAST 2 based package for Bayesian multispecies coalescent (MSC) analyses using efficient and parallelised MCMC operators.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            }
        }
    },
    "operation_3630": {
        "Name": "Protein quantification",
        "Count": 1,
        "Tools": {
            "stpeter": {
                "Name": "StPeter",
                "Description": "A tool for analyzing proteomics data acquired by mass spectrometry. Quantifies proteins from shotgun MS/MS data using normalized spectral count or normalized spectral index techniques. Incorporates distributed techniques to account for peptide sequence degeneracy.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            }
        }
    },
    "operation_3634": {
        "Name": "Label-free quantification",
        "Count": 1,
        "Tools": {
            "stpeter": {
                "Name": "StPeter",
                "Description": "A tool for analyzing proteomics data acquired by mass spectrometry. Quantifies proteins from shotgun MS/MS data using normalized spectral count or normalized spectral index techniques. Incorporates distributed techniques to account for peptide sequence degeneracy.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            }
        }
    },
    "operation_3637": {
        "Name": "Spectral counting",
        "Count": 1,
        "Tools": {
            "stpeter": {
                "Name": "StPeter",
                "Description": "A tool for analyzing proteomics data acquired by mass spectrometry. Quantifies proteins from shotgun MS/MS data using normalized spectral count or normalized spectral index techniques. Incorporates distributed techniques to account for peptide sequence degeneracy.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            }
        }
    },
    "operation_0230": {
        "Name": "Sequence generation",
        "Count": 1,
        "Tools": {
            "sv-gen": {
                "Name": "sv-gen",
                "Description": "Highly portable parallel workflow to generate artificial genomes with structural variants.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            }
        }
    },
    "operation_3225": {
        "Name": "Variant classification",
        "Count": 1,
        "Tools": {
            "tiddit": {
                "Name": "TIDDIT",
                "Description": "Efficient and comprehensive structural variant caller for massive parallel sequencing data. Identify chromosomal rearrangements using Mate Pair or Paired End sequencing data. It allows identification of intra and inter-chromosomal translocations, deletions, tandem-duplications and inversions, using supplementary alignments as well as discordant pairs.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            }
        }
    },
    "operation_3933": {
        "Name": "Demultiplexing",
        "Count": 1,
        "Tools": {
            "tis": {
                "Name": "TIS",
                "Description": "Assessment of methods for Transposon Insertion Sequencing(TIS) analyses.\n\nThe TA are distributed relatively evenly along genome. The Mariner-based transposons can be inserted to impact statistically every gene, with in average more than 30 insertions site per kb. With the low insertion bias, it is easy to build saturated libraries. But local variations means less loci and less statistical power.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": false,
                "distributed": true
            }
        }
    },
    "operation_0319": {
        "Name": "Protein secondary structure assignment",
        "Count": 1,
        "Tools": {
            "what_if": {
                "Name": "WHAT IF",
                "Description": "PDB Related Datbases present a series of databases that run parallel to the PDB. DSSP holds the secondary structure of the proteins. PDBREPORT holds reports on the structure quality and lists errors. HSSP holds a multiple sequence alignment for all proteins. The PDBFINDER holds easy to parse summaries of the PDB file content. PDB_REDO holds re-refined, and often improved, copies of all structures solved by X-ray.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            }
        }
    },
    "operation_2416": {
        "Name": "Protein secondary structure analysis",
        "Count": 1,
        "Tools": {
            "what_if": {
                "Name": "WHAT IF",
                "Description": "PDB Related Datbases present a series of databases that run parallel to the PDB. DSSP holds the secondary structure of the proteins. PDBREPORT holds reports on the structure quality and lists errors. HSSP holds a multiple sequence alignment for all proteins. The PDBFINDER holds easy to parse summaries of the PDB file content. PDB_REDO holds re-refined, and often improved, copies of all structures solved by X-ray.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            }
        }
    },
    "operation_2488": {
        "Name": "Protein secondary structure comparison",
        "Count": 1,
        "Tools": {
            "what_if": {
                "Name": "WHAT IF",
                "Description": "PDB Related Datbases present a series of databases that run parallel to the PDB. DSSP holds the secondary structure of the proteins. PDBREPORT holds reports on the structure quality and lists errors. HSSP holds a multiple sequence alignment for all proteins. The PDBFINDER holds easy to parse summaries of the PDB file content. PDB_REDO holds re-refined, and often improved, copies of all structures solved by X-ray.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            }
        }
    },
    "operation_3209": {
        "Name": "Genome comparison",
        "Count": 1,
        "Tools": {
            "winbioinftools": {
                "Name": "WinBioinfTools",
                "Description": "Bioinformatics Tools for Windows Cluster provides: 1) CoCoNUT for pairwise genome comparison, 2) parallel BLAST for biological database search, and 3) parallel global pairwise sequence alignment  running over Windows Cluster running Windows HPC server 2008.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            }
        }
    },
    "operation_2406": {
        "Name": "Protein structure analysis",
        "Count": 1,
        "Tools": {
            "xchemexplorer": {
                "Name": "XChemExplorer",
                "Description": "Data management and workflow tool for the parallel determination of protein-ligand structures. It was initially written to support crystallographic fragment screening at beamline I04-1 at the Diamond Light Source, but it is a generic program that can be used to facilitate any structure-based drug design project.",
                "GPU": false,
                "CPU": false,
                "ram": false,
                "parallel": true,
                "distributed": false
            }
        }
    },
    "Total": {
        "Operations": 201,
        "Tools": 375
    }
}